2025-06-18 10:31:31,954 - INFO - === Neuron Activation Difference Analyzer ===
2025-06-18 10:31:31,956 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-06-18 10:31:31,956 - INFO - Input text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-18 10:31:31,956 - INFO - Noise scale: 5
2025-06-18 10:31:31,956 - INFO - Number of samples: 100
2025-06-18 10:31:31,956 - INFO - Random seed: 42
2025-06-18 10:31:31,956 - INFO - Device: cuda
2025-06-18 10:31:31,956 - INFO - Log file: ./log/llama_3b.log
2025-06-18 10:31:31,957 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct, using device: cuda
2025-06-18 10:32:13,109 - INFO - Model loading completed
2025-06-18 10:32:13,111 - INFO - Starting neuron activation difference analysis
2025-06-18 10:32:13,115 - INFO - Set up hooks for 280 key modules
2025-06-18 10:32:13,118 - INFO - Input text length: 115 tokens
2025-06-18 10:32:13,118 - INFO - Collecting baseline activations
2025-06-18 10:32:13,892 - INFO - Collected baseline activations from 252 modules
2025-06-18 10:32:13,893 - INFO - Running noise experiment 1/100
2025-06-18 10:32:13,964 - INFO - Running noise experiment 2/100
2025-06-18 10:32:14,030 - INFO - Running noise experiment 3/100
2025-06-18 10:32:14,093 - INFO - Running noise experiment 4/100
2025-06-18 10:32:14,158 - INFO - Running noise experiment 5/100
2025-06-18 10:32:14,222 - INFO - Running noise experiment 6/100
2025-06-18 10:32:14,290 - INFO - Running noise experiment 7/100
2025-06-18 10:32:14,355 - INFO - Running noise experiment 8/100
2025-06-18 10:32:14,421 - INFO - Running noise experiment 9/100
2025-06-18 10:32:14,486 - INFO - Running noise experiment 10/100
2025-06-18 10:32:14,552 - INFO - Running noise experiment 11/100
2025-06-18 10:32:14,617 - INFO - Running noise experiment 12/100
2025-06-18 10:32:14,684 - INFO - Running noise experiment 13/100
2025-06-18 10:32:14,750 - INFO - Running noise experiment 14/100
2025-06-18 10:32:14,816 - INFO - Running noise experiment 15/100
2025-06-18 10:32:14,882 - INFO - Running noise experiment 16/100
2025-06-18 10:32:14,950 - INFO - Running noise experiment 17/100
2025-06-18 10:32:15,017 - INFO - Running noise experiment 18/100
2025-06-18 10:32:15,084 - INFO - Running noise experiment 19/100
2025-06-18 10:32:15,151 - INFO - Running noise experiment 20/100
2025-06-18 10:32:15,219 - INFO - Running noise experiment 21/100
2025-06-18 10:32:15,287 - INFO - Running noise experiment 22/100
2025-06-18 10:32:15,354 - INFO - Running noise experiment 23/100
2025-06-18 10:32:15,422 - INFO - Running noise experiment 24/100
2025-06-18 10:32:15,490 - INFO - Running noise experiment 25/100
2025-06-18 10:32:15,559 - INFO - Running noise experiment 26/100
2025-06-18 10:32:15,627 - INFO - Running noise experiment 27/100
2025-06-18 10:32:15,698 - INFO - Running noise experiment 28/100
2025-06-18 10:32:15,765 - INFO - Running noise experiment 29/100
2025-06-18 10:32:15,833 - INFO - Running noise experiment 30/100
2025-06-18 10:32:15,902 - INFO - Running noise experiment 31/100
2025-06-18 10:32:15,972 - INFO - Running noise experiment 32/100
2025-06-18 10:32:16,044 - INFO - Running noise experiment 33/100
2025-06-18 10:32:16,119 - INFO - Running noise experiment 34/100
2025-06-18 10:32:16,195 - INFO - Running noise experiment 35/100
2025-06-18 10:32:16,268 - INFO - Running noise experiment 36/100
2025-06-18 10:32:16,339 - INFO - Running noise experiment 37/100
2025-06-18 10:32:16,409 - INFO - Running noise experiment 38/100
2025-06-18 10:32:16,480 - INFO - Running noise experiment 39/100
2025-06-18 10:32:16,550 - INFO - Running noise experiment 40/100
2025-06-18 10:32:16,621 - INFO - Running noise experiment 41/100
2025-06-18 10:32:16,691 - INFO - Running noise experiment 42/100
2025-06-18 10:32:16,761 - INFO - Running noise experiment 43/100
2025-06-18 10:32:16,831 - INFO - Running noise experiment 44/100
2025-06-18 10:32:16,901 - INFO - Running noise experiment 45/100
2025-06-18 10:32:16,972 - INFO - Running noise experiment 46/100
2025-06-18 10:32:17,043 - INFO - Running noise experiment 47/100
2025-06-18 10:32:17,113 - INFO - Running noise experiment 48/100
2025-06-18 10:32:17,187 - INFO - Running noise experiment 49/100
2025-06-18 10:32:17,260 - INFO - Running noise experiment 50/100
2025-06-18 10:32:17,334 - INFO - Running noise experiment 51/100
2025-06-18 10:32:17,405 - INFO - Running noise experiment 52/100
2025-06-18 10:32:17,477 - INFO - Running noise experiment 53/100
2025-06-18 10:32:17,548 - INFO - Running noise experiment 54/100
2025-06-18 10:32:17,620 - INFO - Running noise experiment 55/100
2025-06-18 10:32:17,692 - INFO - Running noise experiment 56/100
2025-06-18 10:32:17,764 - INFO - Running noise experiment 57/100
2025-06-18 10:32:17,837 - INFO - Running noise experiment 58/100
2025-06-18 10:32:17,909 - INFO - Running noise experiment 59/100
2025-06-18 10:32:17,983 - INFO - Running noise experiment 60/100
2025-06-18 10:32:18,057 - INFO - Running noise experiment 61/100
2025-06-18 10:32:18,133 - INFO - Running noise experiment 62/100
2025-06-18 10:32:18,209 - INFO - Running noise experiment 63/100
2025-06-18 10:32:18,283 - INFO - Running noise experiment 64/100
2025-06-18 10:32:18,357 - INFO - Running noise experiment 65/100
2025-06-18 10:32:18,430 - INFO - Running noise experiment 66/100
2025-06-18 10:32:18,504 - INFO - Running noise experiment 67/100
2025-06-18 10:32:18,578 - INFO - Running noise experiment 68/100
2025-06-18 10:32:18,653 - INFO - Running noise experiment 69/100
2025-06-18 10:32:18,726 - INFO - Running noise experiment 70/100
2025-06-18 10:32:18,799 - INFO - Running noise experiment 71/100
2025-06-18 10:32:18,873 - INFO - Running noise experiment 72/100
2025-06-18 10:32:18,947 - INFO - Running noise experiment 73/100
2025-06-18 10:32:19,022 - INFO - Running noise experiment 74/100
2025-06-18 10:32:19,098 - INFO - Running noise experiment 75/100
2025-06-18 10:32:19,172 - INFO - Running noise experiment 76/100
2025-06-18 10:32:19,246 - INFO - Running noise experiment 77/100
2025-06-18 10:32:19,321 - INFO - Running noise experiment 78/100
2025-06-18 10:32:19,397 - INFO - Running noise experiment 79/100
2025-06-18 10:32:19,473 - INFO - Running noise experiment 80/100
2025-06-18 10:32:19,549 - INFO - Running noise experiment 81/100
2025-06-18 10:32:19,624 - INFO - Running noise experiment 82/100
2025-06-18 10:32:19,699 - INFO - Running noise experiment 83/100
2025-06-18 10:32:19,774 - INFO - Running noise experiment 84/100
2025-06-18 10:32:19,849 - INFO - Running noise experiment 85/100
2025-06-18 10:32:19,925 - INFO - Running noise experiment 86/100
2025-06-18 10:32:20,002 - INFO - Running noise experiment 87/100
2025-06-18 10:32:20,077 - INFO - Running noise experiment 88/100
2025-06-18 10:32:20,157 - INFO - Running noise experiment 89/100
2025-06-18 10:32:20,235 - INFO - Running noise experiment 90/100
2025-06-18 10:32:20,313 - INFO - Running noise experiment 91/100
2025-06-18 10:32:20,391 - INFO - Running noise experiment 92/100
2025-06-18 10:32:20,473 - INFO - Running noise experiment 93/100
2025-06-18 10:32:20,554 - INFO - Running noise experiment 94/100
2025-06-18 10:32:20,641 - INFO - Running noise experiment 95/100
2025-06-18 10:32:20,719 - INFO - Running noise experiment 96/100
2025-06-18 10:32:20,797 - INFO - Running noise experiment 97/100
2025-06-18 10:32:20,880 - INFO - Running noise experiment 98/100
2025-06-18 10:32:20,964 - INFO - Running noise experiment 99/100
2025-06-18 10:32:21,041 - INFO - Running noise experiment 100/100
2025-06-18 10:32:21,119 - INFO - Successfully collected activation differences from 252 modules
2025-06-18 10:32:21,120 - INFO - Computing neuron importance
2025-06-18 11:21:19,877 - INFO - Found 125296640 meaningful neurons
2025-06-18 11:21:19,878 - INFO - Sorting neurons by activation difference
2025-06-18 11:22:18,851 - INFO - Saving results to ./neurons/llama_3b.json
2025-06-18 11:31:57,022 - INFO - === Neuron Activation Difference Analyzer ===
2025-06-18 11:31:57,022 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-06-18 11:31:57,022 - INFO - Input text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-18 11:31:57,022 - INFO - Noise scale: 5
2025-06-18 11:31:57,023 - INFO - Number of samples: 100
2025-06-18 11:31:57,023 - INFO - Random seed: 42
2025-06-18 11:31:57,023 - INFO - Device: cuda
2025-06-18 11:31:57,023 - INFO - Log file: ./log/llama_3b.log
2025-06-18 11:31:57,024 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct, using device: cuda
2025-06-18 11:32:38,818 - INFO - Model loading completed
2025-06-18 11:32:38,841 - INFO - Starting neuron activation difference analysis
2025-06-18 11:32:38,844 - INFO - Set up hooks for 280 key modules
2025-06-18 11:32:38,847 - INFO - Input text length: 115 tokens
2025-06-18 11:32:38,847 - INFO - Collecting baseline activations
2025-06-18 11:32:39,703 - INFO - Collected baseline activations from 252 modules
2025-06-18 11:32:39,703 - INFO - Running noise experiment 1/100
2025-06-18 11:32:39,785 - INFO - Running noise experiment 2/100
2025-06-18 11:32:39,850 - INFO - Running noise experiment 3/100
2025-06-18 11:32:39,914 - INFO - Running noise experiment 4/100
2025-06-18 11:32:39,980 - INFO - Running noise experiment 5/100
2025-06-18 11:32:40,046 - INFO - Running noise experiment 6/100
2025-06-18 11:32:40,111 - INFO - Running noise experiment 7/100
2025-06-18 11:32:40,194 - INFO - Running noise experiment 8/100
2025-06-18 11:32:40,262 - INFO - Running noise experiment 9/100
2025-06-18 11:32:40,329 - INFO - Running noise experiment 10/100
2025-06-18 11:32:40,395 - INFO - Running noise experiment 11/100
2025-06-18 11:32:40,463 - INFO - Running noise experiment 12/100
2025-06-18 11:32:40,530 - INFO - Running noise experiment 13/100
2025-06-18 11:32:40,600 - INFO - Running noise experiment 14/100
2025-06-18 11:32:40,668 - INFO - Running noise experiment 15/100
2025-06-18 11:32:40,735 - INFO - Running noise experiment 16/100
2025-06-18 11:32:40,816 - INFO - Running noise experiment 17/100
2025-06-18 11:32:40,883 - INFO - Running noise experiment 18/100
2025-06-18 11:32:40,950 - INFO - Running noise experiment 19/100
2025-06-18 11:32:41,018 - INFO - Running noise experiment 20/100
2025-06-18 11:32:41,086 - INFO - Running noise experiment 21/100
2025-06-18 11:32:41,155 - INFO - Running noise experiment 22/100
2025-06-18 11:32:41,225 - INFO - Running noise experiment 23/100
2025-06-18 11:32:41,295 - INFO - Running noise experiment 24/100
2025-06-18 11:32:41,365 - INFO - Running noise experiment 25/100
2025-06-18 11:32:41,437 - INFO - Running noise experiment 26/100
2025-06-18 11:32:41,510 - INFO - Running noise experiment 27/100
2025-06-18 11:32:41,578 - INFO - Running noise experiment 28/100
2025-06-18 11:32:41,647 - INFO - Running noise experiment 29/100
2025-06-18 11:32:41,717 - INFO - Running noise experiment 30/100
2025-06-18 11:32:41,786 - INFO - Running noise experiment 31/100
2025-06-18 11:32:41,860 - INFO - Running noise experiment 32/100
2025-06-18 11:32:41,936 - INFO - Running noise experiment 33/100
2025-06-18 11:32:42,006 - INFO - Running noise experiment 34/100
2025-06-18 11:32:42,077 - INFO - Running noise experiment 35/100
2025-06-18 11:32:42,148 - INFO - Running noise experiment 36/100
2025-06-18 11:32:42,232 - INFO - Running noise experiment 37/100
2025-06-18 11:32:42,303 - INFO - Running noise experiment 38/100
2025-06-18 11:32:42,375 - INFO - Running noise experiment 39/100
2025-06-18 11:32:42,448 - INFO - Running noise experiment 40/100
2025-06-18 11:32:42,521 - INFO - Running noise experiment 41/100
2025-06-18 11:32:42,594 - INFO - Running noise experiment 42/100
2025-06-18 11:32:42,671 - INFO - Running noise experiment 43/100
2025-06-18 11:32:42,744 - INFO - Running noise experiment 44/100
2025-06-18 11:32:42,820 - INFO - Running noise experiment 45/100
2025-06-18 11:32:42,898 - INFO - Running noise experiment 46/100
2025-06-18 11:32:42,977 - INFO - Running noise experiment 47/100
2025-06-18 11:32:43,056 - INFO - Running noise experiment 48/100
2025-06-18 11:32:43,131 - INFO - Running noise experiment 49/100
2025-06-18 11:32:43,209 - INFO - Running noise experiment 50/100
2025-06-18 11:32:43,288 - INFO - Running noise experiment 51/100
2025-06-18 11:32:43,364 - INFO - Running noise experiment 52/100
2025-06-18 11:32:43,444 - INFO - Running noise experiment 53/100
2025-06-18 11:32:43,517 - INFO - Running noise experiment 54/100
2025-06-18 11:32:43,593 - INFO - Running noise experiment 55/100
2025-06-18 11:32:43,670 - INFO - Running noise experiment 56/100
2025-06-18 11:32:43,747 - INFO - Running noise experiment 57/100
2025-06-18 11:32:43,822 - INFO - Running noise experiment 58/100
2025-06-18 11:32:43,900 - INFO - Running noise experiment 59/100
2025-06-18 11:32:43,973 - INFO - Running noise experiment 60/100
2025-06-18 11:32:44,049 - INFO - Running noise experiment 61/100
2025-06-18 11:32:44,125 - INFO - Running noise experiment 62/100
2025-06-18 11:32:44,203 - INFO - Running noise experiment 63/100
2025-06-18 11:32:44,281 - INFO - Running noise experiment 64/100
2025-06-18 11:32:44,369 - INFO - Running noise experiment 65/100
2025-06-18 11:32:44,456 - INFO - Running noise experiment 66/100
2025-06-18 11:32:44,539 - INFO - Running noise experiment 67/100
2025-06-18 11:32:44,622 - INFO - Running noise experiment 68/100
2025-06-18 11:32:44,716 - INFO - Running noise experiment 69/100
2025-06-18 11:32:44,796 - INFO - Running noise experiment 70/100
2025-06-18 11:32:44,887 - INFO - Running noise experiment 71/100
2025-06-18 11:32:44,969 - INFO - Running noise experiment 72/100
2025-06-18 11:32:45,046 - INFO - Running noise experiment 73/100
2025-06-18 11:32:45,124 - INFO - Running noise experiment 74/100
2025-06-18 11:32:45,203 - INFO - Running noise experiment 75/100
2025-06-18 11:32:45,280 - INFO - Running noise experiment 76/100
2025-06-18 11:32:45,355 - INFO - Running noise experiment 77/100
2025-06-18 11:32:45,432 - INFO - Running noise experiment 78/100
2025-06-18 11:32:45,509 - INFO - Running noise experiment 79/100
2025-06-18 11:32:45,586 - INFO - Running noise experiment 80/100
2025-06-18 11:32:45,679 - INFO - Running noise experiment 81/100
2025-06-18 11:32:45,754 - INFO - Running noise experiment 82/100
2025-06-18 11:32:45,830 - INFO - Running noise experiment 83/100
2025-06-18 11:32:45,907 - INFO - Running noise experiment 84/100
2025-06-18 11:32:45,984 - INFO - Running noise experiment 85/100
2025-06-18 11:32:46,065 - INFO - Running noise experiment 86/100
2025-06-18 11:32:46,147 - INFO - Running noise experiment 87/100
2025-06-18 11:32:46,227 - INFO - Running noise experiment 88/100
2025-06-18 11:32:46,304 - INFO - Running noise experiment 89/100
2025-06-18 11:32:46,382 - INFO - Running noise experiment 90/100
2025-06-18 11:32:47,448 - INFO - Running noise experiment 91/100
2025-06-18 11:32:47,526 - INFO - Running noise experiment 92/100
2025-06-18 11:32:47,612 - INFO - Running noise experiment 93/100
2025-06-18 11:32:47,702 - INFO - Running noise experiment 94/100
2025-06-18 11:32:47,794 - INFO - Running noise experiment 95/100
2025-06-18 11:32:47,874 - INFO - Running noise experiment 96/100
2025-06-18 11:32:47,957 - INFO - Running noise experiment 97/100
2025-06-18 11:32:49,030 - INFO - Running noise experiment 98/100
2025-06-18 11:32:49,146 - INFO - Running noise experiment 99/100
2025-06-18 11:32:49,231 - INFO - Running noise experiment 100/100
2025-06-18 11:32:49,311 - INFO - Successfully collected activation differences from 252 modules
2025-06-18 11:32:49,311 - INFO - Computing neuron importance
2025-06-18 12:21:44,328 - INFO - Found 125296640 meaningful neurons
2025-06-18 12:21:44,329 - INFO - Sorting neurons by activation difference
2025-06-18 12:22:42,390 - INFO - Saving results to ./neurons/llama_3b.json
2025-06-18 12:22:42,489 - INFO - Analysis completed
2025-06-18 12:22:42,490 - INFO - Total discovered neurons: 125296640
2025-06-18 12:22:42,490 - INFO - Top 10 neurons with highest activation difference:
2025-06-18 12:22:42,490 - INFO - Rank 1: Layer model.layers.1.mlp.down_proj, Activation diff: 416.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 588
2025-06-18 12:22:42,490 - INFO - Rank 2: Layer model.layers.1.mlp.down_proj, Activation diff: 384.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 1016
2025-06-18 12:22:42,490 - INFO - Rank 3: Layer model.layers.1.mlp.down_proj, Activation diff: 370.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 3046
2025-06-18 12:22:42,490 - INFO - Rank 4: Layer model.layers.1.mlp.down_proj, Activation diff: 330.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 1731
2025-06-18 12:22:42,490 - INFO - Rank 5: Layer model.layers.27.mlp.down_proj, Activation diff: 277.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 588
2025-06-18 12:22:42,490 - INFO - Rank 6: Layer model.layers.27.mlp.down_proj, Activation diff: 269.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 1016
2025-06-18 12:22:42,490 - INFO - Rank 7: Layer model.layers.27.mlp.down_proj, Activation diff: 246.125000, batch_idx: 0, seq_idx: 0, hidden_idx: 3046
2025-06-18 12:22:42,491 - INFO - Rank 8: Layer model.layers.27.mlp.down_proj, Activation diff: 223.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 1731
2025-06-18 12:22:42,491 - INFO - Rank 9: Layer model.layers.1.mlp.up_proj, Activation diff: 38.312500, batch_idx: 0, seq_idx: 0, hidden_idx: 1419
2025-06-18 12:22:42,491 - INFO - Rank 10: Layer model.layers.1.mlp.down_proj, Activation diff: 35.875000, batch_idx: 0, seq_idx: 0, hidden_idx: 1659
2025-06-18 12:22:43,796 - INFO - === Analysis Completed ===
2025-06-18 12:22:43,799 - INFO - Discovered 125296640 neurons
2025-06-18 12:22:43,800 - INFO - Results saved to: ./neurons/llama_3b.json
2025-06-18 12:22:43,801 - INFO - Log saved to: ./log/llama_3b.log
2025-06-21 13:13:49,437 - INFO - === Progressive Neuron Masking Analyzer ===
2025-06-21 13:13:49,461 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-06-21 13:13:49,461 - INFO - Neuron file: ./neurons/llama_3b.json
2025-06-21 13:13:49,461 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:13:49,461 - INFO - Step size: 1
2025-06-21 13:13:49,461 - INFO - Max magnitude increase: 4.0
2025-06-21 13:13:49,461 - INFO - Random seed: 42
2025-06-21 13:13:49,461 - INFO - Device: cuda
2025-06-21 13:13:49,462 - INFO - Log file: ./log/llama_3b.log
2025-06-21 13:13:49,463 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct, using device: cuda
2025-06-21 13:14:40,846 - INFO - Model loading completed
2025-06-21 13:14:40,866 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-06-21 13:14:40,916 - INFO - Loaded 10000 neurons
2025-06-21 13:14:40,916 - INFO - Starting progressive neuron masking analysis
2025-06-21 13:14:40,917 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:14:40,917 - INFO - Step size: 1
2025-06-21 13:14:40,917 - INFO - Max magnitude increase: 4.0
2025-06-21 13:14:40,919 - INFO - Set up masking hooks for 62 target layers
2025-06-21 13:14:40,919 - INFO - Computing baseline perplexity
2025-06-21 13:14:41,783 - INFO - Baseline perplexity: 45.6465
2025-06-21 13:14:41,784 - INFO - Step 1: masking 1 neurons (total: 1)
2025-06-21 13:14:41,881 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:41,915 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:41,915 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:41,915 - INFO - Step 2: masking 2 neurons (total: 2)
2025-06-21 13:14:41,955 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:41,989 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:41,990 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:41,990 - INFO - Step 3: masking 3 neurons (total: 3)
2025-06-21 13:14:42,029 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,063 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,063 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,063 - INFO - Step 4: masking 4 neurons (total: 4)
2025-06-21 13:14:42,103 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,137 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,137 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,137 - INFO - Step 5: masking 5 neurons (total: 5)
2025-06-21 13:14:42,211 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,244 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,245 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,246 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,246 - INFO - Step 6: masking 6 neurons (total: 6)
2025-06-21 13:14:42,320 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,352 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,354 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,354 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,354 - INFO - Step 7: masking 7 neurons (total: 7)
2025-06-21 13:14:42,429 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,462 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,463 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,464 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,464 - INFO - Step 8: masking 8 neurons (total: 8)
2025-06-21 13:14:42,539 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,571 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,573 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,573 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,573 - INFO - Step 9: masking 9 neurons (total: 9)
2025-06-21 13:14:42,682 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:42,683 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,715 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,717 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,717 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,717 - INFO - Step 10: masking 10 neurons (total: 10)
2025-06-21 13:14:42,827 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:42,827 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,860 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:42,861 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:42,861 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:42,861 - INFO - Step 11: masking 11 neurons (total: 11)
2025-06-21 13:14:42,971 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:42,971 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,004 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,005 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:43,005 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:43,005 - INFO - Step 12: masking 12 neurons (total: 12)
2025-06-21 13:14:43,147 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,150 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:43,150 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,183 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,184 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:43,184 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:43,185 - INFO - Step 13: masking 13 neurons (total: 13)
2025-06-21 13:14:43,327 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,329 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:43,330 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,362 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,364 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:43,364 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:43,364 - INFO - Step 14: masking 14 neurons (total: 14)
2025-06-21 13:14:43,542 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,545 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:43,545 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,577 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:43,578 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,579 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:43,579 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:43,579 - INFO - Step 15: masking 15 neurons (total: 15)
2025-06-21 13:14:43,756 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,759 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:43,759 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,791 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:43,792 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,793 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:43,793 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:43,793 - INFO - Step 16: masking 16 neurons (total: 16)
2025-06-21 13:14:43,970 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:43,973 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:43,973 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,006 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,006 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,007 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:44,007 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:44,008 - INFO - Step 17: masking 17 neurons (total: 17)
2025-06-21 13:14:44,184 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,187 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,187 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,220 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,220 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,222 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:44,222 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:44,222 - INFO - Step 18: masking 18 neurons (total: 18)
2025-06-21 13:14:44,400 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,402 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,402 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,435 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,435 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,436 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:44,437 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:44,437 - INFO - Step 19: masking 19 neurons (total: 19)
2025-06-21 13:14:44,614 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,617 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,617 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,649 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,650 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,651 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:44,651 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:44,651 - INFO - Step 20: masking 20 neurons (total: 20)
2025-06-21 13:14:44,829 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,832 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,832 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,864 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:44,865 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:44,866 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:44,866 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:44,866 - INFO - Step 21: masking 21 neurons (total: 21)
2025-06-21 13:14:45,043 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,046 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,046 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,079 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,079 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,080 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:45,081 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:45,081 - INFO - Step 22: masking 22 neurons (total: 22)
2025-06-21 13:14:45,293 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,296 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,296 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,328 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,329 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,329 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,330 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:45,330 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:45,331 - INFO - Step 23: masking 23 neurons (total: 23)
2025-06-21 13:14:45,547 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,550 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,550 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,583 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,583 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,584 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,585 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:45,585 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:45,585 - INFO - Step 24: masking 24 neurons (total: 24)
2025-06-21 13:14:45,799 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,801 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,802 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,834 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,834 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:45,835 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:45,836 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:45,836 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:45,836 - INFO - Step 25: masking 25 neurons (total: 25)
2025-06-21 13:14:46,049 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,052 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,052 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,084 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,085 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,085 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,086 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:46,086 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:46,086 - INFO - Step 26: masking 26 neurons (total: 26)
2025-06-21 13:14:46,300 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,302 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,303 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,335 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,335 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,336 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,337 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:46,337 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:46,337 - INFO - Step 27: masking 27 neurons (total: 27)
2025-06-21 13:14:46,550 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,553 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,553 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,586 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,586 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,586 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,588 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:46,588 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:46,588 - INFO - Step 28: masking 28 neurons (total: 28)
2025-06-21 13:14:46,801 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,803 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,804 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,836 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,836 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:46,837 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:46,838 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:46,838 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:46,838 - INFO - Step 29: masking 29 neurons (total: 29)
2025-06-21 13:14:47,051 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,053 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,053 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,086 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,086 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,086 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,088 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:47,088 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:47,088 - INFO - Step 30: masking 30 neurons (total: 30)
2025-06-21 13:14:47,300 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,303 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,303 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,335 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,336 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,336 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,337 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:47,338 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:47,338 - INFO - Step 31: masking 31 neurons (total: 31)
2025-06-21 13:14:47,550 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,553 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,553 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,585 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,586 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,586 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,587 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:47,587 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:47,588 - INFO - Step 32: masking 32 neurons (total: 32)
2025-06-21 13:14:47,800 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,803 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,803 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,836 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,836 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:47,836 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:47,838 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:47,838 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:47,838 - INFO - Step 33: masking 33 neurons (total: 33)
2025-06-21 13:14:48,050 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,053 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,053 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,085 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,086 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,086 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,087 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:48,087 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:48,087 - INFO - Step 34: masking 34 neurons (total: 34)
2025-06-21 13:14:48,300 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,302 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,303 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,335 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,335 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,336 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,337 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:48,337 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:48,337 - INFO - Step 35: masking 35 neurons (total: 35)
2025-06-21 13:14:48,553 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,555 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,556 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,588 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,589 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,589 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,590 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:48,591 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:48,591 - INFO - Step 36: masking 36 neurons (total: 36)
2025-06-21 13:14:48,807 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,810 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,810 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,842 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,843 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:48,843 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:48,844 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:48,844 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:48,845 - INFO - Step 37: masking 37 neurons (total: 37)
2025-06-21 13:14:49,057 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,060 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,060 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,092 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,093 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,093 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,094 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:49,094 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:49,094 - INFO - Step 38: masking 38 neurons (total: 38)
2025-06-21 13:14:49,307 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,309 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,309 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,342 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,342 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,342 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,344 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:49,344 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:49,344 - INFO - Step 39: masking 39 neurons (total: 39)
2025-06-21 13:14:49,557 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,559 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,560 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,592 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,592 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,592 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,594 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:49,594 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:49,594 - INFO - Step 40: masking 40 neurons (total: 40)
2025-06-21 13:14:49,804 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,807 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,807 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,839 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,839 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:49,840 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:49,841 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:49,841 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:49,841 - INFO - Step 41: masking 41 neurons (total: 41)
2025-06-21 13:14:50,048 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,051 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,051 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,083 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,083 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,084 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,085 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:50,085 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:50,085 - INFO - Step 42: masking 42 neurons (total: 42)
2025-06-21 13:14:50,293 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,296 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,296 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,328 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,328 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,328 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,330 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:50,330 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:50,330 - INFO - Step 43: masking 43 neurons (total: 43)
2025-06-21 13:14:50,538 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,541 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,541 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,573 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,573 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,573 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,575 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:50,575 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:50,575 - INFO - Step 44: masking 44 neurons (total: 44)
2025-06-21 13:14:50,782 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,785 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,785 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,816 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,817 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:50,817 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:50,818 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:50,818 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:50,818 - INFO - Step 45: masking 45 neurons (total: 45)
2025-06-21 13:14:51,025 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,028 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,028 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,059 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,060 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,060 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,061 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:51,062 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:51,062 - INFO - Step 46: masking 46 neurons (total: 46)
2025-06-21 13:14:51,269 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,271 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,272 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,303 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,303 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,304 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,305 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:51,305 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:51,305 - INFO - Step 47: masking 47 neurons (total: 47)
2025-06-21 13:14:51,512 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,515 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,515 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,547 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,547 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,548 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,549 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:51,549 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:51,549 - INFO - Step 48: masking 48 neurons (total: 48)
2025-06-21 13:14:51,757 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,760 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,760 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,792 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,792 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:51,793 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:51,794 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:51,794 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:51,794 - INFO - Step 49: masking 49 neurons (total: 49)
2025-06-21 13:14:52,036 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,039 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,039 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,069 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,071 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,071 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,071 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,072 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:52,072 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:52,073 - INFO - Step 50: masking 50 neurons (total: 50)
2025-06-21 13:14:52,348 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,351 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,351 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,381 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,381 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,383 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,383 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,383 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,385 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:52,385 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:52,385 - INFO - Step 51: masking 51 neurons (total: 51)
2025-06-21 13:14:52,661 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,664 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,664 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,694 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,694 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,696 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,696 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,696 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,698 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:52,698 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:52,698 - INFO - Step 52: masking 52 neurons (total: 52)
2025-06-21 13:14:52,974 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:52,977 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:52,977 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,007 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,007 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,009 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,009 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,009 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,010 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:53,011 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:53,011 - INFO - Step 53: masking 53 neurons (total: 53)
2025-06-21 13:14:53,320 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,323 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,323 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,348 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,353 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,354 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,355 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,355 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,356 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,357 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:53,357 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:53,357 - INFO - Step 54: masking 54 neurons (total: 54)
2025-06-21 13:14:53,702 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,703 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:53,705 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,705 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,730 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,735 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,736 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,737 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,737 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:53,738 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:53,739 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:53,739 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:53,739 - INFO - Step 55: masking 55 neurons (total: 55)
2025-06-21 13:14:54,083 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,083 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:54,086 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,086 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,110 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,116 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,116 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,118 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,118 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,118 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,120 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:54,120 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:54,120 - INFO - Step 56: masking 56 neurons (total: 56)
2025-06-21 13:14:54,464 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,464 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:54,467 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,467 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,492 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,497 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,498 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,499 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,499 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,500 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,501 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:54,501 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:54,501 - INFO - Step 57: masking 57 neurons (total: 57)
2025-06-21 13:14:54,846 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,846 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:54,848 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,849 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,873 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,879 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,879 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,881 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,881 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:54,881 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:54,882 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:54,883 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:54,883 - INFO - Step 58: masking 58 neurons (total: 58)
2025-06-21 13:14:55,227 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,227 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:55,230 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,230 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,255 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,260 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,261 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,262 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,262 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,263 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,264 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:55,264 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:55,264 - INFO - Step 59: masking 59 neurons (total: 59)
2025-06-21 13:14:55,609 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,609 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:55,611 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,612 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,636 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,642 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,642 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,644 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,644 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,644 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,646 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:55,646 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:55,646 - INFO - Step 60: masking 60 neurons (total: 60)
2025-06-21 13:14:55,990 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:55,990 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:55,993 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:55,993 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,017 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,023 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,024 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,025 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,025 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,025 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,027 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:56,027 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:56,027 - INFO - Step 61: masking 61 neurons (total: 61)
2025-06-21 13:14:56,371 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,372 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:56,374 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,374 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,399 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,405 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,405 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,406 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,407 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,407 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,408 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:56,408 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:56,409 - INFO - Step 62: masking 62 neurons (total: 62)
2025-06-21 13:14:56,753 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,754 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:56,756 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,756 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,781 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,787 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,787 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,788 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,789 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:56,789 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:56,790 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:56,790 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:56,790 - INFO - Step 63: masking 63 neurons (total: 63)
2025-06-21 13:14:57,134 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,135 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:57,137 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,137 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,162 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,168 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,168 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,169 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,170 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,170 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,171 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:57,171 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:57,171 - INFO - Step 64: masking 64 neurons (total: 64)
2025-06-21 13:14:57,516 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,516 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:57,519 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,519 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,543 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,549 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,550 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,551 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,551 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,551 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,553 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:57,553 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:57,553 - INFO - Step 65: masking 65 neurons (total: 65)
2025-06-21 13:14:57,897 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,898 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:57,900 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,900 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,925 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,931 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,931 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,932 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,933 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:57,933 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:57,934 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:57,934 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:57,934 - INFO - Step 66: masking 66 neurons (total: 66)
2025-06-21 13:14:58,279 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,280 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:58,282 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,282 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,307 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,313 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,313 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,314 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,314 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,315 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,316 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:58,316 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:58,316 - INFO - Step 67: masking 67 neurons (total: 67)
2025-06-21 13:14:58,662 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,663 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:58,665 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,665 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,690 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,696 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,696 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,697 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,698 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:58,698 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:58,699 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:58,699 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:58,700 - INFO - Step 68: masking 68 neurons (total: 68)
2025-06-21 13:14:59,044 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,044 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:59,047 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,047 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,072 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,077 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,078 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,079 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,079 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,079 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,081 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:59,081 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:59,081 - INFO - Step 69: masking 69 neurons (total: 69)
2025-06-21 13:14:59,426 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,427 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:59,429 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,429 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,454 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,460 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,460 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,461 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,461 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,462 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,463 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:59,463 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:59,463 - INFO - Step 70: masking 70 neurons (total: 70)
2025-06-21 13:14:59,809 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,809 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:14:59,812 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,812 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,836 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,842 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,843 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,844 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,844 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:14:59,844 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:14:59,846 - INFO - Masked perplexity: 45.6465
2025-06-21 13:14:59,846 - INFO - Magnitude increase: 0.0000
2025-06-21 13:14:59,846 - INFO - Step 71: masking 71 neurons (total: 71)
2025-06-21 13:15:00,190 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,191 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:00,193 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,193 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,218 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,224 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,224 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,225 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,225 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,226 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,227 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:00,227 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:00,227 - INFO - Step 72: masking 72 neurons (total: 72)
2025-06-21 13:15:00,572 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,572 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:00,574 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,575 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,599 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,605 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,606 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,607 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,607 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,607 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,609 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:00,609 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:00,609 - INFO - Step 73: masking 73 neurons (total: 73)
2025-06-21 13:15:00,957 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,957 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:00,959 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,960 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,984 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,990 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,990 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,992 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,992 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:00,992 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:00,994 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:00,994 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:00,994 - INFO - Step 74: masking 74 neurons (total: 74)
2025-06-21 13:15:01,339 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,339 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:01,341 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,342 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,366 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,372 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,372 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,374 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,374 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,374 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,376 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:01,376 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:01,376 - INFO - Step 75: masking 75 neurons (total: 75)
2025-06-21 13:15:01,720 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,721 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:01,723 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,723 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,748 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,754 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,754 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,755 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,756 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:01,756 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:01,757 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:01,757 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:01,757 - INFO - Step 76: masking 76 neurons (total: 76)
2025-06-21 13:15:02,103 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,103 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:02,105 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,106 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,130 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,136 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,136 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,138 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,138 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,138 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,139 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:02,140 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:02,140 - INFO - Step 77: masking 77 neurons (total: 77)
2025-06-21 13:15:02,484 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,485 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:02,487 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,487 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,512 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,518 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,518 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,519 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,520 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,520 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,521 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:02,521 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:02,522 - INFO - Step 78: masking 78 neurons (total: 78)
2025-06-21 13:15:02,867 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,867 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:02,870 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,870 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,894 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,900 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,901 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,902 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,902 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:02,902 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:02,904 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:02,904 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:02,904 - INFO - Step 79: masking 79 neurons (total: 79)
2025-06-21 13:15:03,250 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,250 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:03,253 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,253 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,277 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,283 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,283 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,285 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,285 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,285 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,287 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:03,287 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:03,287 - INFO - Step 80: masking 80 neurons (total: 80)
2025-06-21 13:15:03,633 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,634 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:03,636 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,636 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,661 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,667 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,667 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,668 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,669 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:03,669 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:03,670 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:03,670 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:03,671 - INFO - Step 81: masking 81 neurons (total: 81)
2025-06-21 13:15:04,016 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,016 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:04,018 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,019 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,043 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,049 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,049 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,051 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,051 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,051 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,053 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:04,053 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:04,053 - INFO - Step 82: masking 82 neurons (total: 82)
2025-06-21 13:15:04,398 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,399 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:04,401 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,401 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,426 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,432 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,432 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,434 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,434 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,434 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,436 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:04,436 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:04,436 - INFO - Step 83: masking 83 neurons (total: 83)
2025-06-21 13:15:04,816 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,816 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:04,819 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,819 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,843 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,847 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:04,849 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,850 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,851 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,851 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:04,851 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:04,853 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:04,853 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:04,853 - INFO - Step 84: masking 84 neurons (total: 84)
2025-06-21 13:15:05,233 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,233 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:05,236 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,236 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,261 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,265 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:05,267 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,267 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,268 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,269 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,269 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,270 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:05,270 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:05,270 - INFO - Step 85: masking 85 neurons (total: 85)
2025-06-21 13:15:05,651 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,651 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:05,654 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,654 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,678 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,682 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:05,685 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,685 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,686 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,686 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:05,687 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:05,688 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:05,688 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:05,688 - INFO - Step 86: masking 86 neurons (total: 86)
2025-06-21 13:15:06,068 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,068 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:06,071 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,071 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,096 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,099 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:06,102 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,102 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,103 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,103 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,104 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,105 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:06,105 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:06,105 - INFO - Step 87: masking 87 neurons (total: 87)
2025-06-21 13:15:06,485 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,485 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:06,487 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,488 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,512 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,516 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:06,518 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,518 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,520 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,520 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,520 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,522 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:06,522 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:06,522 - INFO - Step 88: masking 88 neurons (total: 88)
2025-06-21 13:15:06,902 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,902 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:06,904 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,905 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,929 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,933 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:06,935 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,936 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,937 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,937 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:06,937 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:06,939 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:06,939 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:06,939 - INFO - Step 89: masking 89 neurons (total: 89)
2025-06-21 13:15:07,319 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,319 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:07,321 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,322 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,346 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,350 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:07,352 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,352 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,354 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,354 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,354 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,356 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:07,356 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:07,356 - INFO - Step 90: masking 90 neurons (total: 90)
2025-06-21 13:15:07,737 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,737 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:07,739 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,740 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,764 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,768 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:07,770 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,771 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,772 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,772 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:07,772 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:07,774 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:07,774 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:07,774 - INFO - Step 91: masking 91 neurons (total: 91)
2025-06-21 13:15:08,154 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,154 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:08,156 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,157 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,181 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,185 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:08,187 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,188 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,189 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,189 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,189 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,191 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:08,191 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:08,191 - INFO - Step 92: masking 92 neurons (total: 92)
2025-06-21 13:15:08,573 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,573 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:08,576 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,576 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,601 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,604 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:08,607 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,607 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,608 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,608 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,609 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,610 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:08,610 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:08,610 - INFO - Step 93: masking 93 neurons (total: 93)
2025-06-21 13:15:08,990 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:08,990 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:08,993 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:08,993 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,018 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,022 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:09,024 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,024 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,025 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,026 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,026 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,027 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:09,027 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:09,027 - INFO - Step 94: masking 94 neurons (total: 94)
2025-06-21 13:15:09,407 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,408 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:09,410 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,410 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,435 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,439 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:09,441 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,441 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,442 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,443 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,443 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,444 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:09,444 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:09,445 - INFO - Step 95: masking 95 neurons (total: 95)
2025-06-21 13:15:09,826 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,826 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:09,829 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,829 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,854 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,858 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:09,860 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,860 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,861 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,862 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:09,862 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:09,863 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:09,863 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:09,863 - INFO - Step 96: masking 96 neurons (total: 96)
2025-06-21 13:15:10,244 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,245 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:10,247 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,247 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,272 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,276 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:10,278 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,278 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,280 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,280 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,280 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,281 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:10,282 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:10,282 - INFO - Step 97: masking 97 neurons (total: 97)
2025-06-21 13:15:10,663 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,664 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:10,666 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,666 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,691 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,695 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:10,697 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,697 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,698 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,699 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:10,699 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:10,700 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:10,700 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:10,701 - INFO - Step 98: masking 98 neurons (total: 98)
2025-06-21 13:15:11,081 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,081 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:11,083 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,084 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,108 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,112 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:11,114 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,114 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,116 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,116 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,116 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,118 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:11,118 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:11,118 - INFO - Step 99: masking 99 neurons (total: 99)
2025-06-21 13:15:11,497 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,498 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:11,500 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,500 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,525 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,529 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:11,531 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,531 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,533 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,533 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,533 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,535 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:11,535 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:11,535 - INFO - Step 100: masking 100 neurons (total: 100)
2025-06-21 13:15:11,915 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,915 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:11,918 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,918 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,943 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,946 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:11,949 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,949 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,950 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,950 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:11,951 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:11,952 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:11,952 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:11,952 - INFO - Step 101: masking 101 neurons (total: 101)
2025-06-21 13:15:12,331 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,332 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:12,334 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,334 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,359 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,363 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:12,365 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,365 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,367 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,367 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,367 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,369 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:12,369 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:12,369 - INFO - Step 102: masking 102 neurons (total: 102)
2025-06-21 13:15:12,748 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,749 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:12,751 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,751 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,776 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,780 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:12,782 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,782 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,784 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,784 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:12,784 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:12,786 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:12,786 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:12,786 - INFO - Step 103: masking 103 neurons (total: 103)
2025-06-21 13:15:13,165 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,166 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:13,168 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,168 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,193 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,197 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:13,199 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,199 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,201 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,201 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,201 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,203 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:13,203 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:13,203 - INFO - Step 104: masking 104 neurons (total: 104)
2025-06-21 13:15:13,583 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,583 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:13,586 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,586 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,611 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,615 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:13,617 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,617 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,618 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,619 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:13,619 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:13,620 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:13,620 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:13,620 - INFO - Step 105: masking 105 neurons (total: 105)
2025-06-21 13:15:14,000 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,001 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:14,003 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,003 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,028 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,032 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:14,034 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,034 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,036 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,036 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,036 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,038 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:14,038 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:14,038 - INFO - Step 106: masking 106 neurons (total: 106)
2025-06-21 13:15:14,419 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,419 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:14,421 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,422 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,446 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,450 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:14,452 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,453 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,454 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,454 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,455 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,456 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:14,456 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:14,456 - INFO - Step 107: masking 107 neurons (total: 107)
2025-06-21 13:15:14,837 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,837 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:14,840 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,840 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,865 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,869 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:14,871 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,871 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,872 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,873 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:14,873 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:14,874 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:14,874 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:14,874 - INFO - Step 108: masking 108 neurons (total: 108)
2025-06-21 13:15:15,255 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,255 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:15,257 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,258 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,282 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,286 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:15,288 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,288 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,290 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,290 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,290 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,292 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:15,292 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:15,292 - INFO - Step 109: masking 109 neurons (total: 109)
2025-06-21 13:15:15,673 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,673 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:15,675 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,676 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,700 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,704 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:15,707 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,707 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,708 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,708 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:15,709 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:15,710 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:15,710 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:15,710 - INFO - Step 110: masking 110 neurons (total: 110)
2025-06-21 13:15:16,091 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,092 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:16,094 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,095 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,119 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,123 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:16,125 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,126 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,127 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,127 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,127 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,129 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:16,129 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:16,129 - INFO - Step 111: masking 111 neurons (total: 111)
2025-06-21 13:15:16,515 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,515 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:16,518 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,518 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,543 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,547 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:16,549 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,550 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,551 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,551 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,551 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,553 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:16,553 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:16,553 - INFO - Step 112: masking 112 neurons (total: 112)
2025-06-21 13:15:16,941 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,942 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:16,944 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,945 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,970 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,974 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:16,976 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,976 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,978 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,978 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:16,978 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:16,979 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:16,980 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:16,980 - INFO - Step 113: masking 113 neurons (total: 113)
2025-06-21 13:15:17,367 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,368 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:17,370 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,370 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,396 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,400 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:17,402 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,402 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,403 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,404 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,404 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,405 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:17,405 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:17,405 - INFO - Step 114: masking 114 neurons (total: 114)
2025-06-21 13:15:17,796 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,796 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:17,799 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,799 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,824 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,828 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:17,830 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,831 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,832 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,832 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:17,833 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:17,834 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:17,834 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:17,834 - INFO - Step 115: masking 115 neurons (total: 115)
2025-06-21 13:15:18,224 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,225 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:18,227 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,227 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,252 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,256 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:18,259 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,259 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,260 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,260 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,261 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,262 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:18,262 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:18,262 - INFO - Step 116: masking 116 neurons (total: 116)
2025-06-21 13:15:18,651 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,651 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:18,653 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,654 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,679 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,683 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:18,685 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,685 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,687 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,687 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:18,687 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:18,688 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:18,689 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:18,689 - INFO - Step 117: masking 117 neurons (total: 117)
2025-06-21 13:15:19,077 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,077 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:19,080 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,080 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,105 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,109 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:19,111 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,112 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,113 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,113 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,114 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,115 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:19,115 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:19,115 - INFO - Step 118: masking 118 neurons (total: 118)
2025-06-21 13:15:19,503 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,504 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:19,506 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,506 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,532 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,536 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:19,538 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,538 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,540 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,540 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,540 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,541 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:19,542 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:19,542 - INFO - Step 119: masking 119 neurons (total: 119)
2025-06-21 13:15:19,931 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,931 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:19,933 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,934 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,959 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,963 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:19,965 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,965 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,966 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,967 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:19,967 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:19,968 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:19,968 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:19,969 - INFO - Step 120: masking 120 neurons (total: 120)
2025-06-21 13:15:20,357 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,357 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:20,360 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,360 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,385 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,389 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:20,392 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,392 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,393 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,394 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,394 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,395 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:20,395 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:20,395 - INFO - Step 121: masking 121 neurons (total: 121)
2025-06-21 13:15:20,785 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,785 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:20,788 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,788 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,813 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,817 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:20,819 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,820 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,821 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,821 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:20,822 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:20,823 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:20,823 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:20,823 - INFO - Step 122: masking 122 neurons (total: 122)
2025-06-21 13:15:21,212 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,212 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:21,214 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,215 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,240 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,244 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:21,246 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,246 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,248 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,248 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,248 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,250 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:21,250 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:21,250 - INFO - Step 123: masking 123 neurons (total: 123)
2025-06-21 13:15:21,640 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,641 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:21,643 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,643 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,669 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,673 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:21,675 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,675 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,676 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,677 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:21,677 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:21,678 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:21,678 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:21,679 - INFO - Step 124: masking 124 neurons (total: 124)
2025-06-21 13:15:22,069 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,070 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:22,072 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,072 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,097 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,101 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:22,104 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,104 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,105 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,105 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,106 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,107 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:22,107 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:22,107 - INFO - Step 125: masking 125 neurons (total: 125)
2025-06-21 13:15:22,495 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,496 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:22,498 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,498 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,524 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,528 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:22,530 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,530 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,531 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,532 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,532 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,533 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:22,533 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:22,534 - INFO - Step 126: masking 126 neurons (total: 126)
2025-06-21 13:15:22,921 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,922 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:22,924 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,924 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,950 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,954 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:22,956 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,956 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,958 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,958 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:22,958 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:22,959 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:22,960 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:22,960 - INFO - Step 127: masking 127 neurons (total: 127)
2025-06-21 13:15:23,348 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,348 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:23,351 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,351 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,376 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,380 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:23,382 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,383 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,384 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,384 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,385 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,386 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:23,386 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:23,386 - INFO - Step 128: masking 128 neurons (total: 128)
2025-06-21 13:15:23,775 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,776 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:23,778 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,778 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,803 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,807 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:23,810 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,810 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,811 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,812 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:23,812 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:23,813 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:23,813 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:23,813 - INFO - Step 129: masking 129 neurons (total: 129)
2025-06-21 13:15:24,206 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,206 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:24,209 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,209 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,234 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,238 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:24,240 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,241 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,242 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,242 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,242 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,244 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:24,244 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:24,244 - INFO - Step 130: masking 130 neurons (total: 130)
2025-06-21 13:15:24,634 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,634 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:24,637 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,637 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,662 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,666 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:24,669 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,669 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,670 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,670 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:24,671 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:24,672 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:24,672 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:24,672 - INFO - Step 131: masking 131 neurons (total: 131)
2025-06-21 13:15:25,061 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,061 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:25,064 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,064 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,089 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,093 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:25,095 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,096 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,097 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,097 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,098 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,099 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:25,099 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:25,099 - INFO - Step 132: masking 132 neurons (total: 132)
2025-06-21 13:15:25,488 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,489 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:25,491 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,491 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,517 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,521 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:25,523 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,523 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,525 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,525 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,525 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,527 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:25,527 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:25,527 - INFO - Step 133: masking 133 neurons (total: 133)
2025-06-21 13:15:25,916 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,917 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:25,919 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,919 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,945 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,949 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:25,951 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,951 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,952 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,953 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:25,953 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:25,954 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:25,954 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:25,955 - INFO - Step 134: masking 134 neurons (total: 134)
2025-06-21 13:15:26,343 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,343 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:26,346 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,346 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,371 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,375 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:26,377 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,378 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,379 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,380 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,380 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,381 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:26,381 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:26,382 - INFO - Step 135: masking 135 neurons (total: 135)
2025-06-21 13:15:26,772 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,773 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:26,775 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,775 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,801 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,805 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:26,807 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,807 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,808 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,809 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:26,809 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:26,810 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:26,810 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:26,811 - INFO - Step 136: masking 136 neurons (total: 136)
2025-06-21 13:15:27,200 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,200 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:27,203 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,203 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,228 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,232 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:27,234 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,235 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,236 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,236 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,237 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,238 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:27,238 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:27,238 - INFO - Step 137: masking 137 neurons (total: 137)
2025-06-21 13:15:27,629 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,629 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:27,631 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,632 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,657 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,661 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:27,663 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,663 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,665 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,665 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:27,665 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:27,666 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:27,667 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:27,667 - INFO - Step 138: masking 138 neurons (total: 138)
2025-06-21 13:15:28,056 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,056 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:28,059 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,059 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,084 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,088 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:28,090 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,091 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,092 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,092 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,093 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,094 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:28,094 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:28,094 - INFO - Step 139: masking 139 neurons (total: 139)
2025-06-21 13:15:28,482 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,482 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:28,485 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,485 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,510 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,514 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:28,517 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,517 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,518 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,518 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,519 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,520 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:28,520 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:28,520 - INFO - Step 140: masking 140 neurons (total: 140)
2025-06-21 13:15:28,909 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,910 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:28,912 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,912 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,937 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,941 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:28,944 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,944 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,945 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,945 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:28,946 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:28,947 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:28,947 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:28,947 - INFO - Step 141: masking 141 neurons (total: 141)
2025-06-21 13:15:29,335 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,336 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:29,338 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,338 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,363 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,367 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:29,370 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,370 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,371 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,371 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,372 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,373 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:29,373 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:29,373 - INFO - Step 142: masking 142 neurons (total: 142)
2025-06-21 13:15:29,762 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,763 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:29,765 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,765 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,790 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,795 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:29,797 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,797 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,798 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,799 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:29,799 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:29,800 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:29,800 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:29,800 - INFO - Step 143: masking 143 neurons (total: 143)
2025-06-21 13:15:30,188 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,189 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:30,191 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,191 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,216 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,220 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:30,223 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,223 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,224 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,224 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,225 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,226 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:30,226 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:30,226 - INFO - Step 144: masking 144 neurons (total: 144)
2025-06-21 13:15:30,617 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,617 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:30,619 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,620 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,645 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,649 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:30,651 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,651 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,653 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,653 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:30,653 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:30,655 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:30,655 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:30,655 - INFO - Step 145: masking 145 neurons (total: 145)
2025-06-21 13:15:31,043 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,044 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:31,046 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,047 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,071 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,075 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:31,077 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,077 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,079 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,079 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,079 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,081 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:31,081 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:31,081 - INFO - Step 146: masking 146 neurons (total: 146)
2025-06-21 13:15:31,460 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,461 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:31,463 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,463 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,488 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,492 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:31,494 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,494 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,496 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,496 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,496 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,497 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:31,498 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:31,498 - INFO - Step 147: masking 147 neurons (total: 147)
2025-06-21 13:15:31,877 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,877 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:31,880 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,880 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,905 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,909 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:31,911 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,911 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,912 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,913 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:31,913 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:31,914 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:31,914 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:31,915 - INFO - Step 148: masking 148 neurons (total: 148)
2025-06-21 13:15:32,294 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,295 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:32,297 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,297 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,322 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,326 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:32,328 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,328 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,330 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,330 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,330 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,331 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:32,332 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:32,332 - INFO - Step 149: masking 149 neurons (total: 149)
2025-06-21 13:15:32,710 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,711 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:32,713 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,713 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,738 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,742 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:32,744 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,744 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,745 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,746 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:32,746 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:32,747 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:32,747 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:32,748 - INFO - Step 150: masking 150 neurons (total: 150)
2025-06-21 13:15:33,126 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,127 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:33,129 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,129 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,154 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,158 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:33,160 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,160 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,162 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,162 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,162 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,164 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:33,164 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:33,164 - INFO - Step 151: masking 151 neurons (total: 151)
2025-06-21 13:15:33,543 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,544 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:33,546 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,546 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,571 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,575 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:33,577 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,578 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,579 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,579 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,579 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,581 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:33,581 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:33,581 - INFO - Step 152: masking 152 neurons (total: 152)
2025-06-21 13:15:33,960 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,961 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:33,963 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,963 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,988 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,992 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:33,994 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,994 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,996 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,996 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:33,996 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:33,998 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:33,998 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:33,998 - INFO - Step 153: masking 153 neurons (total: 153)
2025-06-21 13:15:34,377 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,377 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:34,380 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,380 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,405 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,409 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:34,411 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,411 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,413 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,413 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,413 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,415 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:34,415 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:34,415 - INFO - Step 154: masking 154 neurons (total: 154)
2025-06-21 13:15:34,795 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,795 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:34,798 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,798 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,823 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,827 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:34,829 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,829 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,830 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,831 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:34,831 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:34,832 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:34,832 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:34,832 - INFO - Step 155: masking 155 neurons (total: 155)
2025-06-21 13:15:35,211 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,212 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:35,214 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,214 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,239 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,243 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:35,245 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,245 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,247 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,247 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,247 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,248 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:35,249 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:35,249 - INFO - Step 156: masking 156 neurons (total: 156)
2025-06-21 13:15:35,629 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,629 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:35,631 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,632 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,656 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,660 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:35,662 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,662 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,664 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,664 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:35,664 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:35,666 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:35,666 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:35,666 - INFO - Step 157: masking 157 neurons (total: 157)
2025-06-21 13:15:36,045 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,045 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:36,048 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,048 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,072 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,076 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:36,078 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,079 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,080 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,080 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,081 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,082 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:36,082 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:36,082 - INFO - Step 158: masking 158 neurons (total: 158)
2025-06-21 13:15:36,462 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,463 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:36,465 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,465 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,490 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,494 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:36,496 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,496 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,498 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,498 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,498 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,500 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:36,500 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:36,500 - INFO - Step 159: masking 159 neurons (total: 159)
2025-06-21 13:15:36,879 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,880 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:36,882 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,882 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,907 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,911 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:36,913 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,913 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,915 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,915 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:36,915 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:36,917 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:36,917 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:36,917 - INFO - Step 160: masking 160 neurons (total: 160)
2025-06-21 13:15:37,296 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,296 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:37,299 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,299 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,324 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,328 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:37,330 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,330 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,331 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,332 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,332 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,333 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:37,333 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:37,334 - INFO - Step 161: masking 161 neurons (total: 161)
2025-06-21 13:15:37,713 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,713 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:37,716 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,716 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,740 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,744 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:37,746 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,747 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,748 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,748 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:37,748 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:37,750 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:37,750 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:37,750 - INFO - Step 162: masking 162 neurons (total: 162)
2025-06-21 13:15:38,129 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,130 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:38,132 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,132 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,157 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,161 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:38,163 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,163 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,165 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,165 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,165 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,167 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:38,167 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:38,167 - INFO - Step 163: masking 163 neurons (total: 163)
2025-06-21 13:15:38,547 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,548 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:38,550 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,550 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,575 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,579 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:38,581 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,581 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,582 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,583 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,583 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,584 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:38,584 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:38,584 - INFO - Step 164: masking 164 neurons (total: 164)
2025-06-21 13:15:38,964 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,964 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:38,967 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,967 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,992 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:38,995 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:38,998 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,998 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,999 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:38,999 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,000 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,001 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:39,001 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:39,001 - INFO - Step 165: masking 165 neurons (total: 165)
2025-06-21 13:15:39,381 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,381 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:39,384 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,384 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,409 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,413 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:39,415 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,415 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,416 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,417 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,417 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,418 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:39,418 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:39,418 - INFO - Step 166: masking 166 neurons (total: 166)
2025-06-21 13:15:39,799 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,799 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:39,802 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,802 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,826 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,830 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:39,833 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,833 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,834 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,834 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:39,835 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:39,836 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:39,836 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:39,836 - INFO - Step 167: masking 167 neurons (total: 167)
2025-06-21 13:15:40,215 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,216 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:40,218 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,218 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,243 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,247 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:40,249 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,249 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,251 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,251 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,251 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,252 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:40,253 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:40,253 - INFO - Step 168: masking 168 neurons (total: 168)
2025-06-21 13:15:40,633 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,633 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:40,636 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,636 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,660 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,664 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:40,667 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,667 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,668 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,668 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:40,669 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:40,670 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:40,670 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:40,670 - INFO - Step 169: masking 169 neurons (total: 169)
2025-06-21 13:15:41,051 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,052 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:41,054 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,054 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,079 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,083 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:41,085 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,085 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,087 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,087 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,087 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,088 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:41,089 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:41,089 - INFO - Step 170: masking 170 neurons (total: 170)
2025-06-21 13:15:41,469 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,469 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:41,472 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,472 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,497 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,501 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:41,503 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,503 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,504 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,505 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,505 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,506 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:41,506 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:41,506 - INFO - Step 171: masking 171 neurons (total: 171)
2025-06-21 13:15:41,887 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,887 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:41,890 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,890 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,915 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,919 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:41,921 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,921 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,922 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,923 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:41,923 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:41,924 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:41,924 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:41,925 - INFO - Step 172: masking 172 neurons (total: 172)
2025-06-21 13:15:42,305 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,305 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:42,308 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,308 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,333 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,337 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:42,339 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,339 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,340 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,341 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,341 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,342 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:42,342 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:42,343 - INFO - Step 173: masking 173 neurons (total: 173)
2025-06-21 13:15:42,723 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,723 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:42,726 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,726 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,751 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,754 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:42,757 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,757 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,758 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,758 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:42,759 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:42,760 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:42,760 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:42,760 - INFO - Step 174: masking 174 neurons (total: 174)
2025-06-21 13:15:43,140 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,141 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:43,143 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,144 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,168 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,172 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:43,174 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,174 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,176 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,176 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,176 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,178 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:43,178 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:43,178 - INFO - Step 175: masking 175 neurons (total: 175)
2025-06-21 13:15:43,558 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,558 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:43,561 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,561 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,585 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,589 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:43,592 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,592 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,593 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,593 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,594 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,595 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:43,595 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:43,595 - INFO - Step 176: masking 176 neurons (total: 176)
2025-06-21 13:15:43,975 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:43,975 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:43,977 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:43,978 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,002 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,006 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:44,008 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,009 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,010 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,010 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,010 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,012 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:44,012 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:44,012 - INFO - Step 177: masking 177 neurons (total: 177)
2025-06-21 13:15:44,391 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,392 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:44,394 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,394 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,419 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,423 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:44,425 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,425 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,426 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,427 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,427 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,428 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:44,428 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:44,429 - INFO - Step 178: masking 178 neurons (total: 178)
2025-06-21 13:15:44,808 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,809 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:44,811 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,811 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,836 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,840 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:44,842 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,842 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,844 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,844 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:44,844 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:44,845 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:44,846 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:44,846 - INFO - Step 179: masking 179 neurons (total: 179)
2025-06-21 13:15:45,225 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,225 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:45,227 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,228 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,252 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,256 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:45,258 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,258 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,260 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,260 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,260 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,262 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:45,262 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:45,262 - INFO - Step 180: masking 180 neurons (total: 180)
2025-06-21 13:15:45,641 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,641 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:45,644 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,644 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,668 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,672 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:45,675 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,675 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,676 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,677 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:45,677 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:45,678 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:45,678 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:45,678 - INFO - Step 181: masking 181 neurons (total: 181)
2025-06-21 13:15:46,058 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,059 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:46,061 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,062 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,086 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,090 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:46,092 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,092 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,094 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,094 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,094 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,096 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:46,096 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:46,096 - INFO - Step 182: masking 182 neurons (total: 182)
2025-06-21 13:15:46,476 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,476 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:46,478 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,479 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,503 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,507 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:46,509 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,510 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,511 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,511 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,511 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,513 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:46,513 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:46,513 - INFO - Step 183: masking 183 neurons (total: 183)
2025-06-21 13:15:46,892 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,893 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:46,895 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,895 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,920 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,924 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:46,926 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,926 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,927 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,928 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:46,928 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:46,929 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:46,929 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:46,929 - INFO - Step 184: masking 184 neurons (total: 184)
2025-06-21 13:15:47,309 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,310 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:47,312 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,312 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,337 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,341 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:47,343 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,343 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,344 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,345 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,345 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,346 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:47,346 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:47,347 - INFO - Step 185: masking 185 neurons (total: 185)
2025-06-21 13:15:47,727 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,727 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:47,729 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,730 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,754 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,758 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:47,760 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,760 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,762 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,762 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:47,762 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:47,764 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:47,764 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:47,764 - INFO - Step 186: masking 186 neurons (total: 186)
2025-06-21 13:15:48,143 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,143 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:48,146 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,146 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,171 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,174 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:48,177 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,177 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,178 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,178 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,179 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,180 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:48,180 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:48,180 - INFO - Step 187: masking 187 neurons (total: 187)
2025-06-21 13:15:48,560 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,561 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:48,563 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,563 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,588 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,592 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:48,594 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,594 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,595 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,596 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,596 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,597 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:48,597 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:48,598 - INFO - Step 188: masking 188 neurons (total: 188)
2025-06-21 13:15:48,977 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:48,977 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:48,980 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:48,980 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,005 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,009 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:49,011 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,011 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,012 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,013 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,013 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,014 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:49,014 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:49,014 - INFO - Step 189: masking 189 neurons (total: 189)
2025-06-21 13:15:49,395 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,395 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:49,397 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,398 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,422 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,426 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:49,429 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,429 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,430 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,430 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,431 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,432 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:49,432 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:49,432 - INFO - Step 190: masking 190 neurons (total: 190)
2025-06-21 13:15:49,812 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,813 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:49,815 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,815 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,840 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,844 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:49,846 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,846 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,848 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,848 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:49,848 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:49,849 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:49,850 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:49,850 - INFO - Step 191: masking 191 neurons (total: 191)
2025-06-21 13:15:50,231 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,231 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:50,233 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,234 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,258 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,262 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:50,264 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,264 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,266 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,266 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,266 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,268 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:50,268 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:50,268 - INFO - Step 192: masking 192 neurons (total: 192)
2025-06-21 13:15:50,648 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,649 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:50,651 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,652 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,676 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,680 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:50,682 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,682 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,684 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,684 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:50,684 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:50,686 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:50,686 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:50,686 - INFO - Step 193: masking 193 neurons (total: 193)
2025-06-21 13:15:51,065 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,066 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:51,068 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,068 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,093 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,097 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:51,099 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,099 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,101 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,101 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,101 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,103 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:51,103 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:51,103 - INFO - Step 194: masking 194 neurons (total: 194)
2025-06-21 13:15:51,483 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,483 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:51,486 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,486 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,511 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,514 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:51,517 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,517 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,518 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,519 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,519 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,520 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:51,520 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:51,521 - INFO - Step 195: masking 195 neurons (total: 195)
2025-06-21 13:15:51,901 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,901 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:51,904 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,904 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,929 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,932 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:51,935 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,935 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,936 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,936 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:51,937 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:51,938 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:51,938 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:51,938 - INFO - Step 196: masking 196 neurons (total: 196)
2025-06-21 13:15:52,318 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,319 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:52,321 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,321 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,346 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,350 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:52,352 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,352 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,354 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,354 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,354 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,356 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:52,356 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:52,356 - INFO - Step 197: masking 197 neurons (total: 197)
2025-06-21 13:15:52,736 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,736 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:52,738 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,739 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,763 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,767 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:52,769 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,769 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,771 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,771 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:52,771 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:52,773 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:52,773 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:52,773 - INFO - Step 198: masking 198 neurons (total: 198)
2025-06-21 13:15:53,153 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,153 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:53,155 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,156 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,180 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,184 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:53,186 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,187 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,188 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,188 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,188 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,190 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:53,190 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:53,190 - INFO - Step 199: masking 199 neurons (total: 199)
2025-06-21 13:15:53,571 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,571 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:53,574 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,574 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,599 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,603 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:53,605 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,605 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,606 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,607 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,607 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,608 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:53,608 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:53,609 - INFO - Step 200: masking 200 neurons (total: 200)
2025-06-21 13:15:53,989 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:53,989 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:53,991 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:53,992 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,016 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,020 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:54,022 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,023 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,024 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,024 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,025 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,026 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:54,026 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:54,026 - INFO - Step 201: masking 201 neurons (total: 201)
2025-06-21 13:15:54,407 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,408 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:54,410 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,410 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,435 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,439 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:54,441 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,441 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,443 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,443 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,443 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,445 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:54,445 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:54,445 - INFO - Step 202: masking 202 neurons (total: 202)
2025-06-21 13:15:54,827 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,828 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:54,830 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,830 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,855 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,859 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:54,861 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,861 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,863 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,863 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:54,863 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:54,864 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:54,865 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:54,865 - INFO - Step 203: masking 203 neurons (total: 203)
2025-06-21 13:15:55,244 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,244 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:55,247 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,247 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,271 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,275 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:55,277 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,278 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,279 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,279 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,280 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,281 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:55,281 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:55,281 - INFO - Step 204: masking 204 neurons (total: 204)
2025-06-21 13:15:55,663 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,663 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:55,666 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,666 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,691 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,694 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:55,697 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,697 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,698 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,698 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:55,699 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:55,700 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:55,700 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:55,700 - INFO - Step 205: masking 205 neurons (total: 205)
2025-06-21 13:15:56,080 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,080 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:56,083 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,083 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,107 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,111 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:56,113 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,114 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,115 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,115 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,116 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,117 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:56,117 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:56,117 - INFO - Step 206: masking 206 neurons (total: 206)
2025-06-21 13:15:56,498 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,498 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:56,501 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,501 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,526 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,530 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:56,532 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,532 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,533 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,534 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,534 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,535 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:56,535 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:56,535 - INFO - Step 207: masking 207 neurons (total: 207)
2025-06-21 13:15:56,915 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,915 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:56,917 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,918 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,942 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,946 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:56,948 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,948 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,950 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,950 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:56,950 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:56,952 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:56,952 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:56,952 - INFO - Step 208: masking 208 neurons (total: 208)
2025-06-21 13:15:57,332 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,333 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:57,335 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,335 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,360 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,364 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:57,366 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,366 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,368 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,368 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,368 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,369 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:57,370 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:57,370 - INFO - Step 209: masking 209 neurons (total: 209)
2025-06-21 13:15:57,750 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,750 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:57,752 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,753 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,777 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,781 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:57,783 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,783 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,785 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,785 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:57,785 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:57,787 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:57,787 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:57,787 - INFO - Step 210: masking 210 neurons (total: 210)
2025-06-21 13:15:58,167 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,167 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:58,169 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,170 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,194 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,198 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:58,200 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,201 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,202 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,202 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,202 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,204 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:58,204 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:58,204 - INFO - Step 211: masking 211 neurons (total: 211)
2025-06-21 13:15:58,584 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,585 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:58,587 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,587 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,612 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,616 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:58,618 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,618 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,619 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,620 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:58,620 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:58,621 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:58,621 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:58,622 - INFO - Step 212: masking 212 neurons (total: 212)
2025-06-21 13:15:59,001 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,002 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:59,004 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,004 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,029 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,033 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:59,035 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,035 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,037 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,037 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,037 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,038 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:59,039 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:59,039 - INFO - Step 213: masking 213 neurons (total: 213)
2025-06-21 13:15:59,418 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,418 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:59,420 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,421 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,445 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,449 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:59,451 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,451 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,453 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,453 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,453 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,455 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:59,455 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:59,455 - INFO - Step 214: masking 214 neurons (total: 214)
2025-06-21 13:15:59,835 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,835 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:59,837 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,838 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,862 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,866 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:15:59,868 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,869 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,870 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,870 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:15:59,870 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:15:59,872 - INFO - Masked perplexity: 45.6465
2025-06-21 13:15:59,872 - INFO - Magnitude increase: 0.0000
2025-06-21 13:15:59,872 - INFO - Step 215: masking 215 neurons (total: 215)
2025-06-21 13:16:00,251 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,252 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:00,254 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,254 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,279 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,283 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:00,285 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,285 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,286 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,287 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,287 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,288 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:00,288 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:00,289 - INFO - Step 216: masking 216 neurons (total: 216)
2025-06-21 13:16:00,668 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,669 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:00,671 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,671 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,696 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,700 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:00,702 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,702 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,704 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,704 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:00,704 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:00,705 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:00,706 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:00,706 - INFO - Step 217: masking 217 neurons (total: 217)
2025-06-21 13:16:01,085 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,086 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:01,088 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,088 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,113 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,117 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:01,119 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,119 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,121 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,121 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,121 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,122 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:01,123 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:01,123 - INFO - Step 218: masking 218 neurons (total: 218)
2025-06-21 13:16:01,503 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,503 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:01,506 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,506 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,531 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,535 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:01,537 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,537 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,538 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,539 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,539 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,540 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:01,540 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:01,540 - INFO - Step 219: masking 219 neurons (total: 219)
2025-06-21 13:16:01,920 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,921 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:01,923 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,923 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,948 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,952 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:01,954 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,954 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,956 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,956 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:01,956 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:01,958 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:01,958 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:01,958 - INFO - Step 220: masking 220 neurons (total: 220)
2025-06-21 13:16:02,338 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,338 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:02,341 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,341 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,365 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,369 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:02,372 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,372 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,373 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,373 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,374 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,375 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:02,375 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:02,375 - INFO - Step 221: masking 221 neurons (total: 221)
2025-06-21 13:16:02,755 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,755 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:02,758 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,758 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,783 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,787 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:02,789 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,789 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,790 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,791 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:02,791 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:02,792 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:02,792 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:02,792 - INFO - Step 222: masking 222 neurons (total: 222)
2025-06-21 13:16:03,172 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,172 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:03,174 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,175 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,199 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,203 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:03,205 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,205 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,207 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,207 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,207 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,209 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:03,209 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:03,209 - INFO - Step 223: masking 223 neurons (total: 223)
2025-06-21 13:16:03,623 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,623 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:03,626 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,626 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,647 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,651 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,655 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:03,657 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,657 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,658 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,659 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:03,659 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:03,660 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:03,660 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:03,661 - INFO - Step 224: masking 224 neurons (total: 224)
2025-06-21 13:16:04,075 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,075 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:04,077 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,078 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,098 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,102 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,106 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:04,108 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,109 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,110 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,110 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,110 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,112 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:04,112 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:04,112 - INFO - Step 225: masking 225 neurons (total: 225)
2025-06-21 13:16:04,526 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,526 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:04,529 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,529 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,550 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,554 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,558 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:04,560 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,560 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,561 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,562 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,562 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,563 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:04,563 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:04,563 - INFO - Step 226: masking 226 neurons (total: 226)
2025-06-21 13:16:04,977 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:04,978 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:04,980 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:04,980 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,001 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,005 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,009 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:05,011 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,011 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,013 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,013 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,013 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,015 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:05,015 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:05,015 - INFO - Step 227: masking 227 neurons (total: 227)
2025-06-21 13:16:05,428 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,429 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:05,431 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,431 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,452 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,456 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,460 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:05,462 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,462 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,464 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,464 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,464 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,466 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:05,466 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:05,466 - INFO - Step 228: masking 228 neurons (total: 228)
2025-06-21 13:16:05,883 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,884 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:05,886 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,886 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,908 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,912 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,916 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:05,918 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,919 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,920 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,920 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:05,920 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:05,922 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:05,922 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:05,922 - INFO - Step 229: masking 229 neurons (total: 229)
2025-06-21 13:16:06,345 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,346 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:06,348 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,348 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,370 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,374 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,378 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:06,380 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,380 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,381 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,382 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,382 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,383 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:06,383 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:06,384 - INFO - Step 230: masking 230 neurons (total: 230)
2025-06-21 13:16:06,807 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,807 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:06,809 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,810 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,831 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,835 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,839 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:06,841 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,841 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,843 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,843 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:06,843 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:06,845 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:06,845 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:06,845 - INFO - Step 231: masking 231 neurons (total: 231)
2025-06-21 13:16:07,267 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,267 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:07,270 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,270 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,291 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,295 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,299 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:07,302 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,302 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,303 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,304 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,304 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,305 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:07,305 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:07,305 - INFO - Step 232: masking 232 neurons (total: 232)
2025-06-21 13:16:07,732 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,733 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:07,735 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,735 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,757 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,760 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,764 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:07,767 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,767 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,768 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,769 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:07,769 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:07,770 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:07,770 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:07,770 - INFO - Step 233: masking 233 neurons (total: 233)
2025-06-21 13:16:08,192 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,193 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:08,195 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,195 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,217 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,221 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,225 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:08,227 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,227 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,228 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,229 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,229 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,230 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:08,230 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:08,231 - INFO - Step 234: masking 234 neurons (total: 234)
2025-06-21 13:16:08,655 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,655 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:08,658 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,658 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,679 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,683 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,687 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:08,690 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,690 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,691 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,691 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:08,692 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:08,693 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:08,693 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:08,693 - INFO - Step 235: masking 235 neurons (total: 235)
2025-06-21 13:16:09,115 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,116 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:09,118 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,118 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,140 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,144 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,148 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:09,150 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,150 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,152 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,152 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,152 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,153 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:09,154 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:09,154 - INFO - Step 236: masking 236 neurons (total: 236)
2025-06-21 13:16:09,576 - WARNING - Shape mismatch for model.layers.0.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,577 - WARNING - Shape mismatch for model.layers.0.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:09,579 - WARNING - Shape mismatch for model.layers.1.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,579 - WARNING - Shape mismatch for model.layers.1.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,601 - WARNING - Shape mismatch for model.layers.19.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,605 - WARNING - Shape mismatch for model.layers.22.self_attn.q_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,608 - WARNING - Shape mismatch for model.layers.25.self_attn.k_proj: output torch.Size([1, 115, 1024]), mask torch.Size([1, 1, 1024])
2025-06-21 13:16:09,611 - WARNING - Shape mismatch for model.layers.26.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,611 - WARNING - Shape mismatch for model.layers.26.mlp.act_fn: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,612 - WARNING - Shape mismatch for model.layers.27.mlp.gate_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,613 - WARNING - Shape mismatch for model.layers.27.mlp.up_proj: output torch.Size([1, 115, 8192]), mask torch.Size([1, 1, 8192])
2025-06-21 13:16:09,613 - WARNING - Shape mismatch for model.layers.27.mlp.down_proj: output torch.Size([1, 115, 3072]), mask torch.Size([1, 1, 3072])
2025-06-21 13:16:09,614 - INFO - Masked perplexity: 45.6465
2025-06-21 13:16:09,614 - INFO - Magnitude increase: 0.0000
2025-06-21 13:16:09,614 - INFO - Step 237: masking 237 neurons (total: 237)
2025-06-21 13:17:16,491 - INFO - === Progressive Neuron Masking Analyzer ===
2025-06-21 13:17:16,492 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-06-21 13:17:16,492 - INFO - Neuron file: ./neurons/llama_3b.json
2025-06-21 13:17:16,492 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:17:16,492 - INFO - Step size: 1
2025-06-21 13:17:16,492 - INFO - Max magnitude increase: 4.0
2025-06-21 13:17:16,492 - INFO - Random seed: 42
2025-06-21 13:17:16,492 - INFO - Device: cuda
2025-06-21 13:17:16,492 - INFO - Log file: ./log/llama_3b.log
2025-06-21 13:17:16,493 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct, using device: cuda
2025-06-21 13:18:07,226 - INFO - Model loading completed
2025-06-21 13:18:07,253 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-06-21 13:18:07,302 - INFO - Loaded 10000 neurons
2025-06-21 13:18:07,302 - INFO - Starting progressive neuron masking analysis
2025-06-21 13:18:07,302 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:18:07,302 - INFO - Step size: 1
2025-06-21 13:18:07,302 - INFO - Max magnitude increase: 4.0
2025-06-21 13:18:07,304 - INFO - Set up masking hooks for 62 target layers
2025-06-21 13:18:07,305 - INFO - Computing baseline perplexity
2025-06-21 13:18:08,182 - INFO - Baseline perplexity: 45.6465
2025-06-21 13:18:08,182 - INFO - Step 1: masking 1 neurons (total: 1)
2025-06-21 13:24:39,707 - INFO - === Progressive Neuron Masking Analyzer ===
2025-06-21 13:24:39,708 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-06-21 13:24:39,708 - INFO - Neuron file: ./neurons/llama_3b.json
2025-06-21 13:24:39,708 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:24:39,708 - INFO - Step size: 1
2025-06-21 13:24:39,708 - INFO - Max magnitude increase: 4.0
2025-06-21 13:24:39,708 - INFO - Random seed: 42
2025-06-21 13:24:39,708 - INFO - Device: cuda
2025-06-21 13:24:39,709 - INFO - Log file: ./log/llama_3b.log
2025-06-21 13:24:39,710 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct, using device: cuda
2025-06-21 13:25:26,318 - INFO - Model loading completed
2025-06-21 13:25:26,332 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-06-21 13:25:26,381 - INFO - Loaded 10000 neurons
2025-06-21 13:25:26,381 - INFO - Starting progressive neuron masking analysis
2025-06-21 13:25:26,382 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:25:26,382 - INFO - Step size: 1
2025-06-21 13:25:26,382 - INFO - Max magnitude increase: 4.0
2025-06-21 13:25:26,384 - INFO - Set up masking hooks for 62 target layers
2025-06-21 13:25:26,384 - INFO - Computing baseline perplexity
2025-06-21 13:25:27,172 - INFO - Baseline perplexity: 45.6465
2025-06-21 13:25:27,174 - INFO - Step 1: masking 1 neurons (total: 1)
2025-06-21 13:25:27,290 - INFO - Masked perplexity: 44.3996
2025-06-21 13:25:27,291 - INFO - Magnitude increase: -0.0120
2025-06-21 13:25:27,291 - INFO - Step 2: masking 2 neurons (total: 2)
2025-06-21 13:25:27,364 - INFO - Masked perplexity: 43.6594
2025-06-21 13:25:27,365 - INFO - Magnitude increase: -0.0193
2025-06-21 13:25:27,365 - INFO - Step 3: masking 3 neurons (total: 3)
2025-06-21 13:25:27,437 - INFO - Masked perplexity: 54.4928
2025-06-21 13:25:27,438 - INFO - Magnitude increase: 0.0769
2025-06-21 13:25:27,438 - INFO - Step 4: masking 4 neurons (total: 4)
2025-06-21 13:25:27,511 - INFO - Masked perplexity: 869713.8750
2025-06-21 13:25:27,511 - INFO - Magnitude increase: 4.2800
2025-06-21 13:25:27,511 - INFO - Stopping: magnitude increase (4.2800) >= threshold (4.0)
2025-06-21 13:25:27,511 - INFO - Saving results to ./result/llama_3b_mask_neuron.json
2025-06-21 13:27:39,901 - INFO - === Progressive Neuron Masking Analyzer ===
2025-06-21 13:27:39,901 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-06-21 13:27:39,901 - INFO - Neuron file: ./neurons/llama_3b.json
2025-06-21 13:27:39,901 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:27:39,901 - INFO - Step size: 1
2025-06-21 13:27:39,901 - INFO - Max magnitude increase: 4.0
2025-06-21 13:27:39,901 - INFO - Random seed: 42
2025-06-21 13:27:39,901 - INFO - Device: cuda
2025-06-21 13:27:39,901 - INFO - Log file: ./log/llama_3b.log
2025-06-21 13:27:39,902 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct, using device: cuda
2025-06-21 13:28:34,893 - INFO - Model loading completed
2025-06-21 13:28:34,917 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-06-21 13:28:34,968 - INFO - Loaded 10000 neurons
2025-06-21 13:28:34,969 - INFO - Starting progressive neuron masking analysis
2025-06-21 13:28:34,969 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-06-21 13:28:34,969 - INFO - Step size: 1
2025-06-21 13:28:34,969 - INFO - Max magnitude increase: 4.0
2025-06-21 13:28:34,971 - INFO - Set up masking hooks for 62 target layers
2025-06-21 13:28:34,971 - INFO - Computing baseline perplexity
2025-06-21 13:28:37,454 - INFO - Baseline perplexity: 45.6465
2025-06-21 13:28:37,455 - INFO - Step 1: masking 1 neurons (total: 1)
2025-06-21 13:28:37,571 - INFO - Masked perplexity: 44.3996
2025-06-21 13:28:37,571 - INFO - Magnitude increase: -0.0120
2025-06-21 13:28:37,571 - INFO - Step 2: masking 2 neurons (total: 2)
2025-06-21 13:28:37,644 - INFO - Masked perplexity: 43.6594
2025-06-21 13:28:37,644 - INFO - Magnitude increase: -0.0193
2025-06-21 13:28:37,644 - INFO - Step 3: masking 3 neurons (total: 3)
2025-06-21 13:28:37,716 - INFO - Masked perplexity: 54.4928
2025-06-21 13:28:37,716 - INFO - Magnitude increase: 0.0769
2025-06-21 13:28:37,716 - INFO - Step 4: masking 4 neurons (total: 4)
2025-06-21 13:28:37,788 - INFO - Masked perplexity: 869713.8750
2025-06-21 13:28:37,788 - INFO - Magnitude increase: 4.2800
2025-06-21 13:28:37,788 - INFO - Stopping: magnitude increase (4.2800) >= threshold (4.0)
2025-06-21 13:28:37,788 - INFO - Saving results to ./result/llama_3b_mask_neuron.json
2025-06-21 13:28:37,791 - INFO - Progressive masking analysis completed
2025-06-21 13:28:37,791 - INFO - Total steps: 4
2025-06-21 13:28:37,791 - INFO - Final masked neurons: 4
2025-06-21 13:28:37,792 - INFO - 
=== Masking Summary ===
2025-06-21 13:28:37,792 - INFO - Step 1: 1 neurons, perplexity: 44.3996, magnitude increase: -0.0120
2025-06-21 13:28:37,792 - INFO - Step 2: 2 neurons, perplexity: 43.6594, magnitude increase: -0.0193
2025-06-21 13:28:37,792 - INFO - Step 3: 3 neurons, perplexity: 54.4928, magnitude increase: 0.0769
2025-06-21 13:28:37,792 - INFO - Step 4: 4 neurons, perplexity: 869713.8750, magnitude increase: 4.2800
2025-06-21 13:28:37,792 - INFO - === Analysis Completed ===
2025-06-21 13:28:37,792 - INFO - Results saved to: ./result/llama_3b_mask_neuron.json
2025-06-21 13:28:37,792 - INFO - Log saved to: ./log/llama_3b.log
2025-07-15 16:32:33,763 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-07-15 16:32:33,786 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-07-15 16:32:33,786 - INFO - Neuron file: ./neurons/llama_3b.json
2025-07-15 16:32:33,786 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-07-15 16:32:33,786 - INFO - Step size: 1
2025-07-15 16:32:33,786 - INFO - Max magnitude increase: 4.0
2025-07-15 16:32:33,786 - INFO - Random seed: 42
2025-07-15 16:32:33,787 - INFO - Device: auto
2025-07-15 16:32:33,847 - INFO - Available GPUs: 1
2025-07-15 16:32:33,849 - INFO - Available GPUs: 1
2025-07-15 16:32:33,849 - INFO - Loading model with multi-GPU: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-07-15 16:32:33,850 - INFO - Transformers version: 4.52.4
2025-07-15 16:32:33,850 - INFO - PyTorch version: 2.6.0+cu124
2025-07-15 16:32:33,850 - INFO - CUDA available: True
2025-07-15 16:33:04,310 - INFO - Multi-GPU model loading completed
2025-07-15 16:33:04,310 - INFO - Model device allocation:
2025-07-15 16:33:04,310 - INFO -   : 0
2025-07-15 16:33:04,311 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-07-15 16:33:04,328 - INFO - Loaded 10000 neurons
2025-07-15 16:33:04,328 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-07-15 16:33:04,328 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-07-15 16:33:04,328 - INFO - Step size: 1
2025-07-15 16:33:04,328 - INFO - Max magnitude increase: 4.0
2025-07-15 16:33:04,328 - INFO - Using 1 GPUs
2025-07-15 16:33:04,331 - INFO - Set up storage hooks for 62 target layers across multiple GPUs
2025-07-15 16:33:04,331 - INFO - Computing baseline perplexity
2025-07-15 16:33:05,228 - INFO - Baseline perplexity: 45.6465
2025-07-15 16:33:05,230 - INFO - Step 1: masking 1 neurons (total: 1)
2025-07-15 16:33:05,269 - INFO - Successfully masked 1 neurons across 1 layers
2025-07-15 16:33:05,310 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,311 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,311 - INFO - Step 2: masking 2 neurons (total: 2)
2025-07-15 16:33:05,351 - INFO - Successfully masked 2 neurons across 1 layers
2025-07-15 16:33:05,392 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,392 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,393 - INFO - Step 3: masking 3 neurons (total: 3)
2025-07-15 16:33:05,433 - INFO - Successfully masked 3 neurons across 1 layers
2025-07-15 16:33:05,474 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,475 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,475 - INFO - Step 4: masking 4 neurons (total: 4)
2025-07-15 16:33:05,515 - INFO - Successfully masked 4 neurons across 1 layers
2025-07-15 16:33:05,556 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,556 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,557 - INFO - Step 5: masking 5 neurons (total: 5)
2025-07-15 16:33:05,596 - INFO - Successfully masked 5 neurons across 2 layers
2025-07-15 16:33:05,637 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,637 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,638 - INFO - Step 6: masking 6 neurons (total: 6)
2025-07-15 16:33:05,678 - INFO - Successfully masked 6 neurons across 2 layers
2025-07-15 16:33:05,720 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,720 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,721 - INFO - Step 7: masking 7 neurons (total: 7)
2025-07-15 16:33:05,761 - INFO - Successfully masked 7 neurons across 2 layers
2025-07-15 16:33:05,802 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,802 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,803 - INFO - Step 8: masking 8 neurons (total: 8)
2025-07-15 16:33:05,843 - INFO - Successfully masked 8 neurons across 2 layers
2025-07-15 16:33:05,884 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,884 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,885 - INFO - Step 9: masking 9 neurons (total: 9)
2025-07-15 16:33:05,925 - INFO - Successfully masked 9 neurons across 3 layers
2025-07-15 16:33:05,965 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:05,966 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:05,966 - INFO - Step 10: masking 10 neurons (total: 10)
2025-07-15 16:33:06,006 - INFO - Successfully masked 10 neurons across 3 layers
2025-07-15 16:33:06,047 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,047 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,048 - INFO - Step 11: masking 11 neurons (total: 11)
2025-07-15 16:33:06,088 - INFO - Successfully masked 11 neurons across 3 layers
2025-07-15 16:33:06,129 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,129 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,130 - INFO - Step 12: masking 12 neurons (total: 12)
2025-07-15 16:33:06,172 - INFO - Successfully masked 12 neurons across 4 layers
2025-07-15 16:33:06,215 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,215 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,216 - INFO - Step 13: masking 13 neurons (total: 13)
2025-07-15 16:33:06,257 - INFO - Successfully masked 13 neurons across 4 layers
2025-07-15 16:33:06,300 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,300 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,301 - INFO - Step 14: masking 14 neurons (total: 14)
2025-07-15 16:33:06,342 - INFO - Successfully masked 14 neurons across 5 layers
2025-07-15 16:33:06,385 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,385 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,386 - INFO - Step 15: masking 15 neurons (total: 15)
2025-07-15 16:33:06,427 - INFO - Successfully masked 15 neurons across 5 layers
2025-07-15 16:33:06,470 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,471 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,472 - INFO - Step 16: masking 16 neurons (total: 16)
2025-07-15 16:33:06,515 - INFO - Successfully masked 16 neurons across 5 layers
2025-07-15 16:33:06,558 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,558 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,559 - INFO - Step 17: masking 17 neurons (total: 17)
2025-07-15 16:33:06,602 - INFO - Successfully masked 17 neurons across 5 layers
2025-07-15 16:33:06,645 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,645 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,646 - INFO - Step 18: masking 18 neurons (total: 18)
2025-07-15 16:33:06,688 - INFO - Successfully masked 18 neurons across 5 layers
2025-07-15 16:33:06,730 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,731 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,732 - INFO - Step 19: masking 19 neurons (total: 19)
2025-07-15 16:33:06,775 - INFO - Successfully masked 19 neurons across 5 layers
2025-07-15 16:33:06,819 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,819 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,820 - INFO - Step 20: masking 20 neurons (total: 20)
2025-07-15 16:33:06,862 - INFO - Successfully masked 20 neurons across 5 layers
2025-07-15 16:33:06,904 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,905 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,905 - INFO - Step 21: masking 21 neurons (total: 21)
2025-07-15 16:33:06,947 - INFO - Successfully masked 21 neurons across 5 layers
2025-07-15 16:33:06,989 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:06,989 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:06,990 - INFO - Step 22: masking 22 neurons (total: 22)
2025-07-15 16:33:07,032 - INFO - Successfully masked 22 neurons across 6 layers
2025-07-15 16:33:07,075 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,075 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,076 - INFO - Step 23: masking 23 neurons (total: 23)
2025-07-15 16:33:07,118 - INFO - Successfully masked 23 neurons across 6 layers
2025-07-15 16:33:07,160 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,160 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,161 - INFO - Step 24: masking 24 neurons (total: 24)
2025-07-15 16:33:07,203 - INFO - Successfully masked 24 neurons across 6 layers
2025-07-15 16:33:07,246 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,246 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,247 - INFO - Step 25: masking 25 neurons (total: 25)
2025-07-15 16:33:07,289 - INFO - Successfully masked 25 neurons across 6 layers
2025-07-15 16:33:07,331 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,332 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,332 - INFO - Step 26: masking 26 neurons (total: 26)
2025-07-15 16:33:07,374 - INFO - Successfully masked 26 neurons across 6 layers
2025-07-15 16:33:07,417 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,417 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,418 - INFO - Step 27: masking 27 neurons (total: 27)
2025-07-15 16:33:07,460 - INFO - Successfully masked 27 neurons across 6 layers
2025-07-15 16:33:07,502 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,502 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,503 - INFO - Step 28: masking 28 neurons (total: 28)
2025-07-15 16:33:07,545 - INFO - Successfully masked 28 neurons across 6 layers
2025-07-15 16:33:07,588 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,588 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,589 - INFO - Step 29: masking 29 neurons (total: 29)
2025-07-15 16:33:07,631 - INFO - Successfully masked 29 neurons across 6 layers
2025-07-15 16:33:07,674 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,674 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,675 - INFO - Step 30: masking 30 neurons (total: 30)
2025-07-15 16:33:07,717 - INFO - Successfully masked 30 neurons across 6 layers
2025-07-15 16:33:07,760 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,760 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,761 - INFO - Step 31: masking 31 neurons (total: 31)
2025-07-15 16:33:07,803 - INFO - Successfully masked 31 neurons across 6 layers
2025-07-15 16:33:07,846 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,846 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,847 - INFO - Step 32: masking 32 neurons (total: 32)
2025-07-15 16:33:07,889 - INFO - Successfully masked 32 neurons across 6 layers
2025-07-15 16:33:07,932 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:07,932 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:07,933 - INFO - Step 33: masking 33 neurons (total: 33)
2025-07-15 16:33:07,975 - INFO - Successfully masked 33 neurons across 6 layers
2025-07-15 16:33:08,018 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,018 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,019 - INFO - Step 34: masking 34 neurons (total: 34)
2025-07-15 16:33:08,061 - INFO - Successfully masked 34 neurons across 6 layers
2025-07-15 16:33:08,104 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,104 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,105 - INFO - Step 35: masking 35 neurons (total: 35)
2025-07-15 16:33:08,147 - INFO - Successfully masked 35 neurons across 6 layers
2025-07-15 16:33:08,190 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,190 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,191 - INFO - Step 36: masking 36 neurons (total: 36)
2025-07-15 16:33:08,235 - INFO - Successfully masked 36 neurons across 6 layers
2025-07-15 16:33:08,277 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,277 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,278 - INFO - Step 37: masking 37 neurons (total: 37)
2025-07-15 16:33:08,320 - INFO - Successfully masked 37 neurons across 6 layers
2025-07-15 16:33:08,362 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,363 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,364 - INFO - Step 38: masking 38 neurons (total: 38)
2025-07-15 16:33:08,406 - INFO - Successfully masked 38 neurons across 6 layers
2025-07-15 16:33:08,448 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,449 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,450 - INFO - Step 39: masking 39 neurons (total: 39)
2025-07-15 16:33:08,493 - INFO - Successfully masked 39 neurons across 6 layers
2025-07-15 16:33:08,536 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,536 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,537 - INFO - Step 40: masking 40 neurons (total: 40)
2025-07-15 16:33:08,579 - INFO - Successfully masked 40 neurons across 6 layers
2025-07-15 16:33:08,621 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,622 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,623 - INFO - Step 41: masking 41 neurons (total: 41)
2025-07-15 16:33:08,664 - INFO - Successfully masked 41 neurons across 6 layers
2025-07-15 16:33:08,707 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,707 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,708 - INFO - Step 42: masking 42 neurons (total: 42)
2025-07-15 16:33:08,750 - INFO - Successfully masked 42 neurons across 6 layers
2025-07-15 16:33:08,792 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,793 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,793 - INFO - Step 43: masking 43 neurons (total: 43)
2025-07-15 16:33:08,836 - INFO - Successfully masked 43 neurons across 6 layers
2025-07-15 16:33:08,878 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,878 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,879 - INFO - Step 44: masking 44 neurons (total: 44)
2025-07-15 16:33:08,921 - INFO - Successfully masked 44 neurons across 6 layers
2025-07-15 16:33:08,963 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:08,963 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:08,964 - INFO - Step 45: masking 45 neurons (total: 45)
2025-07-15 16:33:09,006 - INFO - Successfully masked 45 neurons across 6 layers
2025-07-15 16:33:09,049 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,049 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,050 - INFO - Step 46: masking 46 neurons (total: 46)
2025-07-15 16:33:09,092 - INFO - Successfully masked 46 neurons across 6 layers
2025-07-15 16:33:09,134 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,134 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,135 - INFO - Step 47: masking 47 neurons (total: 47)
2025-07-15 16:33:09,177 - INFO - Successfully masked 47 neurons across 6 layers
2025-07-15 16:33:09,219 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,220 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,220 - INFO - Step 48: masking 48 neurons (total: 48)
2025-07-15 16:33:09,263 - INFO - Successfully masked 48 neurons across 6 layers
2025-07-15 16:33:09,305 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,305 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,306 - INFO - Step 49: masking 49 neurons (total: 49)
2025-07-15 16:33:09,348 - INFO - Successfully masked 49 neurons across 7 layers
2025-07-15 16:33:09,391 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,391 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,392 - INFO - Step 50: masking 50 neurons (total: 50)
2025-07-15 16:33:09,434 - INFO - Successfully masked 50 neurons across 8 layers
2025-07-15 16:33:09,476 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,476 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,477 - INFO - Step 51: masking 51 neurons (total: 51)
2025-07-15 16:33:09,519 - INFO - Successfully masked 51 neurons across 8 layers
2025-07-15 16:33:09,562 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,562 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,563 - INFO - Step 52: masking 52 neurons (total: 52)
2025-07-15 16:33:09,605 - INFO - Successfully masked 52 neurons across 8 layers
2025-07-15 16:33:09,647 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,648 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,648 - INFO - Step 53: masking 53 neurons (total: 53)
2025-07-15 16:33:09,691 - INFO - Successfully masked 53 neurons across 9 layers
2025-07-15 16:33:09,733 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,733 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,734 - INFO - Step 54: masking 54 neurons (total: 54)
2025-07-15 16:33:09,778 - INFO - Successfully masked 54 neurons across 10 layers
2025-07-15 16:33:09,819 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,820 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,821 - INFO - Step 55: masking 55 neurons (total: 55)
2025-07-15 16:33:09,862 - INFO - Successfully masked 55 neurons across 10 layers
2025-07-15 16:33:09,902 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,903 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,904 - INFO - Step 56: masking 56 neurons (total: 56)
2025-07-15 16:33:09,947 - INFO - Successfully masked 56 neurons across 10 layers
2025-07-15 16:33:09,990 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:09,990 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:09,991 - INFO - Step 57: masking 57 neurons (total: 57)
2025-07-15 16:33:10,034 - INFO - Successfully masked 57 neurons across 10 layers
2025-07-15 16:33:10,076 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,076 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,077 - INFO - Step 58: masking 58 neurons (total: 58)
2025-07-15 16:33:10,120 - INFO - Successfully masked 58 neurons across 10 layers
2025-07-15 16:33:10,162 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,162 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,163 - INFO - Step 59: masking 59 neurons (total: 59)
2025-07-15 16:33:10,204 - INFO - Successfully masked 59 neurons across 10 layers
2025-07-15 16:33:10,244 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,245 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,246 - INFO - Step 60: masking 60 neurons (total: 60)
2025-07-15 16:33:10,287 - INFO - Successfully masked 60 neurons across 10 layers
2025-07-15 16:33:10,327 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,328 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,328 - INFO - Step 61: masking 61 neurons (total: 61)
2025-07-15 16:33:10,369 - INFO - Successfully masked 61 neurons across 10 layers
2025-07-15 16:33:10,410 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,410 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,411 - INFO - Step 62: masking 62 neurons (total: 62)
2025-07-15 16:33:10,452 - INFO - Successfully masked 62 neurons across 10 layers
2025-07-15 16:33:10,493 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,493 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,494 - INFO - Step 63: masking 63 neurons (total: 63)
2025-07-15 16:33:10,535 - INFO - Successfully masked 63 neurons across 10 layers
2025-07-15 16:33:10,575 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,576 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,577 - INFO - Step 64: masking 64 neurons (total: 64)
2025-07-15 16:33:10,621 - INFO - Successfully masked 64 neurons across 10 layers
2025-07-15 16:33:10,663 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,664 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,665 - INFO - Step 65: masking 65 neurons (total: 65)
2025-07-15 16:33:10,708 - INFO - Successfully masked 65 neurons across 10 layers
2025-07-15 16:33:10,749 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,750 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,751 - INFO - Step 66: masking 66 neurons (total: 66)
2025-07-15 16:33:10,792 - INFO - Successfully masked 66 neurons across 10 layers
2025-07-15 16:33:10,832 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,832 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,833 - INFO - Step 67: masking 67 neurons (total: 67)
2025-07-15 16:33:10,874 - INFO - Successfully masked 67 neurons across 10 layers
2025-07-15 16:33:10,915 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,915 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,916 - INFO - Step 68: masking 68 neurons (total: 68)
2025-07-15 16:33:10,957 - INFO - Successfully masked 68 neurons across 10 layers
2025-07-15 16:33:10,997 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:10,998 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:10,998 - INFO - Step 69: masking 69 neurons (total: 69)
2025-07-15 16:33:11,039 - INFO - Successfully masked 69 neurons across 10 layers
2025-07-15 16:33:11,080 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,081 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,081 - INFO - Step 70: masking 70 neurons (total: 70)
2025-07-15 16:33:11,122 - INFO - Successfully masked 70 neurons across 10 layers
2025-07-15 16:33:11,163 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,163 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,164 - INFO - Step 71: masking 71 neurons (total: 71)
2025-07-15 16:33:11,205 - INFO - Successfully masked 71 neurons across 10 layers
2025-07-15 16:33:11,246 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,247 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,247 - INFO - Step 72: masking 72 neurons (total: 72)
2025-07-15 16:33:11,290 - INFO - Successfully masked 72 neurons across 10 layers
2025-07-15 16:33:11,333 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,334 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,335 - INFO - Step 73: masking 73 neurons (total: 73)
2025-07-15 16:33:11,377 - INFO - Successfully masked 73 neurons across 10 layers
2025-07-15 16:33:11,431 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,431 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,432 - INFO - Step 74: masking 74 neurons (total: 74)
2025-07-15 16:33:11,474 - INFO - Successfully masked 74 neurons across 10 layers
2025-07-15 16:33:11,516 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,516 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,517 - INFO - Step 75: masking 75 neurons (total: 75)
2025-07-15 16:33:11,559 - INFO - Successfully masked 75 neurons across 10 layers
2025-07-15 16:33:11,602 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,602 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,603 - INFO - Step 76: masking 76 neurons (total: 76)
2025-07-15 16:33:11,647 - INFO - Successfully masked 76 neurons across 10 layers
2025-07-15 16:33:11,690 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,690 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,691 - INFO - Step 77: masking 77 neurons (total: 77)
2025-07-15 16:33:11,732 - INFO - Successfully masked 77 neurons across 10 layers
2025-07-15 16:33:11,773 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,773 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,774 - INFO - Step 78: masking 78 neurons (total: 78)
2025-07-15 16:33:11,815 - INFO - Successfully masked 78 neurons across 10 layers
2025-07-15 16:33:11,856 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,857 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,857 - INFO - Step 79: masking 79 neurons (total: 79)
2025-07-15 16:33:11,899 - INFO - Successfully masked 79 neurons across 10 layers
2025-07-15 16:33:11,939 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:11,940 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:11,941 - INFO - Step 80: masking 80 neurons (total: 80)
2025-07-15 16:33:11,982 - INFO - Successfully masked 80 neurons across 10 layers
2025-07-15 16:33:12,023 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,023 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,024 - INFO - Step 81: masking 81 neurons (total: 81)
2025-07-15 16:33:12,065 - INFO - Successfully masked 81 neurons across 10 layers
2025-07-15 16:33:12,106 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,106 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,107 - INFO - Step 82: masking 82 neurons (total: 82)
2025-07-15 16:33:12,152 - INFO - Successfully masked 82 neurons across 10 layers
2025-07-15 16:33:12,194 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,194 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,196 - INFO - Step 83: masking 83 neurons (total: 83)
2025-07-15 16:33:12,241 - INFO - Successfully masked 83 neurons across 11 layers
2025-07-15 16:33:12,284 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,285 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,285 - INFO - Step 84: masking 84 neurons (total: 84)
2025-07-15 16:33:12,329 - INFO - Successfully masked 84 neurons across 11 layers
2025-07-15 16:33:12,372 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,372 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,373 - INFO - Step 85: masking 85 neurons (total: 85)
2025-07-15 16:33:12,417 - INFO - Successfully masked 85 neurons across 11 layers
2025-07-15 16:33:12,460 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,461 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,462 - INFO - Step 86: masking 86 neurons (total: 86)
2025-07-15 16:33:12,506 - INFO - Successfully masked 86 neurons across 11 layers
2025-07-15 16:33:12,548 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,548 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,549 - INFO - Step 87: masking 87 neurons (total: 87)
2025-07-15 16:33:12,591 - INFO - Successfully masked 87 neurons across 11 layers
2025-07-15 16:33:12,632 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,632 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,633 - INFO - Step 88: masking 88 neurons (total: 88)
2025-07-15 16:33:12,675 - INFO - Successfully masked 88 neurons across 11 layers
2025-07-15 16:33:12,716 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,717 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,718 - INFO - Step 89: masking 89 neurons (total: 89)
2025-07-15 16:33:12,759 - INFO - Successfully masked 89 neurons across 11 layers
2025-07-15 16:33:12,800 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,801 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,802 - INFO - Step 90: masking 90 neurons (total: 90)
2025-07-15 16:33:12,844 - INFO - Successfully masked 90 neurons across 11 layers
2025-07-15 16:33:12,885 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,886 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,886 - INFO - Step 91: masking 91 neurons (total: 91)
2025-07-15 16:33:12,928 - INFO - Successfully masked 91 neurons across 11 layers
2025-07-15 16:33:12,969 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:12,970 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:12,970 - INFO - Step 92: masking 92 neurons (total: 92)
2025-07-15 16:33:13,012 - INFO - Successfully masked 92 neurons across 11 layers
2025-07-15 16:33:13,054 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,054 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,055 - INFO - Step 93: masking 93 neurons (total: 93)
2025-07-15 16:33:13,097 - INFO - Successfully masked 93 neurons across 11 layers
2025-07-15 16:33:13,138 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,138 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,139 - INFO - Step 94: masking 94 neurons (total: 94)
2025-07-15 16:33:13,181 - INFO - Successfully masked 94 neurons across 11 layers
2025-07-15 16:33:13,222 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,223 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,224 - INFO - Step 95: masking 95 neurons (total: 95)
2025-07-15 16:33:13,266 - INFO - Successfully masked 95 neurons across 11 layers
2025-07-15 16:33:13,307 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,307 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,308 - INFO - Step 96: masking 96 neurons (total: 96)
2025-07-15 16:33:13,350 - INFO - Successfully masked 96 neurons across 11 layers
2025-07-15 16:33:13,391 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,391 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,392 - INFO - Step 97: masking 97 neurons (total: 97)
2025-07-15 16:33:13,434 - INFO - Successfully masked 97 neurons across 11 layers
2025-07-15 16:33:13,476 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,476 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,477 - INFO - Step 98: masking 98 neurons (total: 98)
2025-07-15 16:33:13,519 - INFO - Successfully masked 98 neurons across 11 layers
2025-07-15 16:33:13,560 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,560 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,561 - INFO - Step 99: masking 99 neurons (total: 99)
2025-07-15 16:33:13,603 - INFO - Successfully masked 99 neurons across 11 layers
2025-07-15 16:33:13,644 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,645 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,646 - INFO - Step 100: masking 100 neurons (total: 100)
2025-07-15 16:33:13,688 - INFO - Successfully masked 100 neurons across 11 layers
2025-07-15 16:33:13,729 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,729 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,730 - INFO - Step 101: masking 101 neurons (total: 101)
2025-07-15 16:33:13,772 - INFO - Successfully masked 101 neurons across 11 layers
2025-07-15 16:33:13,813 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,814 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,815 - INFO - Step 102: masking 102 neurons (total: 102)
2025-07-15 16:33:13,857 - INFO - Successfully masked 102 neurons across 11 layers
2025-07-15 16:33:13,898 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,898 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,899 - INFO - Step 103: masking 103 neurons (total: 103)
2025-07-15 16:33:13,943 - INFO - Successfully masked 103 neurons across 11 layers
2025-07-15 16:33:13,984 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:13,985 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:13,985 - INFO - Step 104: masking 104 neurons (total: 104)
2025-07-15 16:33:14,027 - INFO - Successfully masked 104 neurons across 11 layers
2025-07-15 16:33:14,068 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,068 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,069 - INFO - Step 105: masking 105 neurons (total: 105)
2025-07-15 16:33:14,111 - INFO - Successfully masked 105 neurons across 11 layers
2025-07-15 16:33:14,152 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,152 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,153 - INFO - Step 106: masking 106 neurons (total: 106)
2025-07-15 16:33:14,195 - INFO - Successfully masked 106 neurons across 11 layers
2025-07-15 16:33:14,236 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,236 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,237 - INFO - Step 107: masking 107 neurons (total: 107)
2025-07-15 16:33:14,279 - INFO - Successfully masked 107 neurons across 11 layers
2025-07-15 16:33:14,319 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,319 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,320 - INFO - Step 108: masking 108 neurons (total: 108)
2025-07-15 16:33:14,362 - INFO - Successfully masked 108 neurons across 11 layers
2025-07-15 16:33:14,403 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,403 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,404 - INFO - Step 109: masking 109 neurons (total: 109)
2025-07-15 16:33:14,446 - INFO - Successfully masked 109 neurons across 11 layers
2025-07-15 16:33:14,486 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,487 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,487 - INFO - Step 110: masking 110 neurons (total: 110)
2025-07-15 16:33:14,529 - INFO - Successfully masked 110 neurons across 11 layers
2025-07-15 16:33:14,570 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,571 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,571 - INFO - Step 111: masking 111 neurons (total: 111)
2025-07-15 16:33:14,613 - INFO - Successfully masked 111 neurons across 11 layers
2025-07-15 16:33:14,654 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,654 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,655 - INFO - Step 112: masking 112 neurons (total: 112)
2025-07-15 16:33:14,697 - INFO - Successfully masked 112 neurons across 11 layers
2025-07-15 16:33:14,738 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,738 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,739 - INFO - Step 113: masking 113 neurons (total: 113)
2025-07-15 16:33:14,783 - INFO - Successfully masked 113 neurons across 11 layers
2025-07-15 16:33:14,827 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,827 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,828 - INFO - Step 114: masking 114 neurons (total: 114)
2025-07-15 16:33:14,872 - INFO - Successfully masked 114 neurons across 11 layers
2025-07-15 16:33:14,915 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:14,915 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:14,916 - INFO - Step 115: masking 115 neurons (total: 115)
2025-07-15 16:33:14,960 - INFO - Successfully masked 115 neurons across 11 layers
2025-07-15 16:33:15,004 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,004 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,005 - INFO - Step 116: masking 116 neurons (total: 116)
2025-07-15 16:33:15,049 - INFO - Successfully masked 116 neurons across 11 layers
2025-07-15 16:33:15,092 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,093 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,094 - INFO - Step 117: masking 117 neurons (total: 117)
2025-07-15 16:33:15,138 - INFO - Successfully masked 117 neurons across 11 layers
2025-07-15 16:33:15,180 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,181 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,182 - INFO - Step 118: masking 118 neurons (total: 118)
2025-07-15 16:33:15,226 - INFO - Successfully masked 118 neurons across 11 layers
2025-07-15 16:33:15,269 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,269 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,271 - INFO - Step 119: masking 119 neurons (total: 119)
2025-07-15 16:33:15,314 - INFO - Successfully masked 119 neurons across 11 layers
2025-07-15 16:33:15,355 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,355 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,356 - INFO - Step 120: masking 120 neurons (total: 120)
2025-07-15 16:33:15,399 - INFO - Successfully masked 120 neurons across 11 layers
2025-07-15 16:33:15,439 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,439 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,440 - INFO - Step 121: masking 121 neurons (total: 121)
2025-07-15 16:33:15,483 - INFO - Successfully masked 121 neurons across 11 layers
2025-07-15 16:33:15,523 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,524 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,524 - INFO - Step 122: masking 122 neurons (total: 122)
2025-07-15 16:33:15,567 - INFO - Successfully masked 122 neurons across 11 layers
2025-07-15 16:33:15,607 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,608 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,609 - INFO - Step 123: masking 123 neurons (total: 123)
2025-07-15 16:33:15,651 - INFO - Successfully masked 123 neurons across 11 layers
2025-07-15 16:33:15,692 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,692 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,693 - INFO - Step 124: masking 124 neurons (total: 124)
2025-07-15 16:33:15,735 - INFO - Successfully masked 124 neurons across 11 layers
2025-07-15 16:33:15,776 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,777 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,777 - INFO - Step 125: masking 125 neurons (total: 125)
2025-07-15 16:33:15,820 - INFO - Successfully masked 125 neurons across 11 layers
2025-07-15 16:33:15,861 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,861 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,862 - INFO - Step 126: masking 126 neurons (total: 126)
2025-07-15 16:33:15,904 - INFO - Successfully masked 126 neurons across 11 layers
2025-07-15 16:33:15,945 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:15,945 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:15,946 - INFO - Step 127: masking 127 neurons (total: 127)
2025-07-15 16:33:15,992 - INFO - Successfully masked 127 neurons across 11 layers
2025-07-15 16:33:16,034 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,035 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,036 - INFO - Step 128: masking 128 neurons (total: 128)
2025-07-15 16:33:16,080 - INFO - Successfully masked 128 neurons across 11 layers
2025-07-15 16:33:16,122 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,122 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,123 - INFO - Step 129: masking 129 neurons (total: 129)
2025-07-15 16:33:16,167 - INFO - Successfully masked 129 neurons across 11 layers
2025-07-15 16:33:16,209 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,210 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,210 - INFO - Step 130: masking 130 neurons (total: 130)
2025-07-15 16:33:16,257 - INFO - Successfully masked 130 neurons across 11 layers
2025-07-15 16:33:16,300 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,300 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,301 - INFO - Step 131: masking 131 neurons (total: 131)
2025-07-15 16:33:16,345 - INFO - Successfully masked 131 neurons across 11 layers
2025-07-15 16:33:16,387 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,388 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,388 - INFO - Step 132: masking 132 neurons (total: 132)
2025-07-15 16:33:16,432 - INFO - Successfully masked 132 neurons across 11 layers
2025-07-15 16:33:16,475 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,475 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,476 - INFO - Step 133: masking 133 neurons (total: 133)
2025-07-15 16:33:16,520 - INFO - Successfully masked 133 neurons across 11 layers
2025-07-15 16:33:16,562 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,562 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,563 - INFO - Step 134: masking 134 neurons (total: 134)
2025-07-15 16:33:16,607 - INFO - Successfully masked 134 neurons across 11 layers
2025-07-15 16:33:16,649 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,650 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,651 - INFO - Step 135: masking 135 neurons (total: 135)
2025-07-15 16:33:16,695 - INFO - Successfully masked 135 neurons across 11 layers
2025-07-15 16:33:16,737 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,737 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,738 - INFO - Step 136: masking 136 neurons (total: 136)
2025-07-15 16:33:16,782 - INFO - Successfully masked 136 neurons across 11 layers
2025-07-15 16:33:16,824 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,825 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,826 - INFO - Step 137: masking 137 neurons (total: 137)
2025-07-15 16:33:16,870 - INFO - Successfully masked 137 neurons across 11 layers
2025-07-15 16:33:16,912 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:16,912 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:16,913 - INFO - Step 138: masking 138 neurons (total: 138)
2025-07-15 16:33:16,957 - INFO - Successfully masked 138 neurons across 11 layers
2025-07-15 16:33:16,999 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,000 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,001 - INFO - Step 139: masking 139 neurons (total: 139)
2025-07-15 16:33:17,045 - INFO - Successfully masked 139 neurons across 11 layers
2025-07-15 16:33:17,087 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,087 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,088 - INFO - Step 140: masking 140 neurons (total: 140)
2025-07-15 16:33:17,134 - INFO - Successfully masked 140 neurons across 11 layers
2025-07-15 16:33:17,176 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,176 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,177 - INFO - Step 141: masking 141 neurons (total: 141)
2025-07-15 16:33:17,221 - INFO - Successfully masked 141 neurons across 11 layers
2025-07-15 16:33:17,263 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,264 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,264 - INFO - Step 142: masking 142 neurons (total: 142)
2025-07-15 16:33:17,309 - INFO - Successfully masked 142 neurons across 11 layers
2025-07-15 16:33:17,351 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,351 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,352 - INFO - Step 143: masking 143 neurons (total: 143)
2025-07-15 16:33:17,396 - INFO - Successfully masked 143 neurons across 11 layers
2025-07-15 16:33:17,438 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,439 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,440 - INFO - Step 144: masking 144 neurons (total: 144)
2025-07-15 16:33:17,484 - INFO - Successfully masked 144 neurons across 11 layers
2025-07-15 16:33:17,526 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,527 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,528 - INFO - Step 145: masking 145 neurons (total: 145)
2025-07-15 16:33:17,572 - INFO - Successfully masked 145 neurons across 11 layers
2025-07-15 16:33:17,615 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,616 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,617 - INFO - Step 146: masking 146 neurons (total: 146)
2025-07-15 16:33:17,661 - INFO - Successfully masked 146 neurons across 11 layers
2025-07-15 16:33:17,703 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,703 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,704 - INFO - Step 147: masking 147 neurons (total: 147)
2025-07-15 16:33:17,748 - INFO - Successfully masked 147 neurons across 11 layers
2025-07-15 16:33:17,791 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,791 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,792 - INFO - Step 148: masking 148 neurons (total: 148)
2025-07-15 16:33:17,836 - INFO - Successfully masked 148 neurons across 11 layers
2025-07-15 16:33:17,878 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,878 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,879 - INFO - Step 149: masking 149 neurons (total: 149)
2025-07-15 16:33:17,923 - INFO - Successfully masked 149 neurons across 11 layers
2025-07-15 16:33:17,965 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:17,966 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:17,967 - INFO - Step 150: masking 150 neurons (total: 150)
2025-07-15 16:33:18,012 - INFO - Successfully masked 150 neurons across 11 layers
2025-07-15 16:33:18,054 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,054 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,055 - INFO - Step 151: masking 151 neurons (total: 151)
2025-07-15 16:33:18,099 - INFO - Successfully masked 151 neurons across 11 layers
2025-07-15 16:33:18,141 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,142 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,143 - INFO - Step 152: masking 152 neurons (total: 152)
2025-07-15 16:33:18,190 - INFO - Successfully masked 152 neurons across 11 layers
2025-07-15 16:33:18,234 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,234 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,235 - INFO - Step 153: masking 153 neurons (total: 153)
2025-07-15 16:33:18,280 - INFO - Successfully masked 153 neurons across 11 layers
2025-07-15 16:33:18,322 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,323 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,324 - INFO - Step 154: masking 154 neurons (total: 154)
2025-07-15 16:33:18,368 - INFO - Successfully masked 154 neurons across 11 layers
2025-07-15 16:33:18,411 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,411 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,412 - INFO - Step 155: masking 155 neurons (total: 155)
2025-07-15 16:33:18,457 - INFO - Successfully masked 155 neurons across 11 layers
2025-07-15 16:33:18,499 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,500 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,501 - INFO - Step 156: masking 156 neurons (total: 156)
2025-07-15 16:33:18,545 - INFO - Successfully masked 156 neurons across 11 layers
2025-07-15 16:33:18,589 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,589 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,590 - INFO - Step 157: masking 157 neurons (total: 157)
2025-07-15 16:33:18,636 - INFO - Successfully masked 157 neurons across 11 layers
2025-07-15 16:33:18,678 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,678 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,679 - INFO - Step 158: masking 158 neurons (total: 158)
2025-07-15 16:33:18,724 - INFO - Successfully masked 158 neurons across 11 layers
2025-07-15 16:33:18,766 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,766 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,767 - INFO - Step 159: masking 159 neurons (total: 159)
2025-07-15 16:33:18,811 - INFO - Successfully masked 159 neurons across 11 layers
2025-07-15 16:33:18,854 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,854 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,855 - INFO - Step 160: masking 160 neurons (total: 160)
2025-07-15 16:33:18,900 - INFO - Successfully masked 160 neurons across 11 layers
2025-07-15 16:33:18,942 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:18,943 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:18,944 - INFO - Step 161: masking 161 neurons (total: 161)
2025-07-15 16:33:18,989 - INFO - Successfully masked 161 neurons across 11 layers
2025-07-15 16:33:19,033 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,033 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,034 - INFO - Step 162: masking 162 neurons (total: 162)
2025-07-15 16:33:19,079 - INFO - Successfully masked 162 neurons across 11 layers
2025-07-15 16:33:19,122 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,122 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,123 - INFO - Step 163: masking 163 neurons (total: 163)
2025-07-15 16:33:19,168 - INFO - Successfully masked 163 neurons across 11 layers
2025-07-15 16:33:19,211 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,211 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,212 - INFO - Step 164: masking 164 neurons (total: 164)
2025-07-15 16:33:19,258 - INFO - Successfully masked 164 neurons across 11 layers
2025-07-15 16:33:19,300 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,301 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,302 - INFO - Step 165: masking 165 neurons (total: 165)
2025-07-15 16:33:19,348 - INFO - Successfully masked 165 neurons across 11 layers
2025-07-15 16:33:19,390 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,391 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,392 - INFO - Step 166: masking 166 neurons (total: 166)
2025-07-15 16:33:19,436 - INFO - Successfully masked 166 neurons across 11 layers
2025-07-15 16:33:19,478 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,479 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,480 - INFO - Step 167: masking 167 neurons (total: 167)
2025-07-15 16:33:19,524 - INFO - Successfully masked 167 neurons across 11 layers
2025-07-15 16:33:19,566 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,567 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,568 - INFO - Step 168: masking 168 neurons (total: 168)
2025-07-15 16:33:19,613 - INFO - Successfully masked 168 neurons across 11 layers
2025-07-15 16:33:19,655 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,655 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,656 - INFO - Step 169: masking 169 neurons (total: 169)
2025-07-15 16:33:19,701 - INFO - Successfully masked 169 neurons across 11 layers
2025-07-15 16:33:19,743 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,743 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,744 - INFO - Step 170: masking 170 neurons (total: 170)
2025-07-15 16:33:19,789 - INFO - Successfully masked 170 neurons across 11 layers
2025-07-15 16:33:19,831 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,831 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,832 - INFO - Step 171: masking 171 neurons (total: 171)
2025-07-15 16:33:19,877 - INFO - Successfully masked 171 neurons across 11 layers
2025-07-15 16:33:19,919 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:19,919 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:19,920 - INFO - Step 172: masking 172 neurons (total: 172)
2025-07-15 16:33:19,965 - INFO - Successfully masked 172 neurons across 11 layers
2025-07-15 16:33:20,007 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,008 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,009 - INFO - Step 173: masking 173 neurons (total: 173)
2025-07-15 16:33:20,054 - INFO - Successfully masked 173 neurons across 11 layers
2025-07-15 16:33:20,096 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,096 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,097 - INFO - Step 174: masking 174 neurons (total: 174)
2025-07-15 16:33:20,142 - INFO - Successfully masked 174 neurons across 11 layers
2025-07-15 16:33:20,184 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,185 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,185 - INFO - Step 175: masking 175 neurons (total: 175)
2025-07-15 16:33:20,230 - INFO - Successfully masked 175 neurons across 11 layers
2025-07-15 16:33:20,272 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,272 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,273 - INFO - Step 176: masking 176 neurons (total: 176)
2025-07-15 16:33:20,318 - INFO - Successfully masked 176 neurons across 11 layers
2025-07-15 16:33:20,360 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,361 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,362 - INFO - Step 177: masking 177 neurons (total: 177)
2025-07-15 16:33:20,408 - INFO - Successfully masked 177 neurons across 11 layers
2025-07-15 16:33:20,450 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,450 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,451 - INFO - Step 178: masking 178 neurons (total: 178)
2025-07-15 16:33:20,498 - INFO - Successfully masked 178 neurons across 11 layers
2025-07-15 16:33:20,541 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,541 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,542 - INFO - Step 179: masking 179 neurons (total: 179)
2025-07-15 16:33:20,587 - INFO - Successfully masked 179 neurons across 11 layers
2025-07-15 16:33:20,629 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,630 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,630 - INFO - Step 180: masking 180 neurons (total: 180)
2025-07-15 16:33:20,676 - INFO - Successfully masked 180 neurons across 11 layers
2025-07-15 16:33:20,718 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,719 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,719 - INFO - Step 181: masking 181 neurons (total: 181)
2025-07-15 16:33:20,765 - INFO - Successfully masked 181 neurons across 11 layers
2025-07-15 16:33:20,807 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,807 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,808 - INFO - Step 182: masking 182 neurons (total: 182)
2025-07-15 16:33:20,854 - INFO - Successfully masked 182 neurons across 11 layers
2025-07-15 16:33:20,896 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,896 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,897 - INFO - Step 183: masking 183 neurons (total: 183)
2025-07-15 16:33:20,943 - INFO - Successfully masked 183 neurons across 11 layers
2025-07-15 16:33:20,985 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:20,985 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:20,986 - INFO - Step 184: masking 184 neurons (total: 184)
2025-07-15 16:33:21,031 - INFO - Successfully masked 184 neurons across 11 layers
2025-07-15 16:33:21,074 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,074 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,075 - INFO - Step 185: masking 185 neurons (total: 185)
2025-07-15 16:33:21,120 - INFO - Successfully masked 185 neurons across 11 layers
2025-07-15 16:33:21,162 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,163 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,164 - INFO - Step 186: masking 186 neurons (total: 186)
2025-07-15 16:33:21,209 - INFO - Successfully masked 186 neurons across 11 layers
2025-07-15 16:33:21,251 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,251 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,252 - INFO - Step 187: masking 187 neurons (total: 187)
2025-07-15 16:33:21,298 - INFO - Successfully masked 187 neurons across 11 layers
2025-07-15 16:33:21,340 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,340 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,341 - INFO - Step 188: masking 188 neurons (total: 188)
2025-07-15 16:33:21,386 - INFO - Successfully masked 188 neurons across 11 layers
2025-07-15 16:33:21,444 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,445 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,445 - INFO - Step 189: masking 189 neurons (total: 189)
2025-07-15 16:33:21,490 - INFO - Successfully masked 189 neurons across 11 layers
2025-07-15 16:33:21,532 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,532 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,533 - INFO - Step 190: masking 190 neurons (total: 190)
2025-07-15 16:33:21,577 - INFO - Successfully masked 190 neurons across 11 layers
2025-07-15 16:33:21,620 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,620 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,621 - INFO - Step 191: masking 191 neurons (total: 191)
2025-07-15 16:33:21,665 - INFO - Successfully masked 191 neurons across 11 layers
2025-07-15 16:33:21,706 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,707 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,707 - INFO - Step 192: masking 192 neurons (total: 192)
2025-07-15 16:33:21,751 - INFO - Successfully masked 192 neurons across 11 layers
2025-07-15 16:33:21,792 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,792 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,793 - INFO - Step 193: masking 193 neurons (total: 193)
2025-07-15 16:33:21,837 - INFO - Successfully masked 193 neurons across 11 layers
2025-07-15 16:33:21,878 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,878 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,879 - INFO - Step 194: masking 194 neurons (total: 194)
2025-07-15 16:33:21,923 - INFO - Successfully masked 194 neurons across 11 layers
2025-07-15 16:33:21,967 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:21,968 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:21,968 - INFO - Step 195: masking 195 neurons (total: 195)
2025-07-15 16:33:22,014 - INFO - Successfully masked 195 neurons across 11 layers
2025-07-15 16:33:22,057 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,057 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,058 - INFO - Step 196: masking 196 neurons (total: 196)
2025-07-15 16:33:22,104 - INFO - Successfully masked 196 neurons across 11 layers
2025-07-15 16:33:22,146 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,146 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,147 - INFO - Step 197: masking 197 neurons (total: 197)
2025-07-15 16:33:22,193 - INFO - Successfully masked 197 neurons across 11 layers
2025-07-15 16:33:22,235 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,236 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,236 - INFO - Step 198: masking 198 neurons (total: 198)
2025-07-15 16:33:22,282 - INFO - Successfully masked 198 neurons across 11 layers
2025-07-15 16:33:22,325 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,325 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,326 - INFO - Step 199: masking 199 neurons (total: 199)
2025-07-15 16:33:22,372 - INFO - Successfully masked 199 neurons across 11 layers
2025-07-15 16:33:22,414 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,414 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,415 - INFO - Step 200: masking 200 neurons (total: 200)
2025-07-15 16:33:22,461 - INFO - Successfully masked 200 neurons across 11 layers
2025-07-15 16:33:22,504 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,504 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,505 - INFO - Step 201: masking 201 neurons (total: 201)
2025-07-15 16:33:22,551 - INFO - Successfully masked 201 neurons across 11 layers
2025-07-15 16:33:22,593 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,593 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,594 - INFO - Step 202: masking 202 neurons (total: 202)
2025-07-15 16:33:22,640 - INFO - Successfully masked 202 neurons across 11 layers
2025-07-15 16:33:22,682 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,682 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,683 - INFO - Step 203: masking 203 neurons (total: 203)
2025-07-15 16:33:22,729 - INFO - Successfully masked 203 neurons across 11 layers
2025-07-15 16:33:22,771 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,771 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,772 - INFO - Step 204: masking 204 neurons (total: 204)
2025-07-15 16:33:22,818 - INFO - Successfully masked 204 neurons across 11 layers
2025-07-15 16:33:22,860 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,860 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,861 - INFO - Step 205: masking 205 neurons (total: 205)
2025-07-15 16:33:22,907 - INFO - Successfully masked 205 neurons across 11 layers
2025-07-15 16:33:22,949 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:22,949 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:22,950 - INFO - Step 206: masking 206 neurons (total: 206)
2025-07-15 16:33:22,997 - INFO - Successfully masked 206 neurons across 11 layers
2025-07-15 16:33:23,040 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,041 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,043 - INFO - Step 207: masking 207 neurons (total: 207)
2025-07-15 16:33:23,089 - INFO - Successfully masked 207 neurons across 11 layers
2025-07-15 16:33:23,132 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,133 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,133 - INFO - Step 208: masking 208 neurons (total: 208)
2025-07-15 16:33:23,180 - INFO - Successfully masked 208 neurons across 11 layers
2025-07-15 16:33:23,222 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,222 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,223 - INFO - Step 209: masking 209 neurons (total: 209)
2025-07-15 16:33:23,271 - INFO - Successfully masked 209 neurons across 11 layers
2025-07-15 16:33:23,313 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,314 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,314 - INFO - Step 210: masking 210 neurons (total: 210)
2025-07-15 16:33:23,360 - INFO - Successfully masked 210 neurons across 11 layers
2025-07-15 16:33:23,402 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,403 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,403 - INFO - Step 211: masking 211 neurons (total: 211)
2025-07-15 16:33:23,449 - INFO - Successfully masked 211 neurons across 11 layers
2025-07-15 16:33:23,492 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,492 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,493 - INFO - Step 212: masking 212 neurons (total: 212)
2025-07-15 16:33:23,539 - INFO - Successfully masked 212 neurons across 11 layers
2025-07-15 16:33:23,581 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,581 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,582 - INFO - Step 213: masking 213 neurons (total: 213)
2025-07-15 16:33:23,628 - INFO - Successfully masked 213 neurons across 11 layers
2025-07-15 16:33:23,671 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,671 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,672 - INFO - Step 214: masking 214 neurons (total: 214)
2025-07-15 16:33:23,718 - INFO - Successfully masked 214 neurons across 11 layers
2025-07-15 16:33:23,760 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,760 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,761 - INFO - Step 215: masking 215 neurons (total: 215)
2025-07-15 16:33:23,807 - INFO - Successfully masked 215 neurons across 11 layers
2025-07-15 16:33:23,849 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,850 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,851 - INFO - Step 216: masking 216 neurons (total: 216)
2025-07-15 16:33:23,897 - INFO - Successfully masked 216 neurons across 11 layers
2025-07-15 16:33:23,938 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:23,939 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:23,939 - INFO - Step 217: masking 217 neurons (total: 217)
2025-07-15 16:33:23,984 - INFO - Successfully masked 217 neurons across 11 layers
2025-07-15 16:33:24,024 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,025 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,025 - INFO - Step 218: masking 218 neurons (total: 218)
2025-07-15 16:33:24,070 - INFO - Successfully masked 218 neurons across 11 layers
2025-07-15 16:33:24,111 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,111 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,112 - INFO - Step 219: masking 219 neurons (total: 219)
2025-07-15 16:33:24,156 - INFO - Successfully masked 219 neurons across 11 layers
2025-07-15 16:33:24,197 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,197 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,198 - INFO - Step 220: masking 220 neurons (total: 220)
2025-07-15 16:33:24,243 - INFO - Successfully masked 220 neurons across 11 layers
2025-07-15 16:33:24,283 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,284 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,285 - INFO - Step 221: masking 221 neurons (total: 221)
2025-07-15 16:33:24,329 - INFO - Successfully masked 221 neurons across 11 layers
2025-07-15 16:33:24,370 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,370 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,371 - INFO - Step 222: masking 222 neurons (total: 222)
2025-07-15 16:33:24,415 - INFO - Successfully masked 222 neurons across 11 layers
2025-07-15 16:33:24,456 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,457 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,457 - INFO - Step 223: masking 223 neurons (total: 223)
2025-07-15 16:33:24,502 - INFO - Successfully masked 223 neurons across 12 layers
2025-07-15 16:33:24,543 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,543 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,544 - INFO - Step 224: masking 224 neurons (total: 224)
2025-07-15 16:33:24,588 - INFO - Successfully masked 224 neurons across 12 layers
2025-07-15 16:33:24,629 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,629 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,630 - INFO - Step 225: masking 225 neurons (total: 225)
2025-07-15 16:33:24,675 - INFO - Successfully masked 225 neurons across 12 layers
2025-07-15 16:33:24,715 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,716 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,717 - INFO - Step 226: masking 226 neurons (total: 226)
2025-07-15 16:33:24,761 - INFO - Successfully masked 226 neurons across 12 layers
2025-07-15 16:33:24,802 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,802 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,803 - INFO - Step 227: masking 227 neurons (total: 227)
2025-07-15 16:33:24,848 - INFO - Successfully masked 227 neurons across 12 layers
2025-07-15 16:33:24,888 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,889 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,890 - INFO - Step 228: masking 228 neurons (total: 228)
2025-07-15 16:33:24,938 - INFO - Successfully masked 228 neurons across 12 layers
2025-07-15 16:33:24,980 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:24,980 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:24,981 - INFO - Step 229: masking 229 neurons (total: 229)
2025-07-15 16:33:25,028 - INFO - Successfully masked 229 neurons across 12 layers
2025-07-15 16:33:25,070 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,070 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,071 - INFO - Step 230: masking 230 neurons (total: 230)
2025-07-15 16:33:25,117 - INFO - Successfully masked 230 neurons across 12 layers
2025-07-15 16:33:25,160 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,160 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,161 - INFO - Step 231: masking 231 neurons (total: 231)
2025-07-15 16:33:25,207 - INFO - Successfully masked 231 neurons across 12 layers
2025-07-15 16:33:25,249 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,250 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,250 - INFO - Step 232: masking 232 neurons (total: 232)
2025-07-15 16:33:25,296 - INFO - Successfully masked 232 neurons across 12 layers
2025-07-15 16:33:25,339 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,339 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,340 - INFO - Step 233: masking 233 neurons (total: 233)
2025-07-15 16:33:25,387 - INFO - Successfully masked 233 neurons across 12 layers
2025-07-15 16:33:25,429 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,429 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,430 - INFO - Step 234: masking 234 neurons (total: 234)
2025-07-15 16:33:25,477 - INFO - Successfully masked 234 neurons across 12 layers
2025-07-15 16:33:25,519 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,520 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,520 - INFO - Step 235: masking 235 neurons (total: 235)
2025-07-15 16:33:25,567 - INFO - Successfully masked 235 neurons across 12 layers
2025-07-15 16:33:25,610 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,610 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,611 - INFO - Step 236: masking 236 neurons (total: 236)
2025-07-15 16:33:25,657 - INFO - Successfully masked 236 neurons across 12 layers
2025-07-15 16:33:25,700 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,700 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,701 - INFO - Step 237: masking 237 neurons (total: 237)
2025-07-15 16:33:25,748 - INFO - Successfully masked 237 neurons across 12 layers
2025-07-15 16:33:25,790 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,791 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,791 - INFO - Step 238: masking 238 neurons (total: 238)
2025-07-15 16:33:25,838 - INFO - Successfully masked 238 neurons across 12 layers
2025-07-15 16:33:25,880 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,880 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,881 - INFO - Step 239: masking 239 neurons (total: 239)
2025-07-15 16:33:25,928 - INFO - Successfully masked 239 neurons across 12 layers
2025-07-15 16:33:25,970 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:25,970 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:25,972 - INFO - Step 240: masking 240 neurons (total: 240)
2025-07-15 16:33:26,020 - INFO - Successfully masked 240 neurons across 12 layers
2025-07-15 16:33:26,064 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,064 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,065 - INFO - Step 241: masking 241 neurons (total: 241)
2025-07-15 16:33:26,113 - INFO - Successfully masked 241 neurons across 12 layers
2025-07-15 16:33:26,156 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,156 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,157 - INFO - Step 242: masking 242 neurons (total: 242)
2025-07-15 16:33:26,205 - INFO - Successfully masked 242 neurons across 12 layers
2025-07-15 16:33:26,248 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,248 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,249 - INFO - Step 243: masking 243 neurons (total: 243)
2025-07-15 16:33:26,296 - INFO - Successfully masked 243 neurons across 12 layers
2025-07-15 16:33:26,338 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,339 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,340 - INFO - Step 244: masking 244 neurons (total: 244)
2025-07-15 16:33:26,387 - INFO - Successfully masked 244 neurons across 12 layers
2025-07-15 16:33:26,430 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,430 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,431 - INFO - Step 245: masking 245 neurons (total: 245)
2025-07-15 16:33:26,478 - INFO - Successfully masked 245 neurons across 12 layers
2025-07-15 16:33:26,521 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,521 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,522 - INFO - Step 246: masking 246 neurons (total: 246)
2025-07-15 16:33:26,569 - INFO - Successfully masked 246 neurons across 12 layers
2025-07-15 16:33:26,611 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,612 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,613 - INFO - Step 247: masking 247 neurons (total: 247)
2025-07-15 16:33:26,660 - INFO - Successfully masked 247 neurons across 12 layers
2025-07-15 16:33:26,702 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,703 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,704 - INFO - Step 248: masking 248 neurons (total: 248)
2025-07-15 16:33:26,751 - INFO - Successfully masked 248 neurons across 12 layers
2025-07-15 16:33:26,793 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,794 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,795 - INFO - Step 249: masking 249 neurons (total: 249)
2025-07-15 16:33:26,842 - INFO - Successfully masked 249 neurons across 12 layers
2025-07-15 16:33:26,884 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,885 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,886 - INFO - Step 250: masking 250 neurons (total: 250)
2025-07-15 16:33:26,933 - INFO - Successfully masked 250 neurons across 12 layers
2025-07-15 16:33:26,975 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:26,975 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:26,976 - INFO - Step 251: masking 251 neurons (total: 251)
2025-07-15 16:33:27,023 - INFO - Successfully masked 251 neurons across 12 layers
2025-07-15 16:33:27,066 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,066 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,067 - INFO - Step 252: masking 252 neurons (total: 252)
2025-07-15 16:33:27,115 - INFO - Successfully masked 252 neurons across 12 layers
2025-07-15 16:33:27,157 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,157 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,158 - INFO - Step 253: masking 253 neurons (total: 253)
2025-07-15 16:33:27,206 - INFO - Successfully masked 253 neurons across 12 layers
2025-07-15 16:33:27,248 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,248 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,249 - INFO - Step 254: masking 254 neurons (total: 254)
2025-07-15 16:33:27,297 - INFO - Successfully masked 254 neurons across 12 layers
2025-07-15 16:33:27,339 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,339 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,340 - INFO - Step 255: masking 255 neurons (total: 255)
2025-07-15 16:33:27,387 - INFO - Successfully masked 255 neurons across 12 layers
2025-07-15 16:33:27,430 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,430 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,431 - INFO - Step 256: masking 256 neurons (total: 256)
2025-07-15 16:33:27,478 - INFO - Successfully masked 256 neurons across 12 layers
2025-07-15 16:33:27,520 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,521 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,522 - INFO - Step 257: masking 257 neurons (total: 257)
2025-07-15 16:33:27,569 - INFO - Successfully masked 257 neurons across 12 layers
2025-07-15 16:33:27,612 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,612 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,613 - INFO - Step 258: masking 258 neurons (total: 258)
2025-07-15 16:33:27,660 - INFO - Successfully masked 258 neurons across 12 layers
2025-07-15 16:33:27,702 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,703 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,704 - INFO - Step 259: masking 259 neurons (total: 259)
2025-07-15 16:33:27,751 - INFO - Successfully masked 259 neurons across 12 layers
2025-07-15 16:33:27,793 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,794 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,795 - INFO - Step 260: masking 260 neurons (total: 260)
2025-07-15 16:33:27,842 - INFO - Successfully masked 260 neurons across 12 layers
2025-07-15 16:33:27,884 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,885 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,886 - INFO - Step 261: masking 261 neurons (total: 261)
2025-07-15 16:33:27,933 - INFO - Successfully masked 261 neurons across 12 layers
2025-07-15 16:33:27,977 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:27,977 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:27,978 - INFO - Step 262: masking 262 neurons (total: 262)
2025-07-15 16:33:28,026 - INFO - Successfully masked 262 neurons across 12 layers
2025-07-15 16:33:28,068 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,068 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,069 - INFO - Step 263: masking 263 neurons (total: 263)
2025-07-15 16:33:28,117 - INFO - Successfully masked 263 neurons across 12 layers
2025-07-15 16:33:28,159 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,160 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,160 - INFO - Step 264: masking 264 neurons (total: 264)
2025-07-15 16:33:28,208 - INFO - Successfully masked 264 neurons across 12 layers
2025-07-15 16:33:28,250 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,250 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,251 - INFO - Step 265: masking 265 neurons (total: 265)
2025-07-15 16:33:28,298 - INFO - Successfully masked 265 neurons across 12 layers
2025-07-15 16:33:28,341 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,341 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,342 - INFO - Step 266: masking 266 neurons (total: 266)
2025-07-15 16:33:28,390 - INFO - Successfully masked 266 neurons across 12 layers
2025-07-15 16:33:28,432 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,433 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,434 - INFO - Step 267: masking 267 neurons (total: 267)
2025-07-15 16:33:28,481 - INFO - Successfully masked 267 neurons across 12 layers
2025-07-15 16:33:28,523 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,524 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,525 - INFO - Step 268: masking 268 neurons (total: 268)
2025-07-15 16:33:28,573 - INFO - Successfully masked 268 neurons across 12 layers
2025-07-15 16:33:28,615 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,615 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,616 - INFO - Step 269: masking 269 neurons (total: 269)
2025-07-15 16:33:28,662 - INFO - Successfully masked 269 neurons across 12 layers
2025-07-15 16:33:28,702 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,703 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,704 - INFO - Step 270: masking 270 neurons (total: 270)
2025-07-15 16:33:28,749 - INFO - Successfully masked 270 neurons across 12 layers
2025-07-15 16:33:28,790 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,790 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,791 - INFO - Step 271: masking 271 neurons (total: 271)
2025-07-15 16:33:28,836 - INFO - Successfully masked 271 neurons across 12 layers
2025-07-15 16:33:28,877 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,877 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,879 - INFO - Step 272: masking 272 neurons (total: 272)
2025-07-15 16:33:28,927 - INFO - Successfully masked 272 neurons across 12 layers
2025-07-15 16:33:28,970 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:28,970 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:28,971 - INFO - Step 273: masking 273 neurons (total: 273)
2025-07-15 16:33:29,019 - INFO - Successfully masked 273 neurons across 12 layers
2025-07-15 16:33:29,061 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,062 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,063 - INFO - Step 274: masking 274 neurons (total: 274)
2025-07-15 16:33:29,110 - INFO - Successfully masked 274 neurons across 12 layers
2025-07-15 16:33:29,153 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,153 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,154 - INFO - Step 275: masking 275 neurons (total: 275)
2025-07-15 16:33:29,201 - INFO - Successfully masked 275 neurons across 12 layers
2025-07-15 16:33:29,244 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,244 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,245 - INFO - Step 276: masking 276 neurons (total: 276)
2025-07-15 16:33:29,293 - INFO - Successfully masked 276 neurons across 12 layers
2025-07-15 16:33:29,336 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,336 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,337 - INFO - Step 277: masking 277 neurons (total: 277)
2025-07-15 16:33:29,385 - INFO - Successfully masked 277 neurons across 12 layers
2025-07-15 16:33:29,429 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,429 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,430 - INFO - Step 278: masking 278 neurons (total: 278)
2025-07-15 16:33:29,477 - INFO - Successfully masked 278 neurons across 12 layers
2025-07-15 16:33:29,519 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,520 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,521 - INFO - Step 279: masking 279 neurons (total: 279)
2025-07-15 16:33:29,568 - INFO - Successfully masked 279 neurons across 12 layers
2025-07-15 16:33:29,610 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,611 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,611 - INFO - Step 280: masking 280 neurons (total: 280)
2025-07-15 16:33:29,661 - INFO - Successfully masked 280 neurons across 12 layers
2025-07-15 16:33:29,703 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,703 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,704 - INFO - Step 281: masking 281 neurons (total: 281)
2025-07-15 16:33:29,750 - INFO - Successfully masked 281 neurons across 12 layers
2025-07-15 16:33:29,790 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,791 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,791 - INFO - Step 282: masking 282 neurons (total: 282)
2025-07-15 16:33:29,837 - INFO - Successfully masked 282 neurons across 12 layers
2025-07-15 16:33:29,878 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,878 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,879 - INFO - Step 283: masking 283 neurons (total: 283)
2025-07-15 16:33:29,925 - INFO - Successfully masked 283 neurons across 12 layers
2025-07-15 16:33:29,965 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:29,966 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:29,966 - INFO - Step 284: masking 284 neurons (total: 284)
2025-07-15 16:33:30,012 - INFO - Successfully masked 284 neurons across 12 layers
2025-07-15 16:33:30,053 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,053 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,054 - INFO - Step 285: masking 285 neurons (total: 285)
2025-07-15 16:33:30,100 - INFO - Successfully masked 285 neurons across 12 layers
2025-07-15 16:33:30,142 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,142 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,143 - INFO - Step 286: masking 286 neurons (total: 286)
2025-07-15 16:33:30,189 - INFO - Successfully masked 286 neurons across 12 layers
2025-07-15 16:33:30,230 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,230 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,231 - INFO - Step 287: masking 287 neurons (total: 287)
2025-07-15 16:33:30,277 - INFO - Successfully masked 287 neurons across 12 layers
2025-07-15 16:33:30,318 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,318 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,319 - INFO - Step 288: masking 288 neurons (total: 288)
2025-07-15 16:33:30,369 - INFO - Successfully masked 288 neurons across 12 layers
2025-07-15 16:33:30,411 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,412 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,413 - INFO - Step 289: masking 289 neurons (total: 289)
2025-07-15 16:33:30,460 - INFO - Successfully masked 289 neurons across 13 layers
2025-07-15 16:33:30,503 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,503 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,504 - INFO - Step 290: masking 290 neurons (total: 290)
2025-07-15 16:33:30,552 - INFO - Successfully masked 290 neurons across 13 layers
2025-07-15 16:33:30,596 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,596 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,597 - INFO - Step 291: masking 291 neurons (total: 291)
2025-07-15 16:33:30,645 - INFO - Successfully masked 291 neurons across 13 layers
2025-07-15 16:33:30,688 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,688 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,689 - INFO - Step 292: masking 292 neurons (total: 292)
2025-07-15 16:33:30,737 - INFO - Successfully masked 292 neurons across 13 layers
2025-07-15 16:33:30,779 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,780 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,781 - INFO - Step 293: masking 293 neurons (total: 293)
2025-07-15 16:33:30,829 - INFO - Successfully masked 293 neurons across 13 layers
2025-07-15 16:33:30,871 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,871 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,872 - INFO - Step 294: masking 294 neurons (total: 294)
2025-07-15 16:33:30,920 - INFO - Successfully masked 294 neurons across 13 layers
2025-07-15 16:33:30,963 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:30,963 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:30,964 - INFO - Step 295: masking 295 neurons (total: 295)
2025-07-15 16:33:31,012 - INFO - Successfully masked 295 neurons across 13 layers
2025-07-15 16:33:31,054 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,055 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,056 - INFO - Step 296: masking 296 neurons (total: 296)
2025-07-15 16:33:31,104 - INFO - Successfully masked 296 neurons across 13 layers
2025-07-15 16:33:31,146 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,146 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,147 - INFO - Step 297: masking 297 neurons (total: 297)
2025-07-15 16:33:31,195 - INFO - Successfully masked 297 neurons across 13 layers
2025-07-15 16:33:31,237 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,237 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,238 - INFO - Step 298: masking 298 neurons (total: 298)
2025-07-15 16:33:31,287 - INFO - Successfully masked 298 neurons across 13 layers
2025-07-15 16:33:31,330 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,330 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,331 - INFO - Step 299: masking 299 neurons (total: 299)
2025-07-15 16:33:31,377 - INFO - Successfully masked 299 neurons across 13 layers
2025-07-15 16:33:31,418 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,419 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,420 - INFO - Step 300: masking 300 neurons (total: 300)
2025-07-15 16:33:31,466 - INFO - Successfully masked 300 neurons across 13 layers
2025-07-15 16:33:31,507 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,507 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,509 - INFO - Step 301: masking 301 neurons (total: 301)
2025-07-15 16:33:31,558 - INFO - Successfully masked 301 neurons across 13 layers
2025-07-15 16:33:31,601 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,601 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,602 - INFO - Step 302: masking 302 neurons (total: 302)
2025-07-15 16:33:31,650 - INFO - Successfully masked 302 neurons across 13 layers
2025-07-15 16:33:31,693 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,693 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,694 - INFO - Step 303: masking 303 neurons (total: 303)
2025-07-15 16:33:31,742 - INFO - Successfully masked 303 neurons across 13 layers
2025-07-15 16:33:31,785 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,785 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,786 - INFO - Step 304: masking 304 neurons (total: 304)
2025-07-15 16:33:31,834 - INFO - Successfully masked 304 neurons across 13 layers
2025-07-15 16:33:31,876 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,877 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,878 - INFO - Step 305: masking 305 neurons (total: 305)
2025-07-15 16:33:31,926 - INFO - Successfully masked 305 neurons across 13 layers
2025-07-15 16:33:31,968 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:31,969 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:31,970 - INFO - Step 306: masking 306 neurons (total: 306)
2025-07-15 16:33:32,018 - INFO - Successfully masked 306 neurons across 13 layers
2025-07-15 16:33:32,061 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,062 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,063 - INFO - Step 307: masking 307 neurons (total: 307)
2025-07-15 16:33:32,112 - INFO - Successfully masked 307 neurons across 13 layers
2025-07-15 16:33:32,154 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,155 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,156 - INFO - Step 308: masking 308 neurons (total: 308)
2025-07-15 16:33:32,204 - INFO - Successfully masked 308 neurons across 13 layers
2025-07-15 16:33:32,246 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,247 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,248 - INFO - Step 309: masking 309 neurons (total: 309)
2025-07-15 16:33:32,296 - INFO - Successfully masked 309 neurons across 13 layers
2025-07-15 16:33:32,339 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,339 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,340 - INFO - Step 310: masking 310 neurons (total: 310)
2025-07-15 16:33:32,389 - INFO - Successfully masked 310 neurons across 13 layers
2025-07-15 16:33:32,431 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,431 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,432 - INFO - Step 311: masking 311 neurons (total: 311)
2025-07-15 16:33:32,481 - INFO - Successfully masked 311 neurons across 13 layers
2025-07-15 16:33:32,523 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,524 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,525 - INFO - Step 312: masking 312 neurons (total: 312)
2025-07-15 16:33:32,573 - INFO - Successfully masked 312 neurons across 13 layers
2025-07-15 16:33:32,615 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,616 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,617 - INFO - Step 313: masking 313 neurons (total: 313)
2025-07-15 16:33:32,665 - INFO - Successfully masked 313 neurons across 13 layers
2025-07-15 16:33:32,707 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,708 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,709 - INFO - Step 314: masking 314 neurons (total: 314)
2025-07-15 16:33:32,757 - INFO - Successfully masked 314 neurons across 13 layers
2025-07-15 16:33:32,800 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,800 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,801 - INFO - Step 315: masking 315 neurons (total: 315)
2025-07-15 16:33:32,849 - INFO - Successfully masked 315 neurons across 13 layers
2025-07-15 16:33:32,893 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,893 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,894 - INFO - Step 316: masking 316 neurons (total: 316)
2025-07-15 16:33:32,943 - INFO - Successfully masked 316 neurons across 13 layers
2025-07-15 16:33:32,987 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:32,987 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:32,988 - INFO - Step 317: masking 317 neurons (total: 317)
2025-07-15 16:33:33,037 - INFO - Successfully masked 317 neurons across 13 layers
2025-07-15 16:33:33,080 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,080 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,081 - INFO - Step 318: masking 318 neurons (total: 318)
2025-07-15 16:33:33,130 - INFO - Successfully masked 318 neurons across 13 layers
2025-07-15 16:33:33,172 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,173 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,174 - INFO - Step 319: masking 319 neurons (total: 319)
2025-07-15 16:33:33,222 - INFO - Successfully masked 319 neurons across 13 layers
2025-07-15 16:33:33,265 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,265 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,266 - INFO - Step 320: masking 320 neurons (total: 320)
2025-07-15 16:33:33,315 - INFO - Successfully masked 320 neurons across 13 layers
2025-07-15 16:33:33,357 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,358 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,359 - INFO - Step 321: masking 321 neurons (total: 321)
2025-07-15 16:33:33,407 - INFO - Successfully masked 321 neurons across 13 layers
2025-07-15 16:33:33,450 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,450 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,451 - INFO - Step 322: masking 322 neurons (total: 322)
2025-07-15 16:33:33,501 - INFO - Successfully masked 322 neurons across 13 layers
2025-07-15 16:33:33,544 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,544 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,545 - INFO - Step 323: masking 323 neurons (total: 323)
2025-07-15 16:33:33,594 - INFO - Successfully masked 323 neurons across 13 layers
2025-07-15 16:33:33,637 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,637 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,638 - INFO - Step 324: masking 324 neurons (total: 324)
2025-07-15 16:33:33,688 - INFO - Successfully masked 324 neurons across 13 layers
2025-07-15 16:33:33,731 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,732 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,732 - INFO - Step 325: masking 325 neurons (total: 325)
2025-07-15 16:33:33,781 - INFO - Successfully masked 325 neurons across 13 layers
2025-07-15 16:33:33,823 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,824 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,825 - INFO - Step 326: masking 326 neurons (total: 326)
2025-07-15 16:33:33,873 - INFO - Successfully masked 326 neurons across 13 layers
2025-07-15 16:33:33,915 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:33,915 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:33,916 - INFO - Step 327: masking 327 neurons (total: 327)
2025-07-15 16:33:33,965 - INFO - Successfully masked 327 neurons across 13 layers
2025-07-15 16:33:34,008 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,008 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,009 - INFO - Step 328: masking 328 neurons (total: 328)
2025-07-15 16:33:34,057 - INFO - Successfully masked 328 neurons across 13 layers
2025-07-15 16:33:34,100 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,100 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,101 - INFO - Step 329: masking 329 neurons (total: 329)
2025-07-15 16:33:34,151 - INFO - Successfully masked 329 neurons across 13 layers
2025-07-15 16:33:34,192 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,193 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,194 - INFO - Step 330: masking 330 neurons (total: 330)
2025-07-15 16:33:34,241 - INFO - Successfully masked 330 neurons across 13 layers
2025-07-15 16:33:34,281 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,282 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,283 - INFO - Step 331: masking 331 neurons (total: 331)
2025-07-15 16:33:34,330 - INFO - Successfully masked 331 neurons across 13 layers
2025-07-15 16:33:34,370 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,371 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,371 - INFO - Step 332: masking 332 neurons (total: 332)
2025-07-15 16:33:34,418 - INFO - Successfully masked 332 neurons across 13 layers
2025-07-15 16:33:34,459 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,460 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,460 - INFO - Step 333: masking 333 neurons (total: 333)
2025-07-15 16:33:34,507 - INFO - Successfully masked 333 neurons across 13 layers
2025-07-15 16:33:34,548 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,548 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,549 - INFO - Step 334: masking 334 neurons (total: 334)
2025-07-15 16:33:34,596 - INFO - Successfully masked 334 neurons across 13 layers
2025-07-15 16:33:34,637 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,637 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,638 - INFO - Step 335: masking 335 neurons (total: 335)
2025-07-15 16:33:34,685 - INFO - Successfully masked 335 neurons across 13 layers
2025-07-15 16:33:34,726 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,727 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,728 - INFO - Step 336: masking 336 neurons (total: 336)
2025-07-15 16:33:34,775 - INFO - Successfully masked 336 neurons across 13 layers
2025-07-15 16:33:34,816 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,816 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,817 - INFO - Step 337: masking 337 neurons (total: 337)
2025-07-15 16:33:34,864 - INFO - Successfully masked 337 neurons across 13 layers
2025-07-15 16:33:34,904 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,905 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:34,906 - INFO - Step 338: masking 338 neurons (total: 338)
2025-07-15 16:33:34,956 - INFO - Successfully masked 338 neurons across 13 layers
2025-07-15 16:33:34,999 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:34,999 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,000 - INFO - Step 339: masking 339 neurons (total: 339)
2025-07-15 16:33:35,049 - INFO - Successfully masked 339 neurons across 13 layers
2025-07-15 16:33:35,091 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,092 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,093 - INFO - Step 340: masking 340 neurons (total: 340)
2025-07-15 16:33:35,142 - INFO - Successfully masked 340 neurons across 13 layers
2025-07-15 16:33:35,184 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,185 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,186 - INFO - Step 341: masking 341 neurons (total: 341)
2025-07-15 16:33:35,233 - INFO - Successfully masked 341 neurons across 13 layers
2025-07-15 16:33:35,274 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,274 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,275 - INFO - Step 342: masking 342 neurons (total: 342)
2025-07-15 16:33:35,322 - INFO - Successfully masked 342 neurons across 13 layers
2025-07-15 16:33:35,363 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,363 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,364 - INFO - Step 343: masking 343 neurons (total: 343)
2025-07-15 16:33:35,411 - INFO - Successfully masked 343 neurons across 13 layers
2025-07-15 16:33:35,452 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,452 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,454 - INFO - Step 344: masking 344 neurons (total: 344)
2025-07-15 16:33:35,505 - INFO - Successfully masked 344 neurons across 13 layers
2025-07-15 16:33:35,548 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,548 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,549 - INFO - Step 345: masking 345 neurons (total: 345)
2025-07-15 16:33:35,599 - INFO - Successfully masked 345 neurons across 13 layers
2025-07-15 16:33:35,642 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,642 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,643 - INFO - Step 346: masking 346 neurons (total: 346)
2025-07-15 16:33:35,693 - INFO - Successfully masked 346 neurons across 14 layers
2025-07-15 16:33:35,735 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,735 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,736 - INFO - Step 347: masking 347 neurons (total: 347)
2025-07-15 16:33:35,786 - INFO - Successfully masked 347 neurons across 14 layers
2025-07-15 16:33:35,828 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,829 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,830 - INFO - Step 348: masking 348 neurons (total: 348)
2025-07-15 16:33:35,879 - INFO - Successfully masked 348 neurons across 14 layers
2025-07-15 16:33:35,922 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:35,922 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:35,923 - INFO - Step 349: masking 349 neurons (total: 349)
2025-07-15 16:33:35,972 - INFO - Successfully masked 349 neurons across 14 layers
2025-07-15 16:33:36,015 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,016 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,017 - INFO - Step 350: masking 350 neurons (total: 350)
2025-07-15 16:33:36,066 - INFO - Successfully masked 350 neurons across 14 layers
2025-07-15 16:33:36,109 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,109 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,110 - INFO - Step 351: masking 351 neurons (total: 351)
2025-07-15 16:33:36,159 - INFO - Successfully masked 351 neurons across 14 layers
2025-07-15 16:33:36,202 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,202 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,203 - INFO - Step 352: masking 352 neurons (total: 352)
2025-07-15 16:33:36,252 - INFO - Successfully masked 352 neurons across 14 layers
2025-07-15 16:33:36,297 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,297 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,298 - INFO - Step 353: masking 353 neurons (total: 353)
2025-07-15 16:33:36,347 - INFO - Successfully masked 353 neurons across 14 layers
2025-07-15 16:33:36,390 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,390 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,391 - INFO - Step 354: masking 354 neurons (total: 354)
2025-07-15 16:33:36,443 - INFO - Successfully masked 354 neurons across 14 layers
2025-07-15 16:33:36,486 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,486 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,487 - INFO - Step 355: masking 355 neurons (total: 355)
2025-07-15 16:33:36,537 - INFO - Successfully masked 355 neurons across 14 layers
2025-07-15 16:33:36,579 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,580 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,581 - INFO - Step 356: masking 356 neurons (total: 356)
2025-07-15 16:33:36,632 - INFO - Successfully masked 356 neurons across 14 layers
2025-07-15 16:33:36,675 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,675 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,676 - INFO - Step 357: masking 357 neurons (total: 357)
2025-07-15 16:33:36,725 - INFO - Successfully masked 357 neurons across 14 layers
2025-07-15 16:33:36,768 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,768 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,769 - INFO - Step 358: masking 358 neurons (total: 358)
2025-07-15 16:33:36,819 - INFO - Successfully masked 358 neurons across 14 layers
2025-07-15 16:33:36,861 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,862 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,863 - INFO - Step 359: masking 359 neurons (total: 359)
2025-07-15 16:33:36,912 - INFO - Successfully masked 359 neurons across 14 layers
2025-07-15 16:33:36,955 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:36,955 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:36,958 - INFO - Step 360: masking 360 neurons (total: 360)
2025-07-15 16:33:37,007 - INFO - Successfully masked 360 neurons across 14 layers
2025-07-15 16:33:37,050 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,050 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,051 - INFO - Step 361: masking 361 neurons (total: 361)
2025-07-15 16:33:37,101 - INFO - Successfully masked 361 neurons across 14 layers
2025-07-15 16:33:37,143 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,144 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,145 - INFO - Step 362: masking 362 neurons (total: 362)
2025-07-15 16:33:37,194 - INFO - Successfully masked 362 neurons across 14 layers
2025-07-15 16:33:37,237 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,237 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,238 - INFO - Step 363: masking 363 neurons (total: 363)
2025-07-15 16:33:37,289 - INFO - Successfully masked 363 neurons across 14 layers
2025-07-15 16:33:37,332 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,332 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,333 - INFO - Step 364: masking 364 neurons (total: 364)
2025-07-15 16:33:37,383 - INFO - Successfully masked 364 neurons across 14 layers
2025-07-15 16:33:37,425 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,425 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,426 - INFO - Step 365: masking 365 neurons (total: 365)
2025-07-15 16:33:37,476 - INFO - Successfully masked 365 neurons across 14 layers
2025-07-15 16:33:37,518 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,519 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,520 - INFO - Step 366: masking 366 neurons (total: 366)
2025-07-15 16:33:37,571 - INFO - Successfully masked 366 neurons across 14 layers
2025-07-15 16:33:37,614 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,614 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,615 - INFO - Step 367: masking 367 neurons (total: 367)
2025-07-15 16:33:37,665 - INFO - Successfully masked 367 neurons across 14 layers
2025-07-15 16:33:37,707 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,707 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,708 - INFO - Step 368: masking 368 neurons (total: 368)
2025-07-15 16:33:37,758 - INFO - Successfully masked 368 neurons across 14 layers
2025-07-15 16:33:37,800 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,800 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,801 - INFO - Step 369: masking 369 neurons (total: 369)
2025-07-15 16:33:37,851 - INFO - Successfully masked 369 neurons across 14 layers
2025-07-15 16:33:37,893 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,893 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,894 - INFO - Step 370: masking 370 neurons (total: 370)
2025-07-15 16:33:37,943 - INFO - Successfully masked 370 neurons across 14 layers
2025-07-15 16:33:37,986 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:37,986 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:37,987 - INFO - Step 371: masking 371 neurons (total: 371)
2025-07-15 16:33:38,037 - INFO - Successfully masked 371 neurons across 14 layers
2025-07-15 16:33:38,080 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,080 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,081 - INFO - Step 372: masking 372 neurons (total: 372)
2025-07-15 16:33:38,130 - INFO - Successfully masked 372 neurons across 14 layers
2025-07-15 16:33:38,172 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,173 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,174 - INFO - Step 373: masking 373 neurons (total: 373)
2025-07-15 16:33:38,223 - INFO - Successfully masked 373 neurons across 14 layers
2025-07-15 16:33:38,266 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,266 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,267 - INFO - Step 374: masking 374 neurons (total: 374)
2025-07-15 16:33:38,317 - INFO - Successfully masked 374 neurons across 14 layers
2025-07-15 16:33:38,359 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,359 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,360 - INFO - Step 375: masking 375 neurons (total: 375)
2025-07-15 16:33:38,410 - INFO - Successfully masked 375 neurons across 14 layers
2025-07-15 16:33:38,452 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,452 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,453 - INFO - Step 376: masking 376 neurons (total: 376)
2025-07-15 16:33:38,503 - INFO - Successfully masked 376 neurons across 14 layers
2025-07-15 16:33:38,545 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,546 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,546 - INFO - Step 377: masking 377 neurons (total: 377)
2025-07-15 16:33:38,596 - INFO - Successfully masked 377 neurons across 14 layers
2025-07-15 16:33:38,638 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,638 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,639 - INFO - Step 378: masking 378 neurons (total: 378)
2025-07-15 16:33:38,689 - INFO - Successfully masked 378 neurons across 14 layers
2025-07-15 16:33:38,731 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,731 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,732 - INFO - Step 379: masking 379 neurons (total: 379)
2025-07-15 16:33:38,781 - INFO - Successfully masked 379 neurons across 14 layers
2025-07-15 16:33:38,824 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,824 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,825 - INFO - Step 380: masking 380 neurons (total: 380)
2025-07-15 16:33:38,875 - INFO - Successfully masked 380 neurons across 14 layers
2025-07-15 16:33:38,917 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:38,917 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:38,918 - INFO - Step 381: masking 381 neurons (total: 381)
2025-07-15 16:33:38,968 - INFO - Successfully masked 381 neurons across 14 layers
2025-07-15 16:33:39,010 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,011 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,011 - INFO - Step 382: masking 382 neurons (total: 382)
2025-07-15 16:33:39,061 - INFO - Successfully masked 382 neurons across 14 layers
2025-07-15 16:33:39,104 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,105 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,106 - INFO - Step 383: masking 383 neurons (total: 383)
2025-07-15 16:33:39,155 - INFO - Successfully masked 383 neurons across 14 layers
2025-07-15 16:33:39,198 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,198 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,199 - INFO - Step 384: masking 384 neurons (total: 384)
2025-07-15 16:33:39,249 - INFO - Successfully masked 384 neurons across 14 layers
2025-07-15 16:33:39,291 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,291 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,292 - INFO - Step 385: masking 385 neurons (total: 385)
2025-07-15 16:33:39,342 - INFO - Successfully masked 385 neurons across 14 layers
2025-07-15 16:33:39,384 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,384 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,385 - INFO - Step 386: masking 386 neurons (total: 386)
2025-07-15 16:33:39,435 - INFO - Successfully masked 386 neurons across 14 layers
2025-07-15 16:33:39,478 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,478 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,479 - INFO - Step 387: masking 387 neurons (total: 387)
2025-07-15 16:33:39,534 - INFO - Successfully masked 387 neurons across 14 layers
2025-07-15 16:33:39,577 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,577 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,578 - INFO - Step 388: masking 388 neurons (total: 388)
2025-07-15 16:33:39,629 - INFO - Successfully masked 388 neurons across 14 layers
2025-07-15 16:33:39,671 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,671 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,672 - INFO - Step 389: masking 389 neurons (total: 389)
2025-07-15 16:33:39,722 - INFO - Successfully masked 389 neurons across 14 layers
2025-07-15 16:33:39,764 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,764 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:39,765 - INFO - Step 390: masking 390 neurons (total: 390)
2025-07-15 16:33:39,821 - INFO - Successfully masked 390 neurons across 14 layers
2025-07-15 16:33:39,864 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:39,865 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:40,368 - INFO - Step 391: masking 391 neurons (total: 391)
2025-07-15 16:33:40,831 - INFO - Successfully masked 391 neurons across 14 layers
2025-07-15 16:33:40,873 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:40,874 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:40,875 - INFO - Step 392: masking 392 neurons (total: 392)
2025-07-15 16:33:40,925 - INFO - Successfully masked 392 neurons across 14 layers
2025-07-15 16:33:40,967 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:40,968 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:40,969 - INFO - Step 393: masking 393 neurons (total: 393)
2025-07-15 16:33:41,019 - INFO - Successfully masked 393 neurons across 14 layers
2025-07-15 16:33:41,061 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:41,061 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:41,062 - INFO - Step 394: masking 394 neurons (total: 394)
2025-07-15 16:33:41,113 - INFO - Successfully masked 394 neurons across 14 layers
2025-07-15 16:33:41,156 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:41,156 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:41,157 - INFO - Step 395: masking 395 neurons (total: 395)
2025-07-15 16:33:41,208 - INFO - Successfully masked 395 neurons across 14 layers
2025-07-15 16:33:41,251 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:41,252 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:41,252 - INFO - Step 396: masking 396 neurons (total: 396)
2025-07-15 16:33:41,303 - INFO - Successfully masked 396 neurons across 14 layers
2025-07-15 16:33:41,345 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:41,346 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:41,349 - INFO - Step 397: masking 397 neurons (total: 397)
2025-07-15 16:33:41,890 - INFO - Successfully masked 397 neurons across 14 layers
2025-07-15 16:33:42,142 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:42,143 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:42,376 - INFO - Step 398: masking 398 neurons (total: 398)
2025-07-15 16:33:42,428 - INFO - Successfully masked 398 neurons across 14 layers
2025-07-15 16:33:42,471 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:42,471 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:42,472 - INFO - Step 399: masking 399 neurons (total: 399)
2025-07-15 16:33:42,524 - INFO - Successfully masked 399 neurons across 14 layers
2025-07-15 16:33:42,565 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:42,566 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:42,567 - INFO - Step 400: masking 400 neurons (total: 400)
2025-07-15 16:33:42,615 - INFO - Successfully masked 400 neurons across 14 layers
2025-07-15 16:33:42,656 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:42,656 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:42,657 - INFO - Step 401: masking 401 neurons (total: 401)
2025-07-15 16:33:42,706 - INFO - Successfully masked 401 neurons across 14 layers
2025-07-15 16:33:42,747 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:42,747 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:42,748 - INFO - Step 402: masking 402 neurons (total: 402)
2025-07-15 16:33:42,796 - INFO - Successfully masked 402 neurons across 14 layers
2025-07-15 16:33:42,837 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:42,837 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:42,838 - INFO - Step 403: masking 403 neurons (total: 403)
2025-07-15 16:33:42,887 - INFO - Successfully masked 403 neurons across 14 layers
2025-07-15 16:33:42,928 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:42,928 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:42,929 - INFO - Step 404: masking 404 neurons (total: 404)
2025-07-15 16:33:43,450 - INFO - Successfully masked 404 neurons across 14 layers
2025-07-15 16:33:43,708 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:43,708 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:43,937 - INFO - Step 405: masking 405 neurons (total: 405)
2025-07-15 16:33:43,989 - INFO - Successfully masked 405 neurons across 14 layers
2025-07-15 16:33:44,031 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:44,031 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:44,033 - INFO - Step 406: masking 406 neurons (total: 406)
2025-07-15 16:33:44,083 - INFO - Successfully masked 406 neurons across 14 layers
2025-07-15 16:33:44,126 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:44,126 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:44,127 - INFO - Step 407: masking 407 neurons (total: 407)
2025-07-15 16:33:44,177 - INFO - Successfully masked 407 neurons across 14 layers
2025-07-15 16:33:44,219 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:44,220 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:44,221 - INFO - Step 408: masking 408 neurons (total: 408)
2025-07-15 16:33:44,271 - INFO - Successfully masked 408 neurons across 14 layers
2025-07-15 16:33:44,314 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:44,314 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:44,315 - INFO - Step 409: masking 409 neurons (total: 409)
2025-07-15 16:33:44,365 - INFO - Successfully masked 409 neurons across 14 layers
2025-07-15 16:33:44,407 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:44,408 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:44,409 - INFO - Step 410: masking 410 neurons (total: 410)
2025-07-15 16:33:44,459 - INFO - Successfully masked 410 neurons across 14 layers
2025-07-15 16:33:44,502 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:44,503 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:44,504 - INFO - Step 411: masking 411 neurons (total: 411)
2025-07-15 16:33:44,992 - INFO - Successfully masked 411 neurons across 14 layers
2025-07-15 16:33:45,247 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:45,247 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:45,461 - INFO - Step 412: masking 412 neurons (total: 412)
2025-07-15 16:33:45,514 - INFO - Successfully masked 412 neurons across 14 layers
2025-07-15 16:33:45,556 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:45,556 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:45,557 - INFO - Step 413: masking 413 neurons (total: 413)
2025-07-15 16:33:45,606 - INFO - Successfully masked 413 neurons across 14 layers
2025-07-15 16:33:45,647 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:45,647 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:45,648 - INFO - Step 414: masking 414 neurons (total: 414)
2025-07-15 16:33:45,697 - INFO - Successfully masked 414 neurons across 14 layers
2025-07-15 16:33:45,738 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:45,738 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:45,739 - INFO - Step 415: masking 415 neurons (total: 415)
2025-07-15 16:33:45,788 - INFO - Successfully masked 415 neurons across 14 layers
2025-07-15 16:33:45,829 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:45,829 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:45,830 - INFO - Step 416: masking 416 neurons (total: 416)
2025-07-15 16:33:45,879 - INFO - Successfully masked 416 neurons across 14 layers
2025-07-15 16:33:45,920 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:45,921 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:45,921 - INFO - Step 417: masking 417 neurons (total: 417)
2025-07-15 16:33:45,970 - INFO - Successfully masked 417 neurons across 14 layers
2025-07-15 16:33:46,011 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:46,012 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:46,012 - INFO - Step 418: masking 418 neurons (total: 418)
2025-07-15 16:33:46,061 - INFO - Successfully masked 418 neurons across 14 layers
2025-07-15 16:33:46,102 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:46,102 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:46,103 - INFO - Step 419: masking 419 neurons (total: 419)
2025-07-15 16:33:46,153 - INFO - Successfully masked 419 neurons across 14 layers
2025-07-15 16:33:46,194 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:46,195 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:46,805 - INFO - Step 420: masking 420 neurons (total: 420)
2025-07-15 16:33:47,179 - INFO - Successfully masked 420 neurons across 14 layers
2025-07-15 16:33:47,222 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:47,222 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:47,223 - INFO - Step 421: masking 421 neurons (total: 421)
2025-07-15 16:33:47,275 - INFO - Successfully masked 421 neurons across 14 layers
2025-07-15 16:33:47,321 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:47,322 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:47,323 - INFO - Step 422: masking 422 neurons (total: 422)
2025-07-15 16:33:47,376 - INFO - Successfully masked 422 neurons across 14 layers
2025-07-15 16:33:47,420 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:47,420 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:47,421 - INFO - Step 423: masking 423 neurons (total: 423)
2025-07-15 16:33:47,474 - INFO - Successfully masked 423 neurons across 14 layers
2025-07-15 16:33:47,518 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:47,518 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:47,528 - INFO - Step 424: masking 424 neurons (total: 424)
2025-07-15 16:33:47,580 - INFO - Successfully masked 424 neurons across 14 layers
2025-07-15 16:33:47,623 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:47,623 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:47,624 - INFO - Step 425: masking 425 neurons (total: 425)
2025-07-15 16:33:47,675 - INFO - Successfully masked 425 neurons across 14 layers
2025-07-15 16:33:47,718 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:47,718 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:47,721 - INFO - Step 426: masking 426 neurons (total: 426)
2025-07-15 16:33:48,158 - INFO - Successfully masked 426 neurons across 14 layers
2025-07-15 16:33:48,531 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:48,532 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:48,731 - INFO - Step 427: masking 427 neurons (total: 427)
2025-07-15 16:33:48,784 - INFO - Successfully masked 427 neurons across 14 layers
2025-07-15 16:33:48,826 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:48,826 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:48,827 - INFO - Step 428: masking 428 neurons (total: 428)
2025-07-15 16:33:48,878 - INFO - Successfully masked 428 neurons across 14 layers
2025-07-15 16:33:48,920 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:48,920 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:48,921 - INFO - Step 429: masking 429 neurons (total: 429)
2025-07-15 16:33:48,973 - INFO - Successfully masked 429 neurons across 14 layers
2025-07-15 16:33:49,015 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:49,016 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:49,017 - INFO - Step 430: masking 430 neurons (total: 430)
2025-07-15 16:33:49,067 - INFO - Successfully masked 430 neurons across 14 layers
2025-07-15 16:33:49,110 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:49,110 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:49,111 - INFO - Step 431: masking 431 neurons (total: 431)
2025-07-15 16:33:49,162 - INFO - Successfully masked 431 neurons across 14 layers
2025-07-15 16:33:49,204 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:49,204 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:49,205 - INFO - Step 432: masking 432 neurons (total: 432)
2025-07-15 16:33:49,256 - INFO - Successfully masked 432 neurons across 14 layers
2025-07-15 16:33:49,298 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:49,299 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:49,299 - INFO - Step 433: masking 433 neurons (total: 433)
2025-07-15 16:33:49,350 - INFO - Successfully masked 433 neurons across 14 layers
2025-07-15 16:33:49,392 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:49,393 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:49,394 - INFO - Step 434: masking 434 neurons (total: 434)
2025-07-15 16:33:49,446 - INFO - Successfully masked 434 neurons across 14 layers
2025-07-15 16:33:49,487 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:49,487 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:49,489 - INFO - Step 435: masking 435 neurons (total: 435)
2025-07-15 16:33:50,036 - INFO - Successfully masked 435 neurons across 14 layers
2025-07-15 16:33:50,289 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:50,289 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:50,491 - INFO - Step 436: masking 436 neurons (total: 436)
2025-07-15 16:33:50,543 - INFO - Successfully masked 436 neurons across 14 layers
2025-07-15 16:33:50,586 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:50,586 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:50,587 - INFO - Step 437: masking 437 neurons (total: 437)
2025-07-15 16:33:50,638 - INFO - Successfully masked 437 neurons across 14 layers
2025-07-15 16:33:50,680 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:50,680 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:50,681 - INFO - Step 438: masking 438 neurons (total: 438)
2025-07-15 16:33:50,732 - INFO - Successfully masked 438 neurons across 14 layers
2025-07-15 16:33:50,774 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:50,774 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:50,775 - INFO - Step 439: masking 439 neurons (total: 439)
2025-07-15 16:33:50,826 - INFO - Successfully masked 439 neurons across 14 layers
2025-07-15 16:33:50,868 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:50,868 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:50,869 - INFO - Step 440: masking 440 neurons (total: 440)
2025-07-15 16:33:50,920 - INFO - Successfully masked 440 neurons across 14 layers
2025-07-15 16:33:50,962 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:50,963 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:50,964 - INFO - Step 441: masking 441 neurons (total: 441)
2025-07-15 16:33:51,015 - INFO - Successfully masked 441 neurons across 14 layers
2025-07-15 16:33:51,057 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:51,057 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:51,058 - INFO - Step 442: masking 442 neurons (total: 442)
2025-07-15 16:33:51,109 - INFO - Successfully masked 442 neurons across 14 layers
2025-07-15 16:33:51,150 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:51,151 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:51,623 - INFO - Step 443: masking 443 neurons (total: 443)
2025-07-15 16:33:52,130 - INFO - Successfully masked 443 neurons across 14 layers
2025-07-15 16:33:52,172 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,172 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,173 - INFO - Step 444: masking 444 neurons (total: 444)
2025-07-15 16:33:52,224 - INFO - Successfully masked 444 neurons across 14 layers
2025-07-15 16:33:52,267 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,267 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,269 - INFO - Step 445: masking 445 neurons (total: 445)
2025-07-15 16:33:52,320 - INFO - Successfully masked 445 neurons across 14 layers
2025-07-15 16:33:52,363 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,364 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,365 - INFO - Step 446: masking 446 neurons (total: 446)
2025-07-15 16:33:52,416 - INFO - Successfully masked 446 neurons across 14 layers
2025-07-15 16:33:52,461 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,461 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,462 - INFO - Step 447: masking 447 neurons (total: 447)
2025-07-15 16:33:52,514 - INFO - Successfully masked 447 neurons across 14 layers
2025-07-15 16:33:52,557 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,557 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,558 - INFO - Step 448: masking 448 neurons (total: 448)
2025-07-15 16:33:52,609 - INFO - Successfully masked 448 neurons across 14 layers
2025-07-15 16:33:52,651 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,652 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,653 - INFO - Step 449: masking 449 neurons (total: 449)
2025-07-15 16:33:52,704 - INFO - Successfully masked 449 neurons across 14 layers
2025-07-15 16:33:52,746 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,746 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,747 - INFO - Step 450: masking 450 neurons (total: 450)
2025-07-15 16:33:52,798 - INFO - Successfully masked 450 neurons across 14 layers
2025-07-15 16:33:52,840 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,840 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,841 - INFO - Step 451: masking 451 neurons (total: 451)
2025-07-15 16:33:52,892 - INFO - Successfully masked 451 neurons across 14 layers
2025-07-15 16:33:52,934 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:52,935 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:52,936 - INFO - Step 452: masking 452 neurons (total: 452)
2025-07-15 16:33:52,987 - INFO - Successfully masked 452 neurons across 14 layers
2025-07-15 16:33:53,029 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,029 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,030 - INFO - Step 453: masking 453 neurons (total: 453)
2025-07-15 16:33:53,082 - INFO - Successfully masked 453 neurons across 14 layers
2025-07-15 16:33:53,124 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,124 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,125 - INFO - Step 454: masking 454 neurons (total: 454)
2025-07-15 16:33:53,176 - INFO - Successfully masked 454 neurons across 14 layers
2025-07-15 16:33:53,218 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,218 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,219 - INFO - Step 455: masking 455 neurons (total: 455)
2025-07-15 16:33:53,271 - INFO - Successfully masked 455 neurons across 14 layers
2025-07-15 16:33:53,313 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,313 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,314 - INFO - Step 456: masking 456 neurons (total: 456)
2025-07-15 16:33:53,365 - INFO - Successfully masked 456 neurons across 14 layers
2025-07-15 16:33:53,407 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,408 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,408 - INFO - Step 457: masking 457 neurons (total: 457)
2025-07-15 16:33:53,460 - INFO - Successfully masked 457 neurons across 14 layers
2025-07-15 16:33:53,502 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,503 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,504 - INFO - Step 458: masking 458 neurons (total: 458)
2025-07-15 16:33:53,558 - INFO - Successfully masked 458 neurons across 14 layers
2025-07-15 16:33:53,601 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,601 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,602 - INFO - Step 459: masking 459 neurons (total: 459)
2025-07-15 16:33:53,654 - INFO - Successfully masked 459 neurons across 14 layers
2025-07-15 16:33:53,698 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,698 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,701 - INFO - Step 460: masking 460 neurons (total: 460)
2025-07-15 16:33:53,754 - INFO - Successfully masked 460 neurons across 14 layers
2025-07-15 16:33:53,797 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,797 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,798 - INFO - Step 461: masking 461 neurons (total: 461)
2025-07-15 16:33:53,848 - INFO - Successfully masked 461 neurons across 14 layers
2025-07-15 16:33:53,889 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,889 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,890 - INFO - Step 462: masking 462 neurons (total: 462)
2025-07-15 16:33:53,943 - INFO - Successfully masked 462 neurons across 14 layers
2025-07-15 16:33:53,986 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:53,986 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:53,987 - INFO - Step 463: masking 463 neurons (total: 463)
2025-07-15 16:33:54,041 - INFO - Successfully masked 463 neurons across 14 layers
2025-07-15 16:33:54,083 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,084 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,085 - INFO - Step 464: masking 464 neurons (total: 464)
2025-07-15 16:33:54,137 - INFO - Successfully masked 464 neurons across 14 layers
2025-07-15 16:33:54,179 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,180 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,181 - INFO - Step 465: masking 465 neurons (total: 465)
2025-07-15 16:33:54,233 - INFO - Successfully masked 465 neurons across 14 layers
2025-07-15 16:33:54,275 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,275 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,276 - INFO - Step 466: masking 466 neurons (total: 466)
2025-07-15 16:33:54,329 - INFO - Successfully masked 466 neurons across 14 layers
2025-07-15 16:33:54,371 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,372 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,373 - INFO - Step 467: masking 467 neurons (total: 467)
2025-07-15 16:33:54,425 - INFO - Successfully masked 467 neurons across 14 layers
2025-07-15 16:33:54,467 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,468 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,469 - INFO - Step 468: masking 468 neurons (total: 468)
2025-07-15 16:33:54,524 - INFO - Successfully masked 468 neurons across 14 layers
2025-07-15 16:33:54,567 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,567 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,568 - INFO - Step 469: masking 469 neurons (total: 469)
2025-07-15 16:33:54,620 - INFO - Successfully masked 469 neurons across 14 layers
2025-07-15 16:33:54,662 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,663 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,664 - INFO - Step 470: masking 470 neurons (total: 470)
2025-07-15 16:33:54,715 - INFO - Successfully masked 470 neurons across 14 layers
2025-07-15 16:33:54,757 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,758 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,758 - INFO - Step 471: masking 471 neurons (total: 471)
2025-07-15 16:33:54,810 - INFO - Successfully masked 471 neurons across 14 layers
2025-07-15 16:33:54,853 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,853 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,854 - INFO - Step 472: masking 472 neurons (total: 472)
2025-07-15 16:33:54,906 - INFO - Successfully masked 472 neurons across 14 layers
2025-07-15 16:33:54,948 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:54,948 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:54,949 - INFO - Step 473: masking 473 neurons (total: 473)
2025-07-15 16:33:55,001 - INFO - Successfully masked 473 neurons across 14 layers
2025-07-15 16:33:55,043 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,043 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,044 - INFO - Step 474: masking 474 neurons (total: 474)
2025-07-15 16:33:55,096 - INFO - Successfully masked 474 neurons across 14 layers
2025-07-15 16:33:55,138 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,139 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,139 - INFO - Step 475: masking 475 neurons (total: 475)
2025-07-15 16:33:55,191 - INFO - Successfully masked 475 neurons across 14 layers
2025-07-15 16:33:55,234 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,234 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,235 - INFO - Step 476: masking 476 neurons (total: 476)
2025-07-15 16:33:55,287 - INFO - Successfully masked 476 neurons across 14 layers
2025-07-15 16:33:55,329 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,329 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,330 - INFO - Step 477: masking 477 neurons (total: 477)
2025-07-15 16:33:55,382 - INFO - Successfully masked 477 neurons across 14 layers
2025-07-15 16:33:55,424 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,425 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,426 - INFO - Step 478: masking 478 neurons (total: 478)
2025-07-15 16:33:55,478 - INFO - Successfully masked 478 neurons across 14 layers
2025-07-15 16:33:55,522 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,522 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,523 - INFO - Step 479: masking 479 neurons (total: 479)
2025-07-15 16:33:55,579 - INFO - Successfully masked 479 neurons across 14 layers
2025-07-15 16:33:55,622 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,622 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,624 - INFO - Step 480: masking 480 neurons (total: 480)
2025-07-15 16:33:55,677 - INFO - Successfully masked 480 neurons across 14 layers
2025-07-15 16:33:55,721 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,721 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,722 - INFO - Step 481: masking 481 neurons (total: 481)
2025-07-15 16:33:55,775 - INFO - Successfully masked 481 neurons across 14 layers
2025-07-15 16:33:55,817 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,818 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,818 - INFO - Step 482: masking 482 neurons (total: 482)
2025-07-15 16:33:55,871 - INFO - Successfully masked 482 neurons across 14 layers
2025-07-15 16:33:55,914 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:55,914 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:55,915 - INFO - Step 483: masking 483 neurons (total: 483)
2025-07-15 16:33:55,968 - INFO - Successfully masked 483 neurons across 14 layers
2025-07-15 16:33:56,010 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,011 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,012 - INFO - Step 484: masking 484 neurons (total: 484)
2025-07-15 16:33:56,064 - INFO - Successfully masked 484 neurons across 14 layers
2025-07-15 16:33:56,107 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,107 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,108 - INFO - Step 485: masking 485 neurons (total: 485)
2025-07-15 16:33:56,162 - INFO - Successfully masked 485 neurons across 14 layers
2025-07-15 16:33:56,205 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,205 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,206 - INFO - Step 486: masking 486 neurons (total: 486)
2025-07-15 16:33:56,258 - INFO - Successfully masked 486 neurons across 14 layers
2025-07-15 16:33:56,300 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,301 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,302 - INFO - Step 487: masking 487 neurons (total: 487)
2025-07-15 16:33:56,354 - INFO - Successfully masked 487 neurons across 14 layers
2025-07-15 16:33:56,396 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,396 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,397 - INFO - Step 488: masking 488 neurons (total: 488)
2025-07-15 16:33:56,449 - INFO - Successfully masked 488 neurons across 14 layers
2025-07-15 16:33:56,493 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,493 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,494 - INFO - Step 489: masking 489 neurons (total: 489)
2025-07-15 16:33:56,547 - INFO - Successfully masked 489 neurons across 14 layers
2025-07-15 16:33:56,591 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,592 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,593 - INFO - Step 490: masking 490 neurons (total: 490)
2025-07-15 16:33:56,650 - INFO - Successfully masked 490 neurons across 14 layers
2025-07-15 16:33:56,693 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,693 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,694 - INFO - Step 491: masking 491 neurons (total: 491)
2025-07-15 16:33:56,747 - INFO - Successfully masked 491 neurons across 14 layers
2025-07-15 16:33:56,789 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,790 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,791 - INFO - Step 492: masking 492 neurons (total: 492)
2025-07-15 16:33:56,843 - INFO - Successfully masked 492 neurons across 14 layers
2025-07-15 16:33:56,886 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,886 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,887 - INFO - Step 493: masking 493 neurons (total: 493)
2025-07-15 16:33:56,940 - INFO - Successfully masked 493 neurons across 14 layers
2025-07-15 16:33:56,982 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:56,983 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:56,984 - INFO - Step 494: masking 494 neurons (total: 494)
2025-07-15 16:33:57,036 - INFO - Successfully masked 494 neurons across 14 layers
2025-07-15 16:33:57,079 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,079 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,080 - INFO - Step 495: masking 495 neurons (total: 495)
2025-07-15 16:33:57,133 - INFO - Successfully masked 495 neurons across 14 layers
2025-07-15 16:33:57,176 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,176 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,177 - INFO - Step 496: masking 496 neurons (total: 496)
2025-07-15 16:33:57,230 - INFO - Successfully masked 496 neurons across 14 layers
2025-07-15 16:33:57,274 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,274 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,275 - INFO - Step 497: masking 497 neurons (total: 497)
2025-07-15 16:33:57,328 - INFO - Successfully masked 497 neurons across 14 layers
2025-07-15 16:33:57,371 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,371 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,372 - INFO - Step 498: masking 498 neurons (total: 498)
2025-07-15 16:33:57,425 - INFO - Successfully masked 498 neurons across 14 layers
2025-07-15 16:33:57,467 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,468 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,469 - INFO - Step 499: masking 499 neurons (total: 499)
2025-07-15 16:33:57,525 - INFO - Successfully masked 499 neurons across 14 layers
2025-07-15 16:33:57,568 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,568 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,569 - INFO - Step 500: masking 500 neurons (total: 500)
2025-07-15 16:33:57,623 - INFO - Successfully masked 500 neurons across 14 layers
2025-07-15 16:33:57,666 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,666 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,667 - INFO - Step 501: masking 501 neurons (total: 501)
2025-07-15 16:33:57,720 - INFO - Successfully masked 501 neurons across 14 layers
2025-07-15 16:33:57,762 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,763 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,763 - INFO - Step 502: masking 502 neurons (total: 502)
2025-07-15 16:33:57,817 - INFO - Successfully masked 502 neurons across 14 layers
2025-07-15 16:33:57,859 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,859 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,860 - INFO - Step 503: masking 503 neurons (total: 503)
2025-07-15 16:33:57,913 - INFO - Successfully masked 503 neurons across 14 layers
2025-07-15 16:33:57,956 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:57,956 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:57,957 - INFO - Step 504: masking 504 neurons (total: 504)
2025-07-15 16:33:58,010 - INFO - Successfully masked 504 neurons across 14 layers
2025-07-15 16:33:58,053 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,053 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,054 - INFO - Step 505: masking 505 neurons (total: 505)
2025-07-15 16:33:58,107 - INFO - Successfully masked 505 neurons across 14 layers
2025-07-15 16:33:58,150 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,150 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,151 - INFO - Step 506: masking 506 neurons (total: 506)
2025-07-15 16:33:58,205 - INFO - Successfully masked 506 neurons across 14 layers
2025-07-15 16:33:58,247 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,248 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,248 - INFO - Step 507: masking 507 neurons (total: 507)
2025-07-15 16:33:58,302 - INFO - Successfully masked 507 neurons across 14 layers
2025-07-15 16:33:58,345 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,345 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,346 - INFO - Step 508: masking 508 neurons (total: 508)
2025-07-15 16:33:58,400 - INFO - Successfully masked 508 neurons across 14 layers
2025-07-15 16:33:58,442 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,443 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,443 - INFO - Step 509: masking 509 neurons (total: 509)
2025-07-15 16:33:58,497 - INFO - Successfully masked 509 neurons across 14 layers
2025-07-15 16:33:58,540 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,540 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,541 - INFO - Step 510: masking 510 neurons (total: 510)
2025-07-15 16:33:58,594 - INFO - Successfully masked 510 neurons across 14 layers
2025-07-15 16:33:58,637 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,637 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,638 - INFO - Step 511: masking 511 neurons (total: 511)
2025-07-15 16:33:58,693 - INFO - Successfully masked 511 neurons across 14 layers
2025-07-15 16:33:58,736 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,736 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,737 - INFO - Step 512: masking 512 neurons (total: 512)
2025-07-15 16:33:58,791 - INFO - Successfully masked 512 neurons across 14 layers
2025-07-15 16:33:58,833 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,834 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,834 - INFO - Step 513: masking 513 neurons (total: 513)
2025-07-15 16:33:58,888 - INFO - Successfully masked 513 neurons across 14 layers
2025-07-15 16:33:58,930 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:58,931 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:58,932 - INFO - Step 514: masking 514 neurons (total: 514)
2025-07-15 16:33:58,985 - INFO - Successfully masked 514 neurons across 14 layers
2025-07-15 16:33:59,027 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,028 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,029 - INFO - Step 515: masking 515 neurons (total: 515)
2025-07-15 16:33:59,084 - INFO - Successfully masked 515 neurons across 14 layers
2025-07-15 16:33:59,126 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,127 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,128 - INFO - Step 516: masking 516 neurons (total: 516)
2025-07-15 16:33:59,181 - INFO - Successfully masked 516 neurons across 14 layers
2025-07-15 16:33:59,224 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,224 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,225 - INFO - Step 517: masking 517 neurons (total: 517)
2025-07-15 16:33:59,279 - INFO - Successfully masked 517 neurons across 14 layers
2025-07-15 16:33:59,322 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,322 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,323 - INFO - Step 518: masking 518 neurons (total: 518)
2025-07-15 16:33:59,376 - INFO - Successfully masked 518 neurons across 14 layers
2025-07-15 16:33:59,417 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,418 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,418 - INFO - Step 519: masking 519 neurons (total: 519)
2025-07-15 16:33:59,470 - INFO - Successfully masked 519 neurons across 14 layers
2025-07-15 16:33:59,511 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,512 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,512 - INFO - Step 520: masking 520 neurons (total: 520)
2025-07-15 16:33:59,564 - INFO - Successfully masked 520 neurons across 14 layers
2025-07-15 16:33:59,605 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,605 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,606 - INFO - Step 521: masking 521 neurons (total: 521)
2025-07-15 16:33:59,658 - INFO - Successfully masked 521 neurons across 14 layers
2025-07-15 16:33:59,700 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,700 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,701 - INFO - Step 522: masking 522 neurons (total: 522)
2025-07-15 16:33:59,753 - INFO - Successfully masked 522 neurons across 14 layers
2025-07-15 16:33:59,794 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,794 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,795 - INFO - Step 523: masking 523 neurons (total: 523)
2025-07-15 16:33:59,847 - INFO - Successfully masked 523 neurons across 14 layers
2025-07-15 16:33:59,887 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,888 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,888 - INFO - Step 524: masking 524 neurons (total: 524)
2025-07-15 16:33:59,940 - INFO - Successfully masked 524 neurons across 14 layers
2025-07-15 16:33:59,981 - INFO - Masked perplexity: 45.6465
2025-07-15 16:33:59,981 - INFO - Magnitude increase: 0.0000
2025-07-15 16:33:59,982 - INFO - Step 525: masking 525 neurons (total: 525)
2025-07-15 16:34:00,034 - INFO - Successfully masked 525 neurons across 14 layers
2025-07-15 16:34:00,075 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,076 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,076 - INFO - Step 526: masking 526 neurons (total: 526)
2025-07-15 16:34:00,128 - INFO - Successfully masked 526 neurons across 14 layers
2025-07-15 16:34:00,169 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,169 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,170 - INFO - Step 527: masking 527 neurons (total: 527)
2025-07-15 16:34:00,221 - INFO - Successfully masked 527 neurons across 14 layers
2025-07-15 16:34:00,262 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,263 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,263 - INFO - Step 528: masking 528 neurons (total: 528)
2025-07-15 16:34:00,315 - INFO - Successfully masked 528 neurons across 14 layers
2025-07-15 16:34:00,356 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,356 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,357 - INFO - Step 529: masking 529 neurons (total: 529)
2025-07-15 16:34:00,409 - INFO - Successfully masked 529 neurons across 14 layers
2025-07-15 16:34:00,449 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,450 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,450 - INFO - Step 530: masking 530 neurons (total: 530)
2025-07-15 16:34:00,502 - INFO - Successfully masked 530 neurons across 14 layers
2025-07-15 16:34:00,546 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,547 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,548 - INFO - Step 531: masking 531 neurons (total: 531)
2025-07-15 16:34:00,601 - INFO - Successfully masked 531 neurons across 14 layers
2025-07-15 16:34:00,644 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,644 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,645 - INFO - Step 532: masking 532 neurons (total: 532)
2025-07-15 16:34:00,699 - INFO - Successfully masked 532 neurons across 14 layers
2025-07-15 16:34:00,741 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,742 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,743 - INFO - Step 533: masking 533 neurons (total: 533)
2025-07-15 16:34:00,796 - INFO - Successfully masked 533 neurons across 14 layers
2025-07-15 16:34:00,838 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,839 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,840 - INFO - Step 534: masking 534 neurons (total: 534)
2025-07-15 16:34:00,896 - INFO - Successfully masked 534 neurons across 14 layers
2025-07-15 16:34:00,939 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:00,939 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:00,940 - INFO - Step 535: masking 535 neurons (total: 535)
2025-07-15 16:34:00,993 - INFO - Successfully masked 535 neurons across 14 layers
2025-07-15 16:34:01,036 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,037 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,037 - INFO - Step 536: masking 536 neurons (total: 536)
2025-07-15 16:34:01,091 - INFO - Successfully masked 536 neurons across 14 layers
2025-07-15 16:34:01,134 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,134 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,135 - INFO - Step 537: masking 537 neurons (total: 537)
2025-07-15 16:34:01,188 - INFO - Successfully masked 537 neurons across 14 layers
2025-07-15 16:34:01,231 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,231 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,232 - INFO - Step 538: masking 538 neurons (total: 538)
2025-07-15 16:34:01,286 - INFO - Successfully masked 538 neurons across 14 layers
2025-07-15 16:34:01,328 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,328 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,329 - INFO - Step 539: masking 539 neurons (total: 539)
2025-07-15 16:34:01,383 - INFO - Successfully masked 539 neurons across 14 layers
2025-07-15 16:34:01,426 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,427 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,427 - INFO - Step 540: masking 540 neurons (total: 540)
2025-07-15 16:34:01,481 - INFO - Successfully masked 540 neurons across 14 layers
2025-07-15 16:34:01,524 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,525 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,526 - INFO - Step 541: masking 541 neurons (total: 541)
2025-07-15 16:34:01,580 - INFO - Successfully masked 541 neurons across 14 layers
2025-07-15 16:34:01,622 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,623 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,624 - INFO - Step 542: masking 542 neurons (total: 542)
2025-07-15 16:34:01,678 - INFO - Successfully masked 542 neurons across 14 layers
2025-07-15 16:34:01,720 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,720 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,721 - INFO - Step 543: masking 543 neurons (total: 543)
2025-07-15 16:34:01,775 - INFO - Successfully masked 543 neurons across 14 layers
2025-07-15 16:34:01,817 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,818 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,819 - INFO - Step 544: masking 544 neurons (total: 544)
2025-07-15 16:34:01,872 - INFO - Successfully masked 544 neurons across 14 layers
2025-07-15 16:34:01,914 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:01,915 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:01,915 - INFO - Step 545: masking 545 neurons (total: 545)
2025-07-15 16:34:01,969 - INFO - Successfully masked 545 neurons across 14 layers
2025-07-15 16:34:02,011 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,011 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,012 - INFO - Step 546: masking 546 neurons (total: 546)
2025-07-15 16:34:02,066 - INFO - Successfully masked 546 neurons across 14 layers
2025-07-15 16:34:02,109 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,109 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,111 - INFO - Step 547: masking 547 neurons (total: 547)
2025-07-15 16:34:02,167 - INFO - Successfully masked 547 neurons across 14 layers
2025-07-15 16:34:02,210 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,210 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,211 - INFO - Step 548: masking 548 neurons (total: 548)
2025-07-15 16:34:02,266 - INFO - Successfully masked 548 neurons across 14 layers
2025-07-15 16:34:02,309 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,309 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,310 - INFO - Step 549: masking 549 neurons (total: 549)
2025-07-15 16:34:02,365 - INFO - Successfully masked 549 neurons across 14 layers
2025-07-15 16:34:02,408 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,408 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,409 - INFO - Step 550: masking 550 neurons (total: 550)
2025-07-15 16:34:02,464 - INFO - Successfully masked 550 neurons across 14 layers
2025-07-15 16:34:02,508 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,508 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,509 - INFO - Step 551: masking 551 neurons (total: 551)
2025-07-15 16:34:02,564 - INFO - Successfully masked 551 neurons across 14 layers
2025-07-15 16:34:02,607 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,607 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,608 - INFO - Step 552: masking 552 neurons (total: 552)
2025-07-15 16:34:02,665 - INFO - Successfully masked 552 neurons across 14 layers
2025-07-15 16:34:02,709 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,709 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,710 - INFO - Step 553: masking 553 neurons (total: 553)
2025-07-15 16:34:02,765 - INFO - Successfully masked 553 neurons across 14 layers
2025-07-15 16:34:02,808 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,808 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,809 - INFO - Step 554: masking 554 neurons (total: 554)
2025-07-15 16:34:02,863 - INFO - Successfully masked 554 neurons across 14 layers
2025-07-15 16:34:02,906 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:02,907 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:02,907 - INFO - Step 555: masking 555 neurons (total: 555)
2025-07-15 16:34:02,962 - INFO - Successfully masked 555 neurons across 14 layers
2025-07-15 16:34:03,005 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,005 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,006 - INFO - Step 556: masking 556 neurons (total: 556)
2025-07-15 16:34:03,061 - INFO - Successfully masked 556 neurons across 14 layers
2025-07-15 16:34:03,104 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,104 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,105 - INFO - Step 557: masking 557 neurons (total: 557)
2025-07-15 16:34:03,162 - INFO - Successfully masked 557 neurons across 14 layers
2025-07-15 16:34:03,205 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,205 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,206 - INFO - Step 558: masking 558 neurons (total: 558)
2025-07-15 16:34:03,260 - INFO - Successfully masked 558 neurons across 14 layers
2025-07-15 16:34:03,303 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,303 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,304 - INFO - Step 559: masking 559 neurons (total: 559)
2025-07-15 16:34:03,358 - INFO - Successfully masked 559 neurons across 14 layers
2025-07-15 16:34:03,401 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,401 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,402 - INFO - Step 560: masking 560 neurons (total: 560)
2025-07-15 16:34:03,456 - INFO - Successfully masked 560 neurons across 14 layers
2025-07-15 16:34:03,498 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,498 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,499 - INFO - Step 561: masking 561 neurons (total: 561)
2025-07-15 16:34:03,553 - INFO - Successfully masked 561 neurons across 14 layers
2025-07-15 16:34:03,596 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,596 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,597 - INFO - Step 562: masking 562 neurons (total: 562)
2025-07-15 16:34:03,651 - INFO - Successfully masked 562 neurons across 15 layers
2025-07-15 16:34:03,693 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,694 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,695 - INFO - Step 563: masking 563 neurons (total: 563)
2025-07-15 16:34:03,749 - INFO - Successfully masked 563 neurons across 15 layers
2025-07-15 16:34:03,791 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,791 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,792 - INFO - Step 564: masking 564 neurons (total: 564)
2025-07-15 16:34:03,846 - INFO - Successfully masked 564 neurons across 15 layers
2025-07-15 16:34:03,889 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,889 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,890 - INFO - Step 565: masking 565 neurons (total: 565)
2025-07-15 16:34:03,944 - INFO - Successfully masked 565 neurons across 15 layers
2025-07-15 16:34:03,986 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:03,987 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:03,987 - INFO - Step 566: masking 566 neurons (total: 566)
2025-07-15 16:34:04,042 - INFO - Successfully masked 566 neurons across 15 layers
2025-07-15 16:34:04,085 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,085 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,086 - INFO - Step 567: masking 567 neurons (total: 567)
2025-07-15 16:34:04,140 - INFO - Successfully masked 567 neurons across 15 layers
2025-07-15 16:34:04,183 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,183 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,184 - INFO - Step 568: masking 568 neurons (total: 568)
2025-07-15 16:34:04,238 - INFO - Successfully masked 568 neurons across 15 layers
2025-07-15 16:34:04,281 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,282 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,282 - INFO - Step 569: masking 569 neurons (total: 569)
2025-07-15 16:34:04,337 - INFO - Successfully masked 569 neurons across 15 layers
2025-07-15 16:34:04,380 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,381 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,381 - INFO - Step 570: masking 570 neurons (total: 570)
2025-07-15 16:34:04,435 - INFO - Successfully masked 570 neurons across 15 layers
2025-07-15 16:34:04,476 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,477 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,478 - INFO - Step 571: masking 571 neurons (total: 571)
2025-07-15 16:34:04,531 - INFO - Successfully masked 571 neurons across 15 layers
2025-07-15 16:34:04,572 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,573 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,574 - INFO - Step 572: masking 572 neurons (total: 572)
2025-07-15 16:34:04,627 - INFO - Successfully masked 572 neurons across 15 layers
2025-07-15 16:34:04,669 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,669 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,670 - INFO - Step 573: masking 573 neurons (total: 573)
2025-07-15 16:34:04,723 - INFO - Successfully masked 573 neurons across 15 layers
2025-07-15 16:34:04,764 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,765 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,766 - INFO - Step 574: masking 574 neurons (total: 574)
2025-07-15 16:34:04,819 - INFO - Successfully masked 574 neurons across 15 layers
2025-07-15 16:34:04,861 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,861 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,862 - INFO - Step 575: masking 575 neurons (total: 575)
2025-07-15 16:34:04,916 - INFO - Successfully masked 575 neurons across 15 layers
2025-07-15 16:34:04,958 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:04,959 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:04,959 - INFO - Step 576: masking 576 neurons (total: 576)
2025-07-15 16:34:05,013 - INFO - Successfully masked 576 neurons across 15 layers
2025-07-15 16:34:05,054 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,055 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,055 - INFO - Step 577: masking 577 neurons (total: 577)
2025-07-15 16:34:05,109 - INFO - Successfully masked 577 neurons across 15 layers
2025-07-15 16:34:05,150 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,150 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,151 - INFO - Step 578: masking 578 neurons (total: 578)
2025-07-15 16:34:05,204 - INFO - Successfully masked 578 neurons across 15 layers
2025-07-15 16:34:05,246 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,246 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,247 - INFO - Step 579: masking 579 neurons (total: 579)
2025-07-15 16:34:05,300 - INFO - Successfully masked 579 neurons across 15 layers
2025-07-15 16:34:05,341 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,342 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,343 - INFO - Step 580: masking 580 neurons (total: 580)
2025-07-15 16:34:05,396 - INFO - Successfully masked 580 neurons across 15 layers
2025-07-15 16:34:05,437 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,437 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,438 - INFO - Step 581: masking 581 neurons (total: 581)
2025-07-15 16:34:05,491 - INFO - Successfully masked 581 neurons across 15 layers
2025-07-15 16:34:05,533 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,533 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,534 - INFO - Step 582: masking 582 neurons (total: 582)
2025-07-15 16:34:05,587 - INFO - Successfully masked 582 neurons across 15 layers
2025-07-15 16:34:05,628 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,629 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,630 - INFO - Step 583: masking 583 neurons (total: 583)
2025-07-15 16:34:05,687 - INFO - Successfully masked 583 neurons across 15 layers
2025-07-15 16:34:05,730 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,730 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,731 - INFO - Step 584: masking 584 neurons (total: 584)
2025-07-15 16:34:05,786 - INFO - Successfully masked 584 neurons across 15 layers
2025-07-15 16:34:05,829 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,829 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,830 - INFO - Step 585: masking 585 neurons (total: 585)
2025-07-15 16:34:05,886 - INFO - Successfully masked 585 neurons across 15 layers
2025-07-15 16:34:05,928 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:05,929 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:05,929 - INFO - Step 586: masking 586 neurons (total: 586)
2025-07-15 16:34:05,985 - INFO - Successfully masked 586 neurons across 15 layers
2025-07-15 16:34:06,027 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,028 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,029 - INFO - Step 587: masking 587 neurons (total: 587)
2025-07-15 16:34:06,084 - INFO - Successfully masked 587 neurons across 15 layers
2025-07-15 16:34:06,126 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,126 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,127 - INFO - Step 588: masking 588 neurons (total: 588)
2025-07-15 16:34:06,182 - INFO - Successfully masked 588 neurons across 16 layers
2025-07-15 16:34:06,224 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,224 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,225 - INFO - Step 589: masking 589 neurons (total: 589)
2025-07-15 16:34:06,280 - INFO - Successfully masked 589 neurons across 16 layers
2025-07-15 16:34:06,323 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,323 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,324 - INFO - Step 590: masking 590 neurons (total: 590)
2025-07-15 16:34:06,379 - INFO - Successfully masked 590 neurons across 16 layers
2025-07-15 16:34:06,422 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,423 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,423 - INFO - Step 591: masking 591 neurons (total: 591)
2025-07-15 16:34:06,480 - INFO - Successfully masked 591 neurons across 16 layers
2025-07-15 16:34:06,523 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,523 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,524 - INFO - Step 592: masking 592 neurons (total: 592)
2025-07-15 16:34:06,578 - INFO - Successfully masked 592 neurons across 16 layers
2025-07-15 16:34:06,619 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,619 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,620 - INFO - Step 593: masking 593 neurons (total: 593)
2025-07-15 16:34:06,674 - INFO - Successfully masked 593 neurons across 16 layers
2025-07-15 16:34:06,716 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,716 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,717 - INFO - Step 594: masking 594 neurons (total: 594)
2025-07-15 16:34:06,771 - INFO - Successfully masked 594 neurons across 16 layers
2025-07-15 16:34:06,812 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,812 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,813 - INFO - Step 595: masking 595 neurons (total: 595)
2025-07-15 16:34:06,867 - INFO - Successfully masked 595 neurons across 16 layers
2025-07-15 16:34:06,908 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:06,909 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:06,910 - INFO - Step 596: masking 596 neurons (total: 596)
2025-07-15 16:34:06,963 - INFO - Successfully masked 596 neurons across 16 layers
2025-07-15 16:34:07,005 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,005 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,006 - INFO - Step 597: masking 597 neurons (total: 597)
2025-07-15 16:34:07,060 - INFO - Successfully masked 597 neurons across 16 layers
2025-07-15 16:34:07,102 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,102 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,103 - INFO - Step 598: masking 598 neurons (total: 598)
2025-07-15 16:34:07,156 - INFO - Successfully masked 598 neurons across 16 layers
2025-07-15 16:34:07,197 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,198 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,198 - INFO - Step 599: masking 599 neurons (total: 599)
2025-07-15 16:34:07,252 - INFO - Successfully masked 599 neurons across 16 layers
2025-07-15 16:34:07,293 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,293 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,294 - INFO - Step 600: masking 600 neurons (total: 600)
2025-07-15 16:34:07,348 - INFO - Successfully masked 600 neurons across 16 layers
2025-07-15 16:34:07,389 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,389 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,390 - INFO - Step 601: masking 601 neurons (total: 601)
2025-07-15 16:34:07,444 - INFO - Successfully masked 601 neurons across 16 layers
2025-07-15 16:34:07,486 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,486 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,487 - INFO - Step 602: masking 602 neurons (total: 602)
2025-07-15 16:34:07,540 - INFO - Successfully masked 602 neurons across 16 layers
2025-07-15 16:34:07,581 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,582 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,582 - INFO - Step 603: masking 603 neurons (total: 603)
2025-07-15 16:34:07,636 - INFO - Successfully masked 603 neurons across 16 layers
2025-07-15 16:34:07,677 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,677 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,678 - INFO - Step 604: masking 604 neurons (total: 604)
2025-07-15 16:34:07,732 - INFO - Successfully masked 604 neurons across 16 layers
2025-07-15 16:34:07,773 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,774 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,775 - INFO - Step 605: masking 605 neurons (total: 605)
2025-07-15 16:34:07,828 - INFO - Successfully masked 605 neurons across 16 layers
2025-07-15 16:34:07,870 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,870 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,871 - INFO - Step 606: masking 606 neurons (total: 606)
2025-07-15 16:34:07,925 - INFO - Successfully masked 606 neurons across 16 layers
2025-07-15 16:34:07,967 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:07,967 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:07,968 - INFO - Step 607: masking 607 neurons (total: 607)
2025-07-15 16:34:08,022 - INFO - Successfully masked 607 neurons across 16 layers
2025-07-15 16:34:08,064 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,064 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,065 - INFO - Step 608: masking 608 neurons (total: 608)
2025-07-15 16:34:08,119 - INFO - Successfully masked 608 neurons across 16 layers
2025-07-15 16:34:08,160 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,161 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,162 - INFO - Step 609: masking 609 neurons (total: 609)
2025-07-15 16:34:08,216 - INFO - Successfully masked 609 neurons across 16 layers
2025-07-15 16:34:08,257 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,258 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,259 - INFO - Step 610: masking 610 neurons (total: 610)
2025-07-15 16:34:08,313 - INFO - Successfully masked 610 neurons across 16 layers
2025-07-15 16:34:08,354 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,355 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,355 - INFO - Step 611: masking 611 neurons (total: 611)
2025-07-15 16:34:08,409 - INFO - Successfully masked 611 neurons across 16 layers
2025-07-15 16:34:08,451 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,451 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,452 - INFO - Step 612: masking 612 neurons (total: 612)
2025-07-15 16:34:08,506 - INFO - Successfully masked 612 neurons across 16 layers
2025-07-15 16:34:08,547 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,547 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,548 - INFO - Step 613: masking 613 neurons (total: 613)
2025-07-15 16:34:08,602 - INFO - Successfully masked 613 neurons across 16 layers
2025-07-15 16:34:08,643 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,644 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,645 - INFO - Step 614: masking 614 neurons (total: 614)
2025-07-15 16:34:08,698 - INFO - Successfully masked 614 neurons across 16 layers
2025-07-15 16:34:08,740 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,740 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,741 - INFO - Step 615: masking 615 neurons (total: 615)
2025-07-15 16:34:08,795 - INFO - Successfully masked 615 neurons across 16 layers
2025-07-15 16:34:08,836 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,837 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,838 - INFO - Step 616: masking 616 neurons (total: 616)
2025-07-15 16:34:08,892 - INFO - Successfully masked 616 neurons across 16 layers
2025-07-15 16:34:08,933 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:08,934 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:08,935 - INFO - Step 617: masking 617 neurons (total: 617)
2025-07-15 16:34:08,989 - INFO - Successfully masked 617 neurons across 16 layers
2025-07-15 16:34:09,030 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,030 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,031 - INFO - Step 618: masking 618 neurons (total: 618)
2025-07-15 16:34:09,085 - INFO - Successfully masked 618 neurons across 16 layers
2025-07-15 16:34:09,126 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,126 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,128 - INFO - Step 619: masking 619 neurons (total: 619)
2025-07-15 16:34:09,185 - INFO - Successfully masked 619 neurons across 16 layers
2025-07-15 16:34:09,227 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,228 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,229 - INFO - Step 620: masking 620 neurons (total: 620)
2025-07-15 16:34:09,284 - INFO - Successfully masked 620 neurons across 16 layers
2025-07-15 16:34:09,326 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,327 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,328 - INFO - Step 621: masking 621 neurons (total: 621)
2025-07-15 16:34:09,383 - INFO - Successfully masked 621 neurons across 16 layers
2025-07-15 16:34:09,425 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,426 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,427 - INFO - Step 622: masking 622 neurons (total: 622)
2025-07-15 16:34:09,482 - INFO - Successfully masked 622 neurons across 16 layers
2025-07-15 16:34:09,525 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,525 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,526 - INFO - Step 623: masking 623 neurons (total: 623)
2025-07-15 16:34:09,581 - INFO - Successfully masked 623 neurons across 16 layers
2025-07-15 16:34:09,624 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,624 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,625 - INFO - Step 624: masking 624 neurons (total: 624)
2025-07-15 16:34:09,681 - INFO - Successfully masked 624 neurons across 16 layers
2025-07-15 16:34:09,723 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,723 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,724 - INFO - Step 625: masking 625 neurons (total: 625)
2025-07-15 16:34:09,779 - INFO - Successfully masked 625 neurons across 16 layers
2025-07-15 16:34:09,820 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,820 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,821 - INFO - Step 626: masking 626 neurons (total: 626)
2025-07-15 16:34:09,878 - INFO - Successfully masked 626 neurons across 16 layers
2025-07-15 16:34:09,921 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:09,921 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:09,922 - INFO - Step 627: masking 627 neurons (total: 627)
2025-07-15 16:34:09,978 - INFO - Successfully masked 627 neurons across 16 layers
2025-07-15 16:34:10,021 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,021 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,024 - INFO - Step 628: masking 628 neurons (total: 628)
2025-07-15 16:34:10,081 - INFO - Successfully masked 628 neurons across 16 layers
2025-07-15 16:34:10,124 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,125 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,126 - INFO - Step 629: masking 629 neurons (total: 629)
2025-07-15 16:34:10,182 - INFO - Successfully masked 629 neurons across 16 layers
2025-07-15 16:34:10,225 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,225 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,227 - INFO - Step 630: masking 630 neurons (total: 630)
2025-07-15 16:34:10,283 - INFO - Successfully masked 630 neurons across 16 layers
2025-07-15 16:34:10,325 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,325 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,326 - INFO - Step 631: masking 631 neurons (total: 631)
2025-07-15 16:34:10,381 - INFO - Successfully masked 631 neurons across 16 layers
2025-07-15 16:34:10,423 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,423 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,424 - INFO - Step 632: masking 632 neurons (total: 632)
2025-07-15 16:34:10,479 - INFO - Successfully masked 632 neurons across 16 layers
2025-07-15 16:34:10,520 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,520 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,521 - INFO - Step 633: masking 633 neurons (total: 633)
2025-07-15 16:34:10,576 - INFO - Successfully masked 633 neurons across 16 layers
2025-07-15 16:34:10,617 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,617 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,618 - INFO - Step 634: masking 634 neurons (total: 634)
2025-07-15 16:34:10,673 - INFO - Successfully masked 634 neurons across 16 layers
2025-07-15 16:34:10,714 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,714 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,715 - INFO - Step 635: masking 635 neurons (total: 635)
2025-07-15 16:34:10,770 - INFO - Successfully masked 635 neurons across 16 layers
2025-07-15 16:34:10,811 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,811 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,812 - INFO - Step 636: masking 636 neurons (total: 636)
2025-07-15 16:34:10,867 - INFO - Successfully masked 636 neurons across 16 layers
2025-07-15 16:34:10,908 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:10,908 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:10,910 - INFO - Step 637: masking 637 neurons (total: 637)
2025-07-15 16:34:10,967 - INFO - Successfully masked 637 neurons across 16 layers
2025-07-15 16:34:11,010 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,010 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,012 - INFO - Step 638: masking 638 neurons (total: 638)
2025-07-15 16:34:11,069 - INFO - Successfully masked 638 neurons across 16 layers
2025-07-15 16:34:11,112 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,112 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,113 - INFO - Step 639: masking 639 neurons (total: 639)
2025-07-15 16:34:11,170 - INFO - Successfully masked 639 neurons across 16 layers
2025-07-15 16:34:11,212 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,213 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,214 - INFO - Step 640: masking 640 neurons (total: 640)
2025-07-15 16:34:11,270 - INFO - Successfully masked 640 neurons across 16 layers
2025-07-15 16:34:11,313 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,313 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,314 - INFO - Step 641: masking 641 neurons (total: 641)
2025-07-15 16:34:11,370 - INFO - Successfully masked 641 neurons across 16 layers
2025-07-15 16:34:11,417 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,418 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,418 - INFO - Step 642: masking 642 neurons (total: 642)
2025-07-15 16:34:11,474 - INFO - Successfully masked 642 neurons across 16 layers
2025-07-15 16:34:11,516 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,516 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,517 - INFO - Step 643: masking 643 neurons (total: 643)
2025-07-15 16:34:11,573 - INFO - Successfully masked 643 neurons across 16 layers
2025-07-15 16:34:11,614 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,615 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,616 - INFO - Step 644: masking 644 neurons (total: 644)
2025-07-15 16:34:11,671 - INFO - Successfully masked 644 neurons across 16 layers
2025-07-15 16:34:11,713 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,713 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,714 - INFO - Step 645: masking 645 neurons (total: 645)
2025-07-15 16:34:11,769 - INFO - Successfully masked 645 neurons across 16 layers
2025-07-15 16:34:11,811 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,811 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,812 - INFO - Step 646: masking 646 neurons (total: 646)
2025-07-15 16:34:11,868 - INFO - Successfully masked 646 neurons across 16 layers
2025-07-15 16:34:11,910 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:11,910 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:11,911 - INFO - Step 647: masking 647 neurons (total: 647)
2025-07-15 16:34:11,965 - INFO - Successfully masked 647 neurons across 16 layers
2025-07-15 16:34:12,006 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,006 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,007 - INFO - Step 648: masking 648 neurons (total: 648)
2025-07-15 16:34:12,062 - INFO - Successfully masked 648 neurons across 16 layers
2025-07-15 16:34:12,103 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,103 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,104 - INFO - Step 649: masking 649 neurons (total: 649)
2025-07-15 16:34:12,159 - INFO - Successfully masked 649 neurons across 16 layers
2025-07-15 16:34:12,199 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,200 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,201 - INFO - Step 650: masking 650 neurons (total: 650)
2025-07-15 16:34:12,255 - INFO - Successfully masked 650 neurons across 16 layers
2025-07-15 16:34:12,296 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,297 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,298 - INFO - Step 651: masking 651 neurons (total: 651)
2025-07-15 16:34:12,352 - INFO - Successfully masked 651 neurons across 16 layers
2025-07-15 16:34:12,393 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,393 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,394 - INFO - Step 652: masking 652 neurons (total: 652)
2025-07-15 16:34:12,448 - INFO - Successfully masked 652 neurons across 16 layers
2025-07-15 16:34:12,490 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,490 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,491 - INFO - Step 653: masking 653 neurons (total: 653)
2025-07-15 16:34:12,546 - INFO - Successfully masked 653 neurons across 16 layers
2025-07-15 16:34:12,586 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,587 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,588 - INFO - Step 654: masking 654 neurons (total: 654)
2025-07-15 16:34:12,642 - INFO - Successfully masked 654 neurons across 16 layers
2025-07-15 16:34:12,683 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,684 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,685 - INFO - Step 655: masking 655 neurons (total: 655)
2025-07-15 16:34:12,739 - INFO - Successfully masked 655 neurons across 16 layers
2025-07-15 16:34:12,780 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,781 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,781 - INFO - Step 656: masking 656 neurons (total: 656)
2025-07-15 16:34:12,836 - INFO - Successfully masked 656 neurons across 16 layers
2025-07-15 16:34:12,877 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,877 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,878 - INFO - Step 657: masking 657 neurons (total: 657)
2025-07-15 16:34:12,932 - INFO - Successfully masked 657 neurons across 16 layers
2025-07-15 16:34:12,973 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:12,974 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:12,974 - INFO - Step 658: masking 658 neurons (total: 658)
2025-07-15 16:34:13,029 - INFO - Successfully masked 658 neurons across 16 layers
2025-07-15 16:34:13,074 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,074 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,075 - INFO - Step 659: masking 659 neurons (total: 659)
2025-07-15 16:34:13,132 - INFO - Successfully masked 659 neurons across 16 layers
2025-07-15 16:34:13,175 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,175 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,176 - INFO - Step 660: masking 660 neurons (total: 660)
2025-07-15 16:34:13,233 - INFO - Successfully masked 660 neurons across 16 layers
2025-07-15 16:34:13,276 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,276 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,277 - INFO - Step 661: masking 661 neurons (total: 661)
2025-07-15 16:34:13,333 - INFO - Successfully masked 661 neurons across 16 layers
2025-07-15 16:34:13,376 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,376 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,377 - INFO - Step 662: masking 662 neurons (total: 662)
2025-07-15 16:34:13,433 - INFO - Successfully masked 662 neurons across 16 layers
2025-07-15 16:34:13,476 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,476 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,477 - INFO - Step 663: masking 663 neurons (total: 663)
2025-07-15 16:34:13,534 - INFO - Successfully masked 663 neurons across 16 layers
2025-07-15 16:34:13,576 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,577 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,578 - INFO - Step 664: masking 664 neurons (total: 664)
2025-07-15 16:34:13,634 - INFO - Successfully masked 664 neurons across 16 layers
2025-07-15 16:34:13,676 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,676 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,677 - INFO - Step 665: masking 665 neurons (total: 665)
2025-07-15 16:34:13,733 - INFO - Successfully masked 665 neurons across 16 layers
2025-07-15 16:34:13,776 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,776 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,777 - INFO - Step 666: masking 666 neurons (total: 666)
2025-07-15 16:34:13,834 - INFO - Successfully masked 666 neurons across 16 layers
2025-07-15 16:34:13,878 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,878 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,879 - INFO - Step 667: masking 667 neurons (total: 667)
2025-07-15 16:34:13,936 - INFO - Successfully masked 667 neurons across 16 layers
2025-07-15 16:34:13,979 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:13,979 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:13,980 - INFO - Step 668: masking 668 neurons (total: 668)
2025-07-15 16:34:14,037 - INFO - Successfully masked 668 neurons across 16 layers
2025-07-15 16:34:14,080 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,080 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,081 - INFO - Step 669: masking 669 neurons (total: 669)
2025-07-15 16:34:14,138 - INFO - Successfully masked 669 neurons across 16 layers
2025-07-15 16:34:14,181 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,181 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,182 - INFO - Step 670: masking 670 neurons (total: 670)
2025-07-15 16:34:14,239 - INFO - Successfully masked 670 neurons across 16 layers
2025-07-15 16:34:14,282 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,282 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,283 - INFO - Step 671: masking 671 neurons (total: 671)
2025-07-15 16:34:14,340 - INFO - Successfully masked 671 neurons across 16 layers
2025-07-15 16:34:14,383 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,383 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,384 - INFO - Step 672: masking 672 neurons (total: 672)
2025-07-15 16:34:14,441 - INFO - Successfully masked 672 neurons across 16 layers
2025-07-15 16:34:14,484 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,484 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,485 - INFO - Step 673: masking 673 neurons (total: 673)
2025-07-15 16:34:14,542 - INFO - Successfully masked 673 neurons across 16 layers
2025-07-15 16:34:14,585 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,585 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,586 - INFO - Step 674: masking 674 neurons (total: 674)
2025-07-15 16:34:14,643 - INFO - Successfully masked 674 neurons across 16 layers
2025-07-15 16:34:14,685 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,686 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,687 - INFO - Step 675: masking 675 neurons (total: 675)
2025-07-15 16:34:14,744 - INFO - Successfully masked 675 neurons across 17 layers
2025-07-15 16:34:14,786 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,787 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,787 - INFO - Step 676: masking 676 neurons (total: 676)
2025-07-15 16:34:14,844 - INFO - Successfully masked 676 neurons across 17 layers
2025-07-15 16:34:14,887 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,887 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,888 - INFO - Step 677: masking 677 neurons (total: 677)
2025-07-15 16:34:14,945 - INFO - Successfully masked 677 neurons across 17 layers
2025-07-15 16:34:14,988 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:14,988 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:14,989 - INFO - Step 678: masking 678 neurons (total: 678)
2025-07-15 16:34:15,046 - INFO - Successfully masked 678 neurons across 17 layers
2025-07-15 16:34:15,089 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,089 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,090 - INFO - Step 679: masking 679 neurons (total: 679)
2025-07-15 16:34:15,147 - INFO - Successfully masked 679 neurons across 17 layers
2025-07-15 16:34:15,190 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,190 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,191 - INFO - Step 680: masking 680 neurons (total: 680)
2025-07-15 16:34:15,248 - INFO - Successfully masked 680 neurons across 17 layers
2025-07-15 16:34:15,291 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,291 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,292 - INFO - Step 681: masking 681 neurons (total: 681)
2025-07-15 16:34:15,350 - INFO - Successfully masked 681 neurons across 17 layers
2025-07-15 16:34:15,393 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,394 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,395 - INFO - Step 682: masking 682 neurons (total: 682)
2025-07-15 16:34:15,452 - INFO - Successfully masked 682 neurons across 17 layers
2025-07-15 16:34:15,496 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,497 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,498 - INFO - Step 683: masking 683 neurons (total: 683)
2025-07-15 16:34:15,557 - INFO - Successfully masked 683 neurons across 17 layers
2025-07-15 16:34:15,600 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,600 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,601 - INFO - Step 684: masking 684 neurons (total: 684)
2025-07-15 16:34:15,657 - INFO - Successfully masked 684 neurons across 17 layers
2025-07-15 16:34:15,698 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,698 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,699 - INFO - Step 685: masking 685 neurons (total: 685)
2025-07-15 16:34:15,755 - INFO - Successfully masked 685 neurons across 17 layers
2025-07-15 16:34:15,795 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,796 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,797 - INFO - Step 686: masking 686 neurons (total: 686)
2025-07-15 16:34:15,852 - INFO - Successfully masked 686 neurons across 17 layers
2025-07-15 16:34:15,893 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,893 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,894 - INFO - Step 687: masking 687 neurons (total: 687)
2025-07-15 16:34:15,949 - INFO - Successfully masked 687 neurons across 18 layers
2025-07-15 16:34:15,990 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:15,990 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:15,991 - INFO - Step 688: masking 688 neurons (total: 688)
2025-07-15 16:34:16,047 - INFO - Successfully masked 688 neurons across 18 layers
2025-07-15 16:34:16,089 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,090 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,090 - INFO - Step 689: masking 689 neurons (total: 689)
2025-07-15 16:34:16,146 - INFO - Successfully masked 689 neurons across 18 layers
2025-07-15 16:34:16,188 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,189 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,190 - INFO - Step 690: masking 690 neurons (total: 690)
2025-07-15 16:34:16,245 - INFO - Successfully masked 690 neurons across 18 layers
2025-07-15 16:34:16,286 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,286 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,287 - INFO - Step 691: masking 691 neurons (total: 691)
2025-07-15 16:34:16,343 - INFO - Successfully masked 691 neurons across 18 layers
2025-07-15 16:34:16,384 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,384 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,385 - INFO - Step 692: masking 692 neurons (total: 692)
2025-07-15 16:34:16,441 - INFO - Successfully masked 692 neurons across 18 layers
2025-07-15 16:34:16,482 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,483 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,483 - INFO - Step 693: masking 693 neurons (total: 693)
2025-07-15 16:34:16,539 - INFO - Successfully masked 693 neurons across 18 layers
2025-07-15 16:34:16,580 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,580 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,581 - INFO - Step 694: masking 694 neurons (total: 694)
2025-07-15 16:34:16,637 - INFO - Successfully masked 694 neurons across 18 layers
2025-07-15 16:34:16,678 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,678 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,679 - INFO - Step 695: masking 695 neurons (total: 695)
2025-07-15 16:34:16,734 - INFO - Successfully masked 695 neurons across 18 layers
2025-07-15 16:34:16,775 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,776 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,776 - INFO - Step 696: masking 696 neurons (total: 696)
2025-07-15 16:34:16,832 - INFO - Successfully masked 696 neurons across 18 layers
2025-07-15 16:34:16,873 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,874 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,875 - INFO - Step 697: masking 697 neurons (total: 697)
2025-07-15 16:34:16,933 - INFO - Successfully masked 697 neurons across 18 layers
2025-07-15 16:34:16,976 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:16,976 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:16,977 - INFO - Step 698: masking 698 neurons (total: 698)
2025-07-15 16:34:17,034 - INFO - Successfully masked 698 neurons across 18 layers
2025-07-15 16:34:17,076 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,077 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,078 - INFO - Step 699: masking 699 neurons (total: 699)
2025-07-15 16:34:17,136 - INFO - Successfully masked 699 neurons across 18 layers
2025-07-15 16:34:17,179 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,179 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,180 - INFO - Step 700: masking 700 neurons (total: 700)
2025-07-15 16:34:17,239 - INFO - Successfully masked 700 neurons across 18 layers
2025-07-15 16:34:17,282 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,282 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,288 - INFO - Step 701: masking 701 neurons (total: 701)
2025-07-15 16:34:17,345 - INFO - Successfully masked 701 neurons across 18 layers
2025-07-15 16:34:17,388 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,388 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,389 - INFO - Step 702: masking 702 neurons (total: 702)
2025-07-15 16:34:17,446 - INFO - Successfully masked 702 neurons across 18 layers
2025-07-15 16:34:17,489 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,489 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,490 - INFO - Step 703: masking 703 neurons (total: 703)
2025-07-15 16:34:17,547 - INFO - Successfully masked 703 neurons across 18 layers
2025-07-15 16:34:17,589 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,590 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,591 - INFO - Step 704: masking 704 neurons (total: 704)
2025-07-15 16:34:17,648 - INFO - Successfully masked 704 neurons across 18 layers
2025-07-15 16:34:17,690 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,690 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,691 - INFO - Step 705: masking 705 neurons (total: 705)
2025-07-15 16:34:17,748 - INFO - Successfully masked 705 neurons across 18 layers
2025-07-15 16:34:17,790 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,791 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,792 - INFO - Step 706: masking 706 neurons (total: 706)
2025-07-15 16:34:17,849 - INFO - Successfully masked 706 neurons across 18 layers
2025-07-15 16:34:17,891 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,891 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,892 - INFO - Step 707: masking 707 neurons (total: 707)
2025-07-15 16:34:17,949 - INFO - Successfully masked 707 neurons across 18 layers
2025-07-15 16:34:17,991 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:17,992 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:17,993 - INFO - Step 708: masking 708 neurons (total: 708)
2025-07-15 16:34:18,051 - INFO - Successfully masked 708 neurons across 18 layers
2025-07-15 16:34:18,093 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,094 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,095 - INFO - Step 709: masking 709 neurons (total: 709)
2025-07-15 16:34:18,152 - INFO - Successfully masked 709 neurons across 18 layers
2025-07-15 16:34:18,195 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,195 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,196 - INFO - Step 710: masking 710 neurons (total: 710)
2025-07-15 16:34:18,253 - INFO - Successfully masked 710 neurons across 18 layers
2025-07-15 16:34:18,296 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,296 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,297 - INFO - Step 711: masking 711 neurons (total: 711)
2025-07-15 16:34:18,354 - INFO - Successfully masked 711 neurons across 18 layers
2025-07-15 16:34:18,396 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,397 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,398 - INFO - Step 712: masking 712 neurons (total: 712)
2025-07-15 16:34:18,455 - INFO - Successfully masked 712 neurons across 18 layers
2025-07-15 16:34:18,497 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,498 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,498 - INFO - Step 713: masking 713 neurons (total: 713)
2025-07-15 16:34:18,556 - INFO - Successfully masked 713 neurons across 18 layers
2025-07-15 16:34:18,599 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,599 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,600 - INFO - Step 714: masking 714 neurons (total: 714)
2025-07-15 16:34:18,657 - INFO - Successfully masked 714 neurons across 18 layers
2025-07-15 16:34:18,699 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,700 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,701 - INFO - Step 715: masking 715 neurons (total: 715)
2025-07-15 16:34:18,758 - INFO - Successfully masked 715 neurons across 18 layers
2025-07-15 16:34:18,800 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,801 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,801 - INFO - Step 716: masking 716 neurons (total: 716)
2025-07-15 16:34:18,859 - INFO - Successfully masked 716 neurons across 18 layers
2025-07-15 16:34:18,901 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:18,901 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:18,902 - INFO - Step 717: masking 717 neurons (total: 717)
2025-07-15 16:34:18,959 - INFO - Successfully masked 717 neurons across 18 layers
2025-07-15 16:34:19,002 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,002 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,003 - INFO - Step 718: masking 718 neurons (total: 718)
2025-07-15 16:34:19,060 - INFO - Successfully masked 718 neurons across 18 layers
2025-07-15 16:34:19,103 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,103 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,104 - INFO - Step 719: masking 719 neurons (total: 719)
2025-07-15 16:34:19,161 - INFO - Successfully masked 719 neurons across 18 layers
2025-07-15 16:34:19,203 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,204 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,205 - INFO - Step 720: masking 720 neurons (total: 720)
2025-07-15 16:34:19,262 - INFO - Successfully masked 720 neurons across 18 layers
2025-07-15 16:34:19,305 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,305 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,306 - INFO - Step 721: masking 721 neurons (total: 721)
2025-07-15 16:34:19,363 - INFO - Successfully masked 721 neurons across 18 layers
2025-07-15 16:34:19,405 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,406 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,407 - INFO - Step 722: masking 722 neurons (total: 722)
2025-07-15 16:34:19,464 - INFO - Successfully masked 722 neurons across 18 layers
2025-07-15 16:34:19,507 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,508 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,509 - INFO - Step 723: masking 723 neurons (total: 723)
2025-07-15 16:34:19,568 - INFO - Successfully masked 723 neurons across 18 layers
2025-07-15 16:34:19,609 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,609 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,610 - INFO - Step 724: masking 724 neurons (total: 724)
2025-07-15 16:34:19,666 - INFO - Successfully masked 724 neurons across 18 layers
2025-07-15 16:34:19,707 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,707 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,708 - INFO - Step 725: masking 725 neurons (total: 725)
2025-07-15 16:34:19,764 - INFO - Successfully masked 725 neurons across 18 layers
2025-07-15 16:34:19,805 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,806 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,806 - INFO - Step 726: masking 726 neurons (total: 726)
2025-07-15 16:34:19,863 - INFO - Successfully masked 726 neurons across 18 layers
2025-07-15 16:34:19,906 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:19,906 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:19,907 - INFO - Step 727: masking 727 neurons (total: 727)
2025-07-15 16:34:19,965 - INFO - Successfully masked 727 neurons across 18 layers
2025-07-15 16:34:20,007 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,008 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,009 - INFO - Step 728: masking 728 neurons (total: 728)
2025-07-15 16:34:20,066 - INFO - Successfully masked 728 neurons across 18 layers
2025-07-15 16:34:20,109 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,109 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,110 - INFO - Step 729: masking 729 neurons (total: 729)
2025-07-15 16:34:20,168 - INFO - Successfully masked 729 neurons across 18 layers
2025-07-15 16:34:20,210 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,210 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,211 - INFO - Step 730: masking 730 neurons (total: 730)
2025-07-15 16:34:20,269 - INFO - Successfully masked 730 neurons across 18 layers
2025-07-15 16:34:20,311 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,311 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,312 - INFO - Step 731: masking 731 neurons (total: 731)
2025-07-15 16:34:20,370 - INFO - Successfully masked 731 neurons across 18 layers
2025-07-15 16:34:20,412 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,412 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,413 - INFO - Step 732: masking 732 neurons (total: 732)
2025-07-15 16:34:20,471 - INFO - Successfully masked 732 neurons across 18 layers
2025-07-15 16:34:20,513 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,514 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,514 - INFO - Step 733: masking 733 neurons (total: 733)
2025-07-15 16:34:20,572 - INFO - Successfully masked 733 neurons across 18 layers
2025-07-15 16:34:20,615 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,615 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,616 - INFO - Step 734: masking 734 neurons (total: 734)
2025-07-15 16:34:20,674 - INFO - Successfully masked 734 neurons across 18 layers
2025-07-15 16:34:20,716 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,716 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,717 - INFO - Step 735: masking 735 neurons (total: 735)
2025-07-15 16:34:20,777 - INFO - Successfully masked 735 neurons across 18 layers
2025-07-15 16:34:20,820 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,820 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,821 - INFO - Step 736: masking 736 neurons (total: 736)
2025-07-15 16:34:20,879 - INFO - Successfully masked 736 neurons across 18 layers
2025-07-15 16:34:20,922 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:20,922 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:20,923 - INFO - Step 737: masking 737 neurons (total: 737)
2025-07-15 16:34:20,982 - INFO - Successfully masked 737 neurons across 18 layers
2025-07-15 16:34:21,024 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,025 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,026 - INFO - Step 738: masking 738 neurons (total: 738)
2025-07-15 16:34:21,084 - INFO - Successfully masked 738 neurons across 18 layers
2025-07-15 16:34:21,127 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,127 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,128 - INFO - Step 739: masking 739 neurons (total: 739)
2025-07-15 16:34:21,186 - INFO - Successfully masked 739 neurons across 18 layers
2025-07-15 16:34:21,229 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,229 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,230 - INFO - Step 740: masking 740 neurons (total: 740)
2025-07-15 16:34:21,289 - INFO - Successfully masked 740 neurons across 18 layers
2025-07-15 16:34:21,332 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,332 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,333 - INFO - Step 741: masking 741 neurons (total: 741)
2025-07-15 16:34:21,392 - INFO - Successfully masked 741 neurons across 18 layers
2025-07-15 16:34:21,435 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,435 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,436 - INFO - Step 742: masking 742 neurons (total: 742)
2025-07-15 16:34:21,495 - INFO - Successfully masked 742 neurons across 18 layers
2025-07-15 16:34:21,538 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,538 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,539 - INFO - Step 743: masking 743 neurons (total: 743)
2025-07-15 16:34:21,598 - INFO - Successfully masked 743 neurons across 18 layers
2025-07-15 16:34:21,641 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,641 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,642 - INFO - Step 744: masking 744 neurons (total: 744)
2025-07-15 16:34:21,701 - INFO - Successfully masked 744 neurons across 18 layers
2025-07-15 16:34:21,744 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,744 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,745 - INFO - Step 745: masking 745 neurons (total: 745)
2025-07-15 16:34:21,804 - INFO - Successfully masked 745 neurons across 18 layers
2025-07-15 16:34:21,846 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,846 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,847 - INFO - Step 746: masking 746 neurons (total: 746)
2025-07-15 16:34:21,906 - INFO - Successfully masked 746 neurons across 18 layers
2025-07-15 16:34:21,949 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:21,949 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:21,950 - INFO - Step 747: masking 747 neurons (total: 747)
2025-07-15 16:34:22,009 - INFO - Successfully masked 747 neurons across 18 layers
2025-07-15 16:34:22,053 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,053 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,054 - INFO - Step 748: masking 748 neurons (total: 748)
2025-07-15 16:34:22,115 - INFO - Successfully masked 748 neurons across 18 layers
2025-07-15 16:34:22,158 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,158 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,159 - INFO - Step 749: masking 749 neurons (total: 749)
2025-07-15 16:34:22,218 - INFO - Successfully masked 749 neurons across 18 layers
2025-07-15 16:34:22,261 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,261 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,262 - INFO - Step 750: masking 750 neurons (total: 750)
2025-07-15 16:34:22,321 - INFO - Successfully masked 750 neurons across 18 layers
2025-07-15 16:34:22,363 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,364 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,365 - INFO - Step 751: masking 751 neurons (total: 751)
2025-07-15 16:34:22,423 - INFO - Successfully masked 751 neurons across 18 layers
2025-07-15 16:34:22,466 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,467 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,468 - INFO - Step 752: masking 752 neurons (total: 752)
2025-07-15 16:34:22,527 - INFO - Successfully masked 752 neurons across 18 layers
2025-07-15 16:34:22,570 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,570 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,571 - INFO - Step 753: masking 753 neurons (total: 753)
2025-07-15 16:34:22,631 - INFO - Successfully masked 753 neurons across 18 layers
2025-07-15 16:34:22,674 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,674 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,675 - INFO - Step 754: masking 754 neurons (total: 754)
2025-07-15 16:34:22,735 - INFO - Successfully masked 754 neurons across 18 layers
2025-07-15 16:34:22,778 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,778 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,779 - INFO - Step 755: masking 755 neurons (total: 755)
2025-07-15 16:34:22,838 - INFO - Successfully masked 755 neurons across 18 layers
2025-07-15 16:34:22,880 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,880 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,881 - INFO - Step 756: masking 756 neurons (total: 756)
2025-07-15 16:34:22,940 - INFO - Successfully masked 756 neurons across 18 layers
2025-07-15 16:34:22,983 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:22,983 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:22,984 - INFO - Step 757: masking 757 neurons (total: 757)
2025-07-15 16:34:23,042 - INFO - Successfully masked 757 neurons across 18 layers
2025-07-15 16:34:23,085 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,085 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,086 - INFO - Step 758: masking 758 neurons (total: 758)
2025-07-15 16:34:23,145 - INFO - Successfully masked 758 neurons across 18 layers
2025-07-15 16:34:23,188 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,188 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,189 - INFO - Step 759: masking 759 neurons (total: 759)
2025-07-15 16:34:23,248 - INFO - Successfully masked 759 neurons across 18 layers
2025-07-15 16:34:23,291 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,291 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,292 - INFO - Step 760: masking 760 neurons (total: 760)
2025-07-15 16:34:23,351 - INFO - Successfully masked 760 neurons across 18 layers
2025-07-15 16:34:23,393 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,394 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,395 - INFO - Step 761: masking 761 neurons (total: 761)
2025-07-15 16:34:23,454 - INFO - Successfully masked 761 neurons across 18 layers
2025-07-15 16:34:23,496 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,497 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,498 - INFO - Step 762: masking 762 neurons (total: 762)
2025-07-15 16:34:23,556 - INFO - Successfully masked 762 neurons across 18 layers
2025-07-15 16:34:23,599 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,599 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,600 - INFO - Step 763: masking 763 neurons (total: 763)
2025-07-15 16:34:23,660 - INFO - Successfully masked 763 neurons across 18 layers
2025-07-15 16:34:23,703 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,703 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,704 - INFO - Step 764: masking 764 neurons (total: 764)
2025-07-15 16:34:23,763 - INFO - Successfully masked 764 neurons across 18 layers
2025-07-15 16:34:23,805 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,806 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,807 - INFO - Step 765: masking 765 neurons (total: 765)
2025-07-15 16:34:23,866 - INFO - Successfully masked 765 neurons across 18 layers
2025-07-15 16:34:23,908 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:23,909 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:23,910 - INFO - Step 766: masking 766 neurons (total: 766)
2025-07-15 16:34:23,969 - INFO - Successfully masked 766 neurons across 18 layers
2025-07-15 16:34:24,011 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,012 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,013 - INFO - Step 767: masking 767 neurons (total: 767)
2025-07-15 16:34:24,074 - INFO - Successfully masked 767 neurons across 18 layers
2025-07-15 16:34:24,117 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,117 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,118 - INFO - Step 768: masking 768 neurons (total: 768)
2025-07-15 16:34:24,177 - INFO - Successfully masked 768 neurons across 18 layers
2025-07-15 16:34:24,220 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,220 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,221 - INFO - Step 769: masking 769 neurons (total: 769)
2025-07-15 16:34:24,280 - INFO - Successfully masked 769 neurons across 18 layers
2025-07-15 16:34:24,322 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,323 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,324 - INFO - Step 770: masking 770 neurons (total: 770)
2025-07-15 16:34:24,383 - INFO - Successfully masked 770 neurons across 18 layers
2025-07-15 16:34:24,425 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,425 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,426 - INFO - Step 771: masking 771 neurons (total: 771)
2025-07-15 16:34:24,485 - INFO - Successfully masked 771 neurons across 18 layers
2025-07-15 16:34:24,527 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,527 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,528 - INFO - Step 772: masking 772 neurons (total: 772)
2025-07-15 16:34:24,587 - INFO - Successfully masked 772 neurons across 18 layers
2025-07-15 16:34:24,630 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,630 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,631 - INFO - Step 773: masking 773 neurons (total: 773)
2025-07-15 16:34:24,690 - INFO - Successfully masked 773 neurons across 18 layers
2025-07-15 16:34:24,732 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,732 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,734 - INFO - Step 774: masking 774 neurons (total: 774)
2025-07-15 16:34:24,794 - INFO - Successfully masked 774 neurons across 18 layers
2025-07-15 16:34:24,838 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,838 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,839 - INFO - Step 775: masking 775 neurons (total: 775)
2025-07-15 16:34:24,899 - INFO - Successfully masked 775 neurons across 18 layers
2025-07-15 16:34:24,943 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:24,943 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:24,944 - INFO - Step 776: masking 776 neurons (total: 776)
2025-07-15 16:34:25,003 - INFO - Successfully masked 776 neurons across 18 layers
2025-07-15 16:34:25,045 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,046 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,047 - INFO - Step 777: masking 777 neurons (total: 777)
2025-07-15 16:34:25,106 - INFO - Successfully masked 777 neurons across 18 layers
2025-07-15 16:34:25,148 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,148 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,149 - INFO - Step 778: masking 778 neurons (total: 778)
2025-07-15 16:34:25,208 - INFO - Successfully masked 778 neurons across 18 layers
2025-07-15 16:34:25,250 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,251 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,252 - INFO - Step 779: masking 779 neurons (total: 779)
2025-07-15 16:34:25,313 - INFO - Successfully masked 779 neurons across 18 layers
2025-07-15 16:34:25,356 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,356 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,357 - INFO - Step 780: masking 780 neurons (total: 780)
2025-07-15 16:34:25,418 - INFO - Successfully masked 780 neurons across 18 layers
2025-07-15 16:34:25,462 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,463 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,465 - INFO - Step 781: masking 781 neurons (total: 781)
2025-07-15 16:34:25,524 - INFO - Successfully masked 781 neurons across 18 layers
2025-07-15 16:34:25,565 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,566 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,567 - INFO - Step 782: masking 782 neurons (total: 782)
2025-07-15 16:34:25,625 - INFO - Successfully masked 782 neurons across 18 layers
2025-07-15 16:34:25,666 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,666 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,667 - INFO - Step 783: masking 783 neurons (total: 783)
2025-07-15 16:34:25,725 - INFO - Successfully masked 783 neurons across 18 layers
2025-07-15 16:34:25,766 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,766 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,767 - INFO - Step 784: masking 784 neurons (total: 784)
2025-07-15 16:34:25,825 - INFO - Successfully masked 784 neurons across 18 layers
2025-07-15 16:34:25,866 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,866 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,867 - INFO - Step 785: masking 785 neurons (total: 785)
2025-07-15 16:34:25,924 - INFO - Successfully masked 785 neurons across 18 layers
2025-07-15 16:34:25,966 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:25,966 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:25,967 - INFO - Step 786: masking 786 neurons (total: 786)
2025-07-15 16:34:26,025 - INFO - Successfully masked 786 neurons across 18 layers
2025-07-15 16:34:26,066 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,066 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,068 - INFO - Step 787: masking 787 neurons (total: 787)
2025-07-15 16:34:26,129 - INFO - Successfully masked 787 neurons across 18 layers
2025-07-15 16:34:26,171 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,172 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,173 - INFO - Step 788: masking 788 neurons (total: 788)
2025-07-15 16:34:26,232 - INFO - Successfully masked 788 neurons across 18 layers
2025-07-15 16:34:26,274 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,275 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,276 - INFO - Step 789: masking 789 neurons (total: 789)
2025-07-15 16:34:26,336 - INFO - Successfully masked 789 neurons across 18 layers
2025-07-15 16:34:26,377 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,378 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,379 - INFO - Step 790: masking 790 neurons (total: 790)
2025-07-15 16:34:26,440 - INFO - Successfully masked 790 neurons across 18 layers
2025-07-15 16:34:26,482 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,482 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,483 - INFO - Step 791: masking 791 neurons (total: 791)
2025-07-15 16:34:26,542 - INFO - Successfully masked 791 neurons across 18 layers
2025-07-15 16:34:26,584 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,585 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,586 - INFO - Step 792: masking 792 neurons (total: 792)
2025-07-15 16:34:26,645 - INFO - Successfully masked 792 neurons across 18 layers
2025-07-15 16:34:26,687 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,687 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,688 - INFO - Step 793: masking 793 neurons (total: 793)
2025-07-15 16:34:26,747 - INFO - Successfully masked 793 neurons across 18 layers
2025-07-15 16:34:26,789 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,789 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,790 - INFO - Step 794: masking 794 neurons (total: 794)
2025-07-15 16:34:26,849 - INFO - Successfully masked 794 neurons across 18 layers
2025-07-15 16:34:26,891 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,891 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,892 - INFO - Step 795: masking 795 neurons (total: 795)
2025-07-15 16:34:26,951 - INFO - Successfully masked 795 neurons across 18 layers
2025-07-15 16:34:26,993 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:26,994 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:26,994 - INFO - Step 796: masking 796 neurons (total: 796)
2025-07-15 16:34:27,053 - INFO - Successfully masked 796 neurons across 18 layers
2025-07-15 16:34:27,095 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,096 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,097 - INFO - Step 797: masking 797 neurons (total: 797)
2025-07-15 16:34:27,156 - INFO - Successfully masked 797 neurons across 18 layers
2025-07-15 16:34:27,198 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,198 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,199 - INFO - Step 798: masking 798 neurons (total: 798)
2025-07-15 16:34:27,258 - INFO - Successfully masked 798 neurons across 18 layers
2025-07-15 16:34:27,300 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,300 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,301 - INFO - Step 799: masking 799 neurons (total: 799)
2025-07-15 16:34:27,360 - INFO - Successfully masked 799 neurons across 18 layers
2025-07-15 16:34:27,402 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,402 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,403 - INFO - Step 800: masking 800 neurons (total: 800)
2025-07-15 16:34:27,462 - INFO - Successfully masked 800 neurons across 18 layers
2025-07-15 16:34:27,504 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,505 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,505 - INFO - Step 801: masking 801 neurons (total: 801)
2025-07-15 16:34:27,566 - INFO - Successfully masked 801 neurons across 18 layers
2025-07-15 16:34:27,610 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,610 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,611 - INFO - Step 802: masking 802 neurons (total: 802)
2025-07-15 16:34:27,671 - INFO - Successfully masked 802 neurons across 18 layers
2025-07-15 16:34:27,713 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,714 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,715 - INFO - Step 803: masking 803 neurons (total: 803)
2025-07-15 16:34:27,775 - INFO - Successfully masked 803 neurons across 18 layers
2025-07-15 16:34:27,817 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,818 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,819 - INFO - Step 804: masking 804 neurons (total: 804)
2025-07-15 16:34:27,879 - INFO - Successfully masked 804 neurons across 18 layers
2025-07-15 16:34:27,921 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:27,922 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:27,923 - INFO - Step 805: masking 805 neurons (total: 805)
2025-07-15 16:34:27,983 - INFO - Successfully masked 805 neurons across 19 layers
2025-07-15 16:34:28,026 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,026 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,027 - INFO - Step 806: masking 806 neurons (total: 806)
2025-07-15 16:34:28,087 - INFO - Successfully masked 806 neurons across 19 layers
2025-07-15 16:34:28,130 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,130 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,132 - INFO - Step 807: masking 807 neurons (total: 807)
2025-07-15 16:34:28,195 - INFO - Successfully masked 807 neurons across 19 layers
2025-07-15 16:34:28,240 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,240 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,241 - INFO - Step 808: masking 808 neurons (total: 808)
2025-07-15 16:34:28,303 - INFO - Successfully masked 808 neurons across 19 layers
2025-07-15 16:34:28,346 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,347 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,347 - INFO - Step 809: masking 809 neurons (total: 809)
2025-07-15 16:34:28,409 - INFO - Successfully masked 809 neurons across 19 layers
2025-07-15 16:34:28,452 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,453 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,454 - INFO - Step 810: masking 810 neurons (total: 810)
2025-07-15 16:34:28,514 - INFO - Successfully masked 810 neurons across 19 layers
2025-07-15 16:34:28,557 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,557 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,558 - INFO - Step 811: masking 811 neurons (total: 811)
2025-07-15 16:34:28,619 - INFO - Successfully masked 811 neurons across 19 layers
2025-07-15 16:34:28,662 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,662 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,663 - INFO - Step 812: masking 812 neurons (total: 812)
2025-07-15 16:34:28,724 - INFO - Successfully masked 812 neurons across 19 layers
2025-07-15 16:34:28,766 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,766 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,767 - INFO - Step 813: masking 813 neurons (total: 813)
2025-07-15 16:34:28,827 - INFO - Successfully masked 813 neurons across 19 layers
2025-07-15 16:34:28,870 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,871 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,872 - INFO - Step 814: masking 814 neurons (total: 814)
2025-07-15 16:34:28,933 - INFO - Successfully masked 814 neurons across 19 layers
2025-07-15 16:34:28,976 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:28,977 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:28,978 - INFO - Step 815: masking 815 neurons (total: 815)
2025-07-15 16:34:29,038 - INFO - Successfully masked 815 neurons across 19 layers
2025-07-15 16:34:29,082 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,082 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,083 - INFO - Step 816: masking 816 neurons (total: 816)
2025-07-15 16:34:29,145 - INFO - Successfully masked 816 neurons across 19 layers
2025-07-15 16:34:29,188 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,188 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,189 - INFO - Step 817: masking 817 neurons (total: 817)
2025-07-15 16:34:29,250 - INFO - Successfully masked 817 neurons across 19 layers
2025-07-15 16:34:29,294 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,294 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,295 - INFO - Step 818: masking 818 neurons (total: 818)
2025-07-15 16:34:29,356 - INFO - Successfully masked 818 neurons across 19 layers
2025-07-15 16:34:29,398 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,399 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,400 - INFO - Step 819: masking 819 neurons (total: 819)
2025-07-15 16:34:29,460 - INFO - Successfully masked 819 neurons across 19 layers
2025-07-15 16:34:29,503 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,503 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,504 - INFO - Step 820: masking 820 neurons (total: 820)
2025-07-15 16:34:29,564 - INFO - Successfully masked 820 neurons across 19 layers
2025-07-15 16:34:29,607 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,607 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,608 - INFO - Step 821: masking 821 neurons (total: 821)
2025-07-15 16:34:29,668 - INFO - Successfully masked 821 neurons across 19 layers
2025-07-15 16:34:29,711 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,711 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,712 - INFO - Step 822: masking 822 neurons (total: 822)
2025-07-15 16:34:29,773 - INFO - Successfully masked 822 neurons across 19 layers
2025-07-15 16:34:29,815 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,816 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,817 - INFO - Step 823: masking 823 neurons (total: 823)
2025-07-15 16:34:29,879 - INFO - Successfully masked 823 neurons across 19 layers
2025-07-15 16:34:29,922 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:29,922 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:29,923 - INFO - Step 824: masking 824 neurons (total: 824)
2025-07-15 16:34:29,984 - INFO - Successfully masked 824 neurons across 19 layers
2025-07-15 16:34:30,027 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,027 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,028 - INFO - Step 825: masking 825 neurons (total: 825)
2025-07-15 16:34:30,089 - INFO - Successfully masked 825 neurons across 19 layers
2025-07-15 16:34:30,131 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,132 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,132 - INFO - Step 826: masking 826 neurons (total: 826)
2025-07-15 16:34:30,192 - INFO - Successfully masked 826 neurons across 19 layers
2025-07-15 16:34:30,235 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,235 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,236 - INFO - Step 827: masking 827 neurons (total: 827)
2025-07-15 16:34:30,297 - INFO - Successfully masked 827 neurons across 19 layers
2025-07-15 16:34:30,339 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,339 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,340 - INFO - Step 828: masking 828 neurons (total: 828)
2025-07-15 16:34:30,400 - INFO - Successfully masked 828 neurons across 19 layers
2025-07-15 16:34:30,443 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,444 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,444 - INFO - Step 829: masking 829 neurons (total: 829)
2025-07-15 16:34:30,505 - INFO - Successfully masked 829 neurons across 19 layers
2025-07-15 16:34:30,547 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,547 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,548 - INFO - Step 830: masking 830 neurons (total: 830)
2025-07-15 16:34:30,609 - INFO - Successfully masked 830 neurons across 19 layers
2025-07-15 16:34:30,651 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,652 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,652 - INFO - Step 831: masking 831 neurons (total: 831)
2025-07-15 16:34:30,713 - INFO - Successfully masked 831 neurons across 19 layers
2025-07-15 16:34:30,755 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,756 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,756 - INFO - Step 832: masking 832 neurons (total: 832)
2025-07-15 16:34:30,817 - INFO - Successfully masked 832 neurons across 19 layers
2025-07-15 16:34:30,859 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,859 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,860 - INFO - Step 833: masking 833 neurons (total: 833)
2025-07-15 16:34:30,921 - INFO - Successfully masked 833 neurons across 19 layers
2025-07-15 16:34:30,964 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:30,964 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:30,965 - INFO - Step 834: masking 834 neurons (total: 834)
2025-07-15 16:34:31,026 - INFO - Successfully masked 834 neurons across 19 layers
2025-07-15 16:34:31,068 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,069 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,070 - INFO - Step 835: masking 835 neurons (total: 835)
2025-07-15 16:34:31,131 - INFO - Successfully masked 835 neurons across 19 layers
2025-07-15 16:34:31,174 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,174 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,175 - INFO - Step 836: masking 836 neurons (total: 836)
2025-07-15 16:34:31,236 - INFO - Successfully masked 836 neurons across 19 layers
2025-07-15 16:34:31,279 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,279 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,280 - INFO - Step 837: masking 837 neurons (total: 837)
2025-07-15 16:34:31,341 - INFO - Successfully masked 837 neurons across 19 layers
2025-07-15 16:34:31,385 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,385 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,386 - INFO - Step 838: masking 838 neurons (total: 838)
2025-07-15 16:34:31,447 - INFO - Successfully masked 838 neurons across 19 layers
2025-07-15 16:34:31,489 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,490 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,491 - INFO - Step 839: masking 839 neurons (total: 839)
2025-07-15 16:34:31,551 - INFO - Successfully masked 839 neurons across 19 layers
2025-07-15 16:34:31,594 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,594 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,595 - INFO - Step 840: masking 840 neurons (total: 840)
2025-07-15 16:34:31,656 - INFO - Successfully masked 840 neurons across 19 layers
2025-07-15 16:34:31,698 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,699 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,700 - INFO - Step 841: masking 841 neurons (total: 841)
2025-07-15 16:34:31,760 - INFO - Successfully masked 841 neurons across 19 layers
2025-07-15 16:34:31,803 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,803 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,804 - INFO - Step 842: masking 842 neurons (total: 842)
2025-07-15 16:34:31,865 - INFO - Successfully masked 842 neurons across 19 layers
2025-07-15 16:34:31,907 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:31,907 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:31,908 - INFO - Step 843: masking 843 neurons (total: 843)
2025-07-15 16:34:31,968 - INFO - Successfully masked 843 neurons across 19 layers
2025-07-15 16:34:32,011 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,011 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,012 - INFO - Step 844: masking 844 neurons (total: 844)
2025-07-15 16:34:32,073 - INFO - Successfully masked 844 neurons across 19 layers
2025-07-15 16:34:32,117 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,117 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,118 - INFO - Step 845: masking 845 neurons (total: 845)
2025-07-15 16:34:32,179 - INFO - Successfully masked 845 neurons across 19 layers
2025-07-15 16:34:32,222 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,222 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,223 - INFO - Step 846: masking 846 neurons (total: 846)
2025-07-15 16:34:32,284 - INFO - Successfully masked 846 neurons across 19 layers
2025-07-15 16:34:32,327 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,327 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,328 - INFO - Step 847: masking 847 neurons (total: 847)
2025-07-15 16:34:32,389 - INFO - Successfully masked 847 neurons across 19 layers
2025-07-15 16:34:32,432 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,432 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,433 - INFO - Step 848: masking 848 neurons (total: 848)
2025-07-15 16:34:32,495 - INFO - Successfully masked 848 neurons across 19 layers
2025-07-15 16:34:32,538 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,538 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,539 - INFO - Step 849: masking 849 neurons (total: 849)
2025-07-15 16:34:32,601 - INFO - Successfully masked 849 neurons across 19 layers
2025-07-15 16:34:32,644 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,644 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,645 - INFO - Step 850: masking 850 neurons (total: 850)
2025-07-15 16:34:32,705 - INFO - Successfully masked 850 neurons across 19 layers
2025-07-15 16:34:32,748 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,748 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,749 - INFO - Step 851: masking 851 neurons (total: 851)
2025-07-15 16:34:32,810 - INFO - Successfully masked 851 neurons across 19 layers
2025-07-15 16:34:32,852 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,852 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,853 - INFO - Step 852: masking 852 neurons (total: 852)
2025-07-15 16:34:32,914 - INFO - Successfully masked 852 neurons across 19 layers
2025-07-15 16:34:32,956 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:32,957 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:32,958 - INFO - Step 853: masking 853 neurons (total: 853)
2025-07-15 16:34:33,018 - INFO - Successfully masked 853 neurons across 19 layers
2025-07-15 16:34:33,061 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,061 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,062 - INFO - Step 854: masking 854 neurons (total: 854)
2025-07-15 16:34:33,123 - INFO - Successfully masked 854 neurons across 19 layers
2025-07-15 16:34:33,166 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,166 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,167 - INFO - Step 855: masking 855 neurons (total: 855)
2025-07-15 16:34:33,227 - INFO - Successfully masked 855 neurons across 19 layers
2025-07-15 16:34:33,270 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,270 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,271 - INFO - Step 856: masking 856 neurons (total: 856)
2025-07-15 16:34:33,332 - INFO - Successfully masked 856 neurons across 19 layers
2025-07-15 16:34:33,376 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,376 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,377 - INFO - Step 857: masking 857 neurons (total: 857)
2025-07-15 16:34:33,438 - INFO - Successfully masked 857 neurons across 19 layers
2025-07-15 16:34:33,481 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,481 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,482 - INFO - Step 858: masking 858 neurons (total: 858)
2025-07-15 16:34:33,543 - INFO - Successfully masked 858 neurons across 19 layers
2025-07-15 16:34:33,586 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,587 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,587 - INFO - Step 859: masking 859 neurons (total: 859)
2025-07-15 16:34:33,649 - INFO - Successfully masked 859 neurons across 19 layers
2025-07-15 16:34:33,692 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,692 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,693 - INFO - Step 860: masking 860 neurons (total: 860)
2025-07-15 16:34:33,754 - INFO - Successfully masked 860 neurons across 19 layers
2025-07-15 16:34:33,797 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,797 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,798 - INFO - Step 861: masking 861 neurons (total: 861)
2025-07-15 16:34:33,861 - INFO - Successfully masked 861 neurons across 19 layers
2025-07-15 16:34:33,903 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:33,904 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:33,905 - INFO - Step 862: masking 862 neurons (total: 862)
2025-07-15 16:34:33,965 - INFO - Successfully masked 862 neurons across 19 layers
2025-07-15 16:34:34,008 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,008 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,009 - INFO - Step 863: masking 863 neurons (total: 863)
2025-07-15 16:34:34,070 - INFO - Successfully masked 863 neurons across 19 layers
2025-07-15 16:34:34,115 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,115 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,116 - INFO - Step 864: masking 864 neurons (total: 864)
2025-07-15 16:34:34,178 - INFO - Successfully masked 864 neurons across 19 layers
2025-07-15 16:34:34,220 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,220 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,221 - INFO - Step 865: masking 865 neurons (total: 865)
2025-07-15 16:34:34,282 - INFO - Successfully masked 865 neurons across 19 layers
2025-07-15 16:34:34,325 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,325 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,326 - INFO - Step 866: masking 866 neurons (total: 866)
2025-07-15 16:34:34,387 - INFO - Successfully masked 866 neurons across 19 layers
2025-07-15 16:34:34,430 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,430 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,431 - INFO - Step 867: masking 867 neurons (total: 867)
2025-07-15 16:34:34,492 - INFO - Successfully masked 867 neurons across 19 layers
2025-07-15 16:34:34,535 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,535 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,536 - INFO - Step 868: masking 868 neurons (total: 868)
2025-07-15 16:34:34,597 - INFO - Successfully masked 868 neurons across 19 layers
2025-07-15 16:34:34,639 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,640 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,641 - INFO - Step 869: masking 869 neurons (total: 869)
2025-07-15 16:34:34,702 - INFO - Successfully masked 869 neurons across 19 layers
2025-07-15 16:34:34,744 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,745 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,746 - INFO - Step 870: masking 870 neurons (total: 870)
2025-07-15 16:34:34,807 - INFO - Successfully masked 870 neurons across 19 layers
2025-07-15 16:34:34,849 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,850 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,850 - INFO - Step 871: masking 871 neurons (total: 871)
2025-07-15 16:34:34,912 - INFO - Successfully masked 871 neurons across 19 layers
2025-07-15 16:34:34,954 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:34,954 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:34,955 - INFO - Step 872: masking 872 neurons (total: 872)
2025-07-15 16:34:35,016 - INFO - Successfully masked 872 neurons across 20 layers
2025-07-15 16:34:35,059 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,059 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,060 - INFO - Step 873: masking 873 neurons (total: 873)
2025-07-15 16:34:35,121 - INFO - Successfully masked 873 neurons across 20 layers
2025-07-15 16:34:35,164 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,164 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,165 - INFO - Step 874: masking 874 neurons (total: 874)
2025-07-15 16:34:35,227 - INFO - Successfully masked 874 neurons across 20 layers
2025-07-15 16:34:35,269 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,270 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,270 - INFO - Step 875: masking 875 neurons (total: 875)
2025-07-15 16:34:35,333 - INFO - Successfully masked 875 neurons across 20 layers
2025-07-15 16:34:35,375 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,375 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,376 - INFO - Step 876: masking 876 neurons (total: 876)
2025-07-15 16:34:35,438 - INFO - Successfully masked 876 neurons across 20 layers
2025-07-15 16:34:35,480 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,480 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,481 - INFO - Step 877: masking 877 neurons (total: 877)
2025-07-15 16:34:35,543 - INFO - Successfully masked 877 neurons across 20 layers
2025-07-15 16:34:35,585 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,586 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,587 - INFO - Step 878: masking 878 neurons (total: 878)
2025-07-15 16:34:35,648 - INFO - Successfully masked 878 neurons across 20 layers
2025-07-15 16:34:35,690 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,690 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,691 - INFO - Step 879: masking 879 neurons (total: 879)
2025-07-15 16:34:35,753 - INFO - Successfully masked 879 neurons across 20 layers
2025-07-15 16:34:35,795 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,795 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,796 - INFO - Step 880: masking 880 neurons (total: 880)
2025-07-15 16:34:35,858 - INFO - Successfully masked 880 neurons across 20 layers
2025-07-15 16:34:35,900 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:35,900 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:35,901 - INFO - Step 881: masking 881 neurons (total: 881)
2025-07-15 16:34:35,963 - INFO - Successfully masked 881 neurons across 20 layers
2025-07-15 16:34:36,005 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,005 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,006 - INFO - Step 882: masking 882 neurons (total: 882)
2025-07-15 16:34:36,069 - INFO - Successfully masked 882 neurons across 20 layers
2025-07-15 16:34:36,113 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,113 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,114 - INFO - Step 883: masking 883 neurons (total: 883)
2025-07-15 16:34:36,176 - INFO - Successfully masked 883 neurons across 20 layers
2025-07-15 16:34:36,219 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,220 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,221 - INFO - Step 884: masking 884 neurons (total: 884)
2025-07-15 16:34:36,282 - INFO - Successfully masked 884 neurons across 20 layers
2025-07-15 16:34:36,323 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,324 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,325 - INFO - Step 885: masking 885 neurons (total: 885)
2025-07-15 16:34:36,386 - INFO - Successfully masked 885 neurons across 20 layers
2025-07-15 16:34:36,428 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,428 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,429 - INFO - Step 886: masking 886 neurons (total: 886)
2025-07-15 16:34:36,490 - INFO - Successfully masked 886 neurons across 20 layers
2025-07-15 16:34:36,532 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,532 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,534 - INFO - Step 887: masking 887 neurons (total: 887)
2025-07-15 16:34:36,596 - INFO - Successfully masked 887 neurons across 20 layers
2025-07-15 16:34:36,637 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,637 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,638 - INFO - Step 888: masking 888 neurons (total: 888)
2025-07-15 16:34:36,699 - INFO - Successfully masked 888 neurons across 20 layers
2025-07-15 16:34:36,740 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,740 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,741 - INFO - Step 889: masking 889 neurons (total: 889)
2025-07-15 16:34:36,801 - INFO - Successfully masked 889 neurons across 20 layers
2025-07-15 16:34:36,842 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,843 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,843 - INFO - Step 890: masking 890 neurons (total: 890)
2025-07-15 16:34:36,904 - INFO - Successfully masked 890 neurons across 20 layers
2025-07-15 16:34:36,947 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:36,948 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:36,949 - INFO - Step 891: masking 891 neurons (total: 891)
2025-07-15 16:34:37,011 - INFO - Successfully masked 891 neurons across 20 layers
2025-07-15 16:34:37,054 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,054 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,055 - INFO - Step 892: masking 892 neurons (total: 892)
2025-07-15 16:34:37,117 - INFO - Successfully masked 892 neurons across 20 layers
2025-07-15 16:34:37,159 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,160 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,161 - INFO - Step 893: masking 893 neurons (total: 893)
2025-07-15 16:34:37,222 - INFO - Successfully masked 893 neurons across 20 layers
2025-07-15 16:34:37,264 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,265 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,266 - INFO - Step 894: masking 894 neurons (total: 894)
2025-07-15 16:34:37,328 - INFO - Successfully masked 894 neurons across 20 layers
2025-07-15 16:34:37,370 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,370 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,371 - INFO - Step 895: masking 895 neurons (total: 895)
2025-07-15 16:34:37,433 - INFO - Successfully masked 895 neurons across 20 layers
2025-07-15 16:34:37,475 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,475 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,476 - INFO - Step 896: masking 896 neurons (total: 896)
2025-07-15 16:34:37,537 - INFO - Successfully masked 896 neurons across 20 layers
2025-07-15 16:34:37,580 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,580 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,581 - INFO - Step 897: masking 897 neurons (total: 897)
2025-07-15 16:34:37,643 - INFO - Successfully masked 897 neurons across 20 layers
2025-07-15 16:34:37,685 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,685 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,686 - INFO - Step 898: masking 898 neurons (total: 898)
2025-07-15 16:34:37,748 - INFO - Successfully masked 898 neurons across 20 layers
2025-07-15 16:34:37,790 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,790 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,791 - INFO - Step 899: masking 899 neurons (total: 899)
2025-07-15 16:34:37,853 - INFO - Successfully masked 899 neurons across 20 layers
2025-07-15 16:34:37,895 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:37,896 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:37,897 - INFO - Step 900: masking 900 neurons (total: 900)
2025-07-15 16:34:37,958 - INFO - Successfully masked 900 neurons across 20 layers
2025-07-15 16:34:38,001 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,001 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,002 - INFO - Step 901: masking 901 neurons (total: 901)
2025-07-15 16:34:38,064 - INFO - Successfully masked 901 neurons across 20 layers
2025-07-15 16:34:38,106 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,107 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,108 - INFO - Step 902: masking 902 neurons (total: 902)
2025-07-15 16:34:38,170 - INFO - Successfully masked 902 neurons across 20 layers
2025-07-15 16:34:38,212 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,212 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,213 - INFO - Step 903: masking 903 neurons (total: 903)
2025-07-15 16:34:38,275 - INFO - Successfully masked 903 neurons across 20 layers
2025-07-15 16:34:38,317 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,317 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,318 - INFO - Step 904: masking 904 neurons (total: 904)
2025-07-15 16:34:38,380 - INFO - Successfully masked 904 neurons across 20 layers
2025-07-15 16:34:38,423 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,423 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,424 - INFO - Step 905: masking 905 neurons (total: 905)
2025-07-15 16:34:38,486 - INFO - Successfully masked 905 neurons across 20 layers
2025-07-15 16:34:38,528 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,528 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,529 - INFO - Step 906: masking 906 neurons (total: 906)
2025-07-15 16:34:38,591 - INFO - Successfully masked 906 neurons across 20 layers
2025-07-15 16:34:38,635 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,635 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,636 - INFO - Step 907: masking 907 neurons (total: 907)
2025-07-15 16:34:38,698 - INFO - Successfully masked 907 neurons across 20 layers
2025-07-15 16:34:38,741 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,741 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,742 - INFO - Step 908: masking 908 neurons (total: 908)
2025-07-15 16:34:38,804 - INFO - Successfully masked 908 neurons across 20 layers
2025-07-15 16:34:38,846 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,846 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,847 - INFO - Step 909: masking 909 neurons (total: 909)
2025-07-15 16:34:38,909 - INFO - Successfully masked 909 neurons across 20 layers
2025-07-15 16:34:38,951 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:38,951 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:38,952 - INFO - Step 910: masking 910 neurons (total: 910)
2025-07-15 16:34:39,014 - INFO - Successfully masked 910 neurons across 20 layers
2025-07-15 16:34:39,056 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,056 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,057 - INFO - Step 911: masking 911 neurons (total: 911)
2025-07-15 16:34:39,119 - INFO - Successfully masked 911 neurons across 20 layers
2025-07-15 16:34:39,162 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,162 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,163 - INFO - Step 912: masking 912 neurons (total: 912)
2025-07-15 16:34:39,225 - INFO - Successfully masked 912 neurons across 20 layers
2025-07-15 16:34:39,267 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,268 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,269 - INFO - Step 913: masking 913 neurons (total: 913)
2025-07-15 16:34:39,331 - INFO - Successfully masked 913 neurons across 20 layers
2025-07-15 16:34:39,373 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,373 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,374 - INFO - Step 914: masking 914 neurons (total: 914)
2025-07-15 16:34:39,436 - INFO - Successfully masked 914 neurons across 20 layers
2025-07-15 16:34:39,479 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,479 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,480 - INFO - Step 915: masking 915 neurons (total: 915)
2025-07-15 16:34:39,542 - INFO - Successfully masked 915 neurons across 20 layers
2025-07-15 16:34:39,585 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,585 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,586 - INFO - Step 916: masking 916 neurons (total: 916)
2025-07-15 16:34:39,651 - INFO - Successfully masked 916 neurons across 20 layers
2025-07-15 16:34:39,693 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,694 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,694 - INFO - Step 917: masking 917 neurons (total: 917)
2025-07-15 16:34:39,757 - INFO - Successfully masked 917 neurons across 20 layers
2025-07-15 16:34:39,799 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,800 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,801 - INFO - Step 918: masking 918 neurons (total: 918)
2025-07-15 16:34:39,863 - INFO - Successfully masked 918 neurons across 20 layers
2025-07-15 16:34:39,905 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:39,906 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:39,907 - INFO - Step 919: masking 919 neurons (total: 919)
2025-07-15 16:34:39,969 - INFO - Successfully masked 919 neurons across 20 layers
2025-07-15 16:34:40,011 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,012 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,012 - INFO - Step 920: masking 920 neurons (total: 920)
2025-07-15 16:34:40,075 - INFO - Successfully masked 920 neurons across 20 layers
2025-07-15 16:34:40,117 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,117 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,118 - INFO - Step 921: masking 921 neurons (total: 921)
2025-07-15 16:34:40,181 - INFO - Successfully masked 921 neurons across 20 layers
2025-07-15 16:34:40,223 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,224 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,224 - INFO - Step 922: masking 922 neurons (total: 922)
2025-07-15 16:34:40,287 - INFO - Successfully masked 922 neurons across 20 layers
2025-07-15 16:34:40,330 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,330 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,331 - INFO - Step 923: masking 923 neurons (total: 923)
2025-07-15 16:34:40,393 - INFO - Successfully masked 923 neurons across 20 layers
2025-07-15 16:34:40,436 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,436 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,437 - INFO - Step 924: masking 924 neurons (total: 924)
2025-07-15 16:34:40,500 - INFO - Successfully masked 924 neurons across 20 layers
2025-07-15 16:34:40,542 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,542 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,543 - INFO - Step 925: masking 925 neurons (total: 925)
2025-07-15 16:34:40,606 - INFO - Successfully masked 925 neurons across 20 layers
2025-07-15 16:34:40,647 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,648 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,649 - INFO - Step 926: masking 926 neurons (total: 926)
2025-07-15 16:34:40,709 - INFO - Successfully masked 926 neurons across 20 layers
2025-07-15 16:34:40,751 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,751 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,752 - INFO - Step 927: masking 927 neurons (total: 927)
2025-07-15 16:34:40,813 - INFO - Successfully masked 927 neurons across 20 layers
2025-07-15 16:34:40,854 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,854 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,855 - INFO - Step 928: masking 928 neurons (total: 928)
2025-07-15 16:34:40,916 - INFO - Successfully masked 928 neurons across 20 layers
2025-07-15 16:34:40,957 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:40,957 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:40,958 - INFO - Step 929: masking 929 neurons (total: 929)
2025-07-15 16:34:41,019 - INFO - Successfully masked 929 neurons across 20 layers
2025-07-15 16:34:41,063 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,063 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,064 - INFO - Step 930: masking 930 neurons (total: 930)
2025-07-15 16:34:41,127 - INFO - Successfully masked 930 neurons across 20 layers
2025-07-15 16:34:41,171 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,171 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,172 - INFO - Step 931: masking 931 neurons (total: 931)
2025-07-15 16:34:41,235 - INFO - Successfully masked 931 neurons across 20 layers
2025-07-15 16:34:41,277 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,278 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,278 - INFO - Step 932: masking 932 neurons (total: 932)
2025-07-15 16:34:41,341 - INFO - Successfully masked 932 neurons across 20 layers
2025-07-15 16:34:41,384 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,384 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,385 - INFO - Step 933: masking 933 neurons (total: 933)
2025-07-15 16:34:41,448 - INFO - Successfully masked 933 neurons across 20 layers
2025-07-15 16:34:41,490 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,491 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,492 - INFO - Step 934: masking 934 neurons (total: 934)
2025-07-15 16:34:41,555 - INFO - Successfully masked 934 neurons across 20 layers
2025-07-15 16:34:41,597 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,598 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,599 - INFO - Step 935: masking 935 neurons (total: 935)
2025-07-15 16:34:41,662 - INFO - Successfully masked 935 neurons across 20 layers
2025-07-15 16:34:41,705 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,705 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,706 - INFO - Step 936: masking 936 neurons (total: 936)
2025-07-15 16:34:41,769 - INFO - Successfully masked 936 neurons across 20 layers
2025-07-15 16:34:41,811 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,812 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,813 - INFO - Step 937: masking 937 neurons (total: 937)
2025-07-15 16:34:41,876 - INFO - Successfully masked 937 neurons across 20 layers
2025-07-15 16:34:41,918 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:41,918 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:41,919 - INFO - Step 938: masking 938 neurons (total: 938)
2025-07-15 16:34:41,982 - INFO - Successfully masked 938 neurons across 20 layers
2025-07-15 16:34:42,025 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,025 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,026 - INFO - Step 939: masking 939 neurons (total: 939)
2025-07-15 16:34:42,089 - INFO - Successfully masked 939 neurons across 20 layers
2025-07-15 16:34:42,132 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,132 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,133 - INFO - Step 940: masking 940 neurons (total: 940)
2025-07-15 16:34:42,196 - INFO - Successfully masked 940 neurons across 20 layers
2025-07-15 16:34:42,238 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,239 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,239 - INFO - Step 941: masking 941 neurons (total: 941)
2025-07-15 16:34:42,302 - INFO - Successfully masked 941 neurons across 20 layers
2025-07-15 16:34:42,345 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,345 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,346 - INFO - Step 942: masking 942 neurons (total: 942)
2025-07-15 16:34:42,410 - INFO - Successfully masked 942 neurons across 20 layers
2025-07-15 16:34:42,452 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,452 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,453 - INFO - Step 943: masking 943 neurons (total: 943)
2025-07-15 16:34:42,515 - INFO - Successfully masked 943 neurons across 20 layers
2025-07-15 16:34:42,556 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,557 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,558 - INFO - Step 944: masking 944 neurons (total: 944)
2025-07-15 16:34:42,620 - INFO - Successfully masked 944 neurons across 20 layers
2025-07-15 16:34:42,661 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,661 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,662 - INFO - Step 945: masking 945 neurons (total: 945)
2025-07-15 16:34:42,724 - INFO - Successfully masked 945 neurons across 21 layers
2025-07-15 16:34:42,765 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,765 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,766 - INFO - Step 946: masking 946 neurons (total: 946)
2025-07-15 16:34:42,827 - INFO - Successfully masked 946 neurons across 21 layers
2025-07-15 16:34:42,868 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,868 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,869 - INFO - Step 947: masking 947 neurons (total: 947)
2025-07-15 16:34:42,930 - INFO - Successfully masked 947 neurons across 21 layers
2025-07-15 16:34:42,971 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:42,971 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:42,972 - INFO - Step 948: masking 948 neurons (total: 948)
2025-07-15 16:34:43,034 - INFO - Successfully masked 948 neurons across 21 layers
2025-07-15 16:34:43,075 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,076 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,077 - INFO - Step 949: masking 949 neurons (total: 949)
2025-07-15 16:34:43,138 - INFO - Successfully masked 949 neurons across 21 layers
2025-07-15 16:34:43,179 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,179 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,180 - INFO - Step 950: masking 950 neurons (total: 950)
2025-07-15 16:34:43,241 - INFO - Successfully masked 950 neurons across 21 layers
2025-07-15 16:34:43,285 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,285 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,286 - INFO - Step 951: masking 951 neurons (total: 951)
2025-07-15 16:34:43,350 - INFO - Successfully masked 951 neurons across 21 layers
2025-07-15 16:34:43,392 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,393 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,394 - INFO - Step 952: masking 952 neurons (total: 952)
2025-07-15 16:34:43,458 - INFO - Successfully masked 952 neurons across 21 layers
2025-07-15 16:34:43,500 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,501 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,502 - INFO - Step 953: masking 953 neurons (total: 953)
2025-07-15 16:34:43,565 - INFO - Successfully masked 953 neurons across 21 layers
2025-07-15 16:34:43,608 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,608 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,609 - INFO - Step 954: masking 954 neurons (total: 954)
2025-07-15 16:34:43,673 - INFO - Successfully masked 954 neurons across 21 layers
2025-07-15 16:34:43,715 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,716 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,717 - INFO - Step 955: masking 955 neurons (total: 955)
2025-07-15 16:34:43,786 - INFO - Successfully masked 955 neurons across 21 layers
2025-07-15 16:34:43,830 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,831 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,831 - INFO - Step 956: masking 956 neurons (total: 956)
2025-07-15 16:34:43,895 - INFO - Successfully masked 956 neurons across 21 layers
2025-07-15 16:34:43,937 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:43,937 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:43,938 - INFO - Step 957: masking 957 neurons (total: 957)
2025-07-15 16:34:44,001 - INFO - Successfully masked 957 neurons across 21 layers
2025-07-15 16:34:44,044 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,044 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,045 - INFO - Step 958: masking 958 neurons (total: 958)
2025-07-15 16:34:44,108 - INFO - Successfully masked 958 neurons across 21 layers
2025-07-15 16:34:44,151 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,151 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,152 - INFO - Step 959: masking 959 neurons (total: 959)
2025-07-15 16:34:44,216 - INFO - Successfully masked 959 neurons across 21 layers
2025-07-15 16:34:44,259 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,260 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,261 - INFO - Step 960: masking 960 neurons (total: 960)
2025-07-15 16:34:44,324 - INFO - Successfully masked 960 neurons across 21 layers
2025-07-15 16:34:44,367 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,368 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,368 - INFO - Step 961: masking 961 neurons (total: 961)
2025-07-15 16:34:44,432 - INFO - Successfully masked 961 neurons across 21 layers
2025-07-15 16:34:44,475 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,475 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,476 - INFO - Step 962: masking 962 neurons (total: 962)
2025-07-15 16:34:44,539 - INFO - Successfully masked 962 neurons across 21 layers
2025-07-15 16:34:44,582 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,582 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,583 - INFO - Step 963: masking 963 neurons (total: 963)
2025-07-15 16:34:44,647 - INFO - Successfully masked 963 neurons across 21 layers
2025-07-15 16:34:44,689 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,690 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,691 - INFO - Step 964: masking 964 neurons (total: 964)
2025-07-15 16:34:44,754 - INFO - Successfully masked 964 neurons across 21 layers
2025-07-15 16:34:44,796 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,796 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,797 - INFO - Step 965: masking 965 neurons (total: 965)
2025-07-15 16:34:44,861 - INFO - Successfully masked 965 neurons across 21 layers
2025-07-15 16:34:44,904 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:44,904 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:44,905 - INFO - Step 966: masking 966 neurons (total: 966)
2025-07-15 16:34:44,968 - INFO - Successfully masked 966 neurons across 21 layers
2025-07-15 16:34:45,011 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,011 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,012 - INFO - Step 967: masking 967 neurons (total: 967)
2025-07-15 16:34:45,076 - INFO - Successfully masked 967 neurons across 21 layers
2025-07-15 16:34:45,117 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,117 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,118 - INFO - Step 968: masking 968 neurons (total: 968)
2025-07-15 16:34:45,180 - INFO - Successfully masked 968 neurons across 21 layers
2025-07-15 16:34:45,221 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,221 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,222 - INFO - Step 969: masking 969 neurons (total: 969)
2025-07-15 16:34:45,284 - INFO - Successfully masked 969 neurons across 21 layers
2025-07-15 16:34:45,325 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,326 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,327 - INFO - Step 970: masking 970 neurons (total: 970)
2025-07-15 16:34:45,389 - INFO - Successfully masked 970 neurons across 21 layers
2025-07-15 16:34:45,431 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,431 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,432 - INFO - Step 971: masking 971 neurons (total: 971)
2025-07-15 16:34:45,497 - INFO - Successfully masked 971 neurons across 21 layers
2025-07-15 16:34:45,540 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,540 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,541 - INFO - Step 972: masking 972 neurons (total: 972)
2025-07-15 16:34:45,604 - INFO - Successfully masked 972 neurons across 21 layers
2025-07-15 16:34:45,647 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,647 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,648 - INFO - Step 973: masking 973 neurons (total: 973)
2025-07-15 16:34:45,711 - INFO - Successfully masked 973 neurons across 21 layers
2025-07-15 16:34:45,753 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,754 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,754 - INFO - Step 974: masking 974 neurons (total: 974)
2025-07-15 16:34:45,818 - INFO - Successfully masked 974 neurons across 21 layers
2025-07-15 16:34:45,860 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,860 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,861 - INFO - Step 975: masking 975 neurons (total: 975)
2025-07-15 16:34:45,924 - INFO - Successfully masked 975 neurons across 21 layers
2025-07-15 16:34:45,966 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:45,967 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:45,967 - INFO - Step 976: masking 976 neurons (total: 976)
2025-07-15 16:34:46,031 - INFO - Successfully masked 976 neurons across 21 layers
2025-07-15 16:34:46,073 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,073 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,074 - INFO - Step 977: masking 977 neurons (total: 977)
2025-07-15 16:34:46,137 - INFO - Successfully masked 977 neurons across 21 layers
2025-07-15 16:34:46,181 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,181 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,182 - INFO - Step 978: masking 978 neurons (total: 978)
2025-07-15 16:34:46,246 - INFO - Successfully masked 978 neurons across 21 layers
2025-07-15 16:34:46,288 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,288 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,289 - INFO - Step 979: masking 979 neurons (total: 979)
2025-07-15 16:34:46,352 - INFO - Successfully masked 979 neurons across 21 layers
2025-07-15 16:34:46,393 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,394 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,395 - INFO - Step 980: masking 980 neurons (total: 980)
2025-07-15 16:34:46,458 - INFO - Successfully masked 980 neurons across 21 layers
2025-07-15 16:34:46,500 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,500 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,501 - INFO - Step 981: masking 981 neurons (total: 981)
2025-07-15 16:34:46,564 - INFO - Successfully masked 981 neurons across 21 layers
2025-07-15 16:34:46,606 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,606 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,607 - INFO - Step 982: masking 982 neurons (total: 982)
2025-07-15 16:34:46,670 - INFO - Successfully masked 982 neurons across 21 layers
2025-07-15 16:34:46,712 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,712 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,713 - INFO - Step 983: masking 983 neurons (total: 983)
2025-07-15 16:34:46,776 - INFO - Successfully masked 983 neurons across 21 layers
2025-07-15 16:34:46,818 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,818 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,819 - INFO - Step 984: masking 984 neurons (total: 984)
2025-07-15 16:34:46,882 - INFO - Successfully masked 984 neurons across 21 layers
2025-07-15 16:34:46,924 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:46,924 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:46,925 - INFO - Step 985: masking 985 neurons (total: 985)
2025-07-15 16:34:46,989 - INFO - Successfully masked 985 neurons across 21 layers
2025-07-15 16:34:47,031 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,031 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,033 - INFO - Step 986: masking 986 neurons (total: 986)
2025-07-15 16:34:47,099 - INFO - Successfully masked 986 neurons across 21 layers
2025-07-15 16:34:47,141 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,142 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,143 - INFO - Step 987: masking 987 neurons (total: 987)
2025-07-15 16:34:47,207 - INFO - Successfully masked 987 neurons across 21 layers
2025-07-15 16:34:47,249 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,250 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,251 - INFO - Step 988: masking 988 neurons (total: 988)
2025-07-15 16:34:47,318 - INFO - Successfully masked 988 neurons across 21 layers
2025-07-15 16:34:47,361 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,361 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,362 - INFO - Step 989: masking 989 neurons (total: 989)
2025-07-15 16:34:47,427 - INFO - Successfully masked 989 neurons across 21 layers
2025-07-15 16:34:47,469 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,470 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,471 - INFO - Step 990: masking 990 neurons (total: 990)
2025-07-15 16:34:47,535 - INFO - Successfully masked 990 neurons across 21 layers
2025-07-15 16:34:47,578 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,578 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,579 - INFO - Step 991: masking 991 neurons (total: 991)
2025-07-15 16:34:47,643 - INFO - Successfully masked 991 neurons across 21 layers
2025-07-15 16:34:47,686 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,687 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,688 - INFO - Step 992: masking 992 neurons (total: 992)
2025-07-15 16:34:47,754 - INFO - Successfully masked 992 neurons across 21 layers
2025-07-15 16:34:47,797 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,798 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,799 - INFO - Step 993: masking 993 neurons (total: 993)
2025-07-15 16:34:47,863 - INFO - Successfully masked 993 neurons across 21 layers
2025-07-15 16:34:47,906 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:47,907 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:47,907 - INFO - Step 994: masking 994 neurons (total: 994)
2025-07-15 16:34:47,972 - INFO - Successfully masked 994 neurons across 21 layers
2025-07-15 16:34:48,015 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:48,016 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:48,017 - INFO - Step 995: masking 995 neurons (total: 995)
2025-07-15 16:34:48,082 - INFO - Successfully masked 995 neurons across 21 layers
2025-07-15 16:34:48,126 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:48,127 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:48,128 - INFO - Step 996: masking 996 neurons (total: 996)
2025-07-15 16:34:48,193 - INFO - Successfully masked 996 neurons across 21 layers
2025-07-15 16:34:48,237 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:48,237 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:48,239 - INFO - Step 997: masking 997 neurons (total: 997)
2025-07-15 16:34:48,305 - INFO - Successfully masked 997 neurons across 21 layers
2025-07-15 16:34:48,348 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:48,348 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:48,349 - INFO - Step 998: masking 998 neurons (total: 998)
2025-07-15 16:34:48,414 - INFO - Successfully masked 998 neurons across 21 layers
2025-07-15 16:34:48,456 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:48,457 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:48,458 - INFO - Step 999: masking 999 neurons (total: 999)
2025-07-15 16:34:48,520 - INFO - Successfully masked 999 neurons across 21 layers
2025-07-15 16:34:48,561 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:48,561 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:48,562 - INFO - Step 1000: masking 1000 neurons (total: 1000)
2025-07-15 16:34:48,624 - INFO - Successfully masked 1000 neurons across 21 layers
2025-07-15 16:34:48,665 - INFO - Masked perplexity: 45.6465
2025-07-15 16:34:48,666 - INFO - Magnitude increase: 0.0000
2025-07-15 16:34:48,666 - WARNING - Stopping: maximum steps reached
2025-07-15 16:34:48,667 - INFO - Saving results to ./result/llama_3b_mask_neuron.json
2025-07-15 16:34:48,721 - INFO - Multi-GPU progressive masking analysis completed
2025-07-15 16:34:48,721 - INFO - Total steps: 1000
2025-07-15 16:34:48,721 - INFO - Final masked neurons: 1000
2025-07-15 16:34:48,721 - INFO - Used 1 GPUs for computation
2025-07-15 16:34:48,721 - INFO - 
=== Multi-GPU Masking Summary ===
2025-07-15 16:34:48,721 - INFO - Step 1: 1 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 2: 2 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 3: 3 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 4: 4 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 5: 5 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 6: 6 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 7: 7 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 8: 8 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 9: 9 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,722 - INFO - Step 10: 10 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 11: 11 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 12: 12 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 13: 13 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 14: 14 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 15: 15 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 16: 16 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 17: 17 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 18: 18 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 19: 19 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 20: 20 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,723 - INFO - Step 21: 21 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 22: 22 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 23: 23 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 24: 24 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 25: 25 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 26: 26 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 27: 27 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 28: 28 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 29: 29 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 30: 30 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 31: 31 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,724 - INFO - Step 32: 32 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 33: 33 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 34: 34 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 35: 35 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 36: 36 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 37: 37 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 38: 38 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 39: 39 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 40: 40 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 41: 41 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,725 - INFO - Step 42: 42 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 43: 43 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 44: 44 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 45: 45 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 46: 46 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 47: 47 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 48: 48 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 49: 49 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 50: 50 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 51: 51 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 52: 52 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,726 - INFO - Step 53: 53 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 54: 54 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 55: 55 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 56: 56 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 57: 57 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 58: 58 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 59: 59 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 60: 60 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 61: 61 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 62: 62 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 63: 63 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,727 - INFO - Step 64: 64 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 65: 65 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 66: 66 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 67: 67 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 68: 68 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 69: 69 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 70: 70 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 71: 71 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 72: 72 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 73: 73 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 74: 74 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,728 - INFO - Step 75: 75 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 76: 76 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 77: 77 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 78: 78 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 79: 79 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 80: 80 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 81: 81 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 82: 82 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 83: 83 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 84: 84 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,729 - INFO - Step 85: 85 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 86: 86 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 87: 87 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 88: 88 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 89: 89 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 90: 90 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 91: 91 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 92: 92 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 93: 93 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 94: 94 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 95: 95 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,730 - INFO - Step 96: 96 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 97: 97 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 98: 98 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 99: 99 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 100: 100 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 101: 101 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 102: 102 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 103: 103 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 104: 104 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 105: 105 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 106: 106 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,731 - INFO - Step 107: 107 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 108: 108 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 109: 109 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 110: 110 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 111: 111 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 112: 112 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 113: 113 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 114: 114 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 115: 115 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 116: 116 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 117: 117 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,732 - INFO - Step 118: 118 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 119: 119 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 120: 120 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 121: 121 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 122: 122 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 123: 123 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 124: 124 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 125: 125 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 126: 126 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 127: 127 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 128: 128 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,733 - INFO - Step 129: 129 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 130: 130 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 131: 131 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 132: 132 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 133: 133 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 134: 134 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 135: 135 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 136: 136 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 137: 137 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 138: 138 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,734 - INFO - Step 139: 139 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 140: 140 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 141: 141 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 142: 142 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 143: 143 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 144: 144 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 145: 145 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 146: 146 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 147: 147 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 148: 148 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 149: 149 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,735 - INFO - Step 150: 150 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 151: 151 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 152: 152 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 153: 153 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 154: 154 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 155: 155 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 156: 156 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 157: 157 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 158: 158 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 159: 159 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 160: 160 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,736 - INFO - Step 161: 161 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 162: 162 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 163: 163 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 164: 164 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 165: 165 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 166: 166 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 167: 167 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 168: 168 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 169: 169 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 170: 170 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 171: 171 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,737 - INFO - Step 172: 172 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 173: 173 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 174: 174 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 175: 175 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 176: 176 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 177: 177 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 178: 178 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 179: 179 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 180: 180 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 181: 181 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,738 - INFO - Step 182: 182 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 183: 183 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 184: 184 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 185: 185 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 186: 186 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 187: 187 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 188: 188 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 189: 189 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 190: 190 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 191: 191 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 192: 192 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,739 - INFO - Step 193: 193 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 194: 194 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 195: 195 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 196: 196 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 197: 197 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 198: 198 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 199: 199 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 200: 200 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 201: 201 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 202: 202 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 203: 203 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,740 - INFO - Step 204: 204 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 205: 205 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 206: 206 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 207: 207 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 208: 208 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 209: 209 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 210: 210 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 211: 211 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 212: 212 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 213: 213 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 214: 214 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,741 - INFO - Step 215: 215 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 216: 216 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 217: 217 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 218: 218 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 219: 219 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 220: 220 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 221: 221 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 222: 222 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 223: 223 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 224: 224 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 225: 225 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,742 - INFO - Step 226: 226 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 227: 227 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 228: 228 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 229: 229 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 230: 230 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 231: 231 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 232: 232 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 233: 233 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 234: 234 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 235: 235 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 236: 236 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,743 - INFO - Step 237: 237 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 238: 238 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 239: 239 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 240: 240 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 241: 241 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 242: 242 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 243: 243 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 244: 244 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 245: 245 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 246: 246 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 247: 247 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,744 - INFO - Step 248: 248 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 249: 249 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 250: 250 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 251: 251 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 252: 252 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 253: 253 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 254: 254 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 255: 255 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 256: 256 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 257: 257 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,745 - INFO - Step 258: 258 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 259: 259 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 260: 260 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 261: 261 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 262: 262 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 263: 263 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 264: 264 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 265: 265 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 266: 266 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 267: 267 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 268: 268 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,746 - INFO - Step 269: 269 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 270: 270 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 271: 271 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 272: 272 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 273: 273 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 274: 274 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 275: 275 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 276: 276 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 277: 277 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 278: 278 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 279: 279 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,747 - INFO - Step 280: 280 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 281: 281 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 282: 282 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 283: 283 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 284: 284 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 285: 285 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 286: 286 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 287: 287 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 288: 288 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 289: 289 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,748 - INFO - Step 290: 290 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 291: 291 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 292: 292 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 293: 293 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 294: 294 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 295: 295 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 296: 296 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 297: 297 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 298: 298 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 299: 299 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 300: 300 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,749 - INFO - Step 301: 301 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 302: 302 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 303: 303 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 304: 304 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 305: 305 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 306: 306 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 307: 307 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 308: 308 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 309: 309 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 310: 310 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 311: 311 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,750 - INFO - Step 312: 312 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 313: 313 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 314: 314 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 315: 315 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 316: 316 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 317: 317 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 318: 318 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 319: 319 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 320: 320 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 321: 321 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 322: 322 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,751 - INFO - Step 323: 323 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 324: 324 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 325: 325 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 326: 326 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 327: 327 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 328: 328 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 329: 329 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 330: 330 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 331: 331 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 332: 332 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 333: 333 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,752 - INFO - Step 334: 334 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 335: 335 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 336: 336 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 337: 337 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 338: 338 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 339: 339 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 340: 340 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 341: 341 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 342: 342 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 343: 343 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 344: 344 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,753 - INFO - Step 345: 345 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 346: 346 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 347: 347 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 348: 348 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 349: 349 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 350: 350 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 351: 351 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 352: 352 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 353: 353 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 354: 354 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,754 - INFO - Step 355: 355 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 356: 356 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 357: 357 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 358: 358 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 359: 359 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 360: 360 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 361: 361 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 362: 362 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 363: 363 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 364: 364 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 365: 365 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,755 - INFO - Step 366: 366 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 367: 367 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 368: 368 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 369: 369 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 370: 370 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 371: 371 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 372: 372 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 373: 373 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 374: 374 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 375: 375 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 376: 376 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,756 - INFO - Step 377: 377 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 378: 378 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 379: 379 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 380: 380 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 381: 381 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 382: 382 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 383: 383 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 384: 384 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 385: 385 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 386: 386 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 387: 387 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,757 - INFO - Step 388: 388 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 389: 389 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 390: 390 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 391: 391 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 392: 392 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 393: 393 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 394: 394 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 395: 395 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 396: 396 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 397: 397 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 398: 398 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,758 - INFO - Step 399: 399 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 400: 400 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 401: 401 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 402: 402 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 403: 403 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 404: 404 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 405: 405 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 406: 406 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 407: 407 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 408: 408 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 409: 409 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,759 - INFO - Step 410: 410 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 411: 411 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 412: 412 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 413: 413 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 414: 414 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 415: 415 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 416: 416 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 417: 417 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 418: 418 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 419: 419 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 420: 420 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,760 - INFO - Step 421: 421 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 422: 422 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 423: 423 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 424: 424 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 425: 425 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 426: 426 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 427: 427 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 428: 428 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 429: 429 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 430: 430 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,761 - INFO - Step 431: 431 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 432: 432 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 433: 433 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 434: 434 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 435: 435 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 436: 436 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 437: 437 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 438: 438 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 439: 439 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 440: 440 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 441: 441 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,762 - INFO - Step 442: 442 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 443: 443 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 444: 444 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 445: 445 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 446: 446 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 447: 447 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 448: 448 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 449: 449 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 450: 450 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 451: 451 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 452: 452 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,763 - INFO - Step 453: 453 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 454: 454 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 455: 455 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 456: 456 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 457: 457 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 458: 458 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 459: 459 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 460: 460 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 461: 461 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 462: 462 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 463: 463 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,764 - INFO - Step 464: 464 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 465: 465 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 466: 466 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 467: 467 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 468: 468 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 469: 469 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 470: 470 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 471: 471 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 472: 472 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 473: 473 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 474: 474 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,765 - INFO - Step 475: 475 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 476: 476 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 477: 477 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 478: 478 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 479: 479 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 480: 480 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 481: 481 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 482: 482 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 483: 483 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 484: 484 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 485: 485 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,766 - INFO - Step 486: 486 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 487: 487 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 488: 488 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 489: 489 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 490: 490 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 491: 491 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 492: 492 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 493: 493 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 494: 494 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 495: 495 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,767 - INFO - Step 496: 496 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 497: 497 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 498: 498 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 499: 499 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 500: 500 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 501: 501 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 502: 502 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 503: 503 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 504: 504 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 505: 505 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 506: 506 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,768 - INFO - Step 507: 507 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 508: 508 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 509: 509 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 510: 510 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 511: 511 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 512: 512 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 513: 513 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 514: 514 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 515: 515 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 516: 516 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 517: 517 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,769 - INFO - Step 518: 518 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 519: 519 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 520: 520 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 521: 521 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 522: 522 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 523: 523 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 524: 524 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 525: 525 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 526: 526 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 527: 527 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 528: 528 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,770 - INFO - Step 529: 529 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 530: 530 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 531: 531 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 532: 532 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 533: 533 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 534: 534 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 535: 535 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 536: 536 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 537: 537 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 538: 538 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,771 - INFO - Step 539: 539 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 540: 540 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 541: 541 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 542: 542 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 543: 543 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 544: 544 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 545: 545 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 546: 546 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 547: 547 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 548: 548 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 549: 549 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,772 - INFO - Step 550: 550 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 551: 551 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 552: 552 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 553: 553 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 554: 554 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 555: 555 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 556: 556 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 557: 557 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 558: 558 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 559: 559 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 560: 560 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,773 - INFO - Step 561: 561 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 562: 562 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 563: 563 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 564: 564 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 565: 565 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 566: 566 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 567: 567 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 568: 568 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 569: 569 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 570: 570 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,774 - INFO - Step 571: 571 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 572: 572 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 573: 573 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 574: 574 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 575: 575 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 576: 576 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 577: 577 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 578: 578 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 579: 579 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 580: 580 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 581: 581 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,775 - INFO - Step 582: 582 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 583: 583 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 584: 584 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 585: 585 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 586: 586 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 587: 587 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 588: 588 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 589: 589 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 590: 590 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 591: 591 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 592: 592 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,776 - INFO - Step 593: 593 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 594: 594 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 595: 595 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 596: 596 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 597: 597 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 598: 598 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 599: 599 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 600: 600 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 601: 601 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 602: 602 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 603: 603 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,777 - INFO - Step 604: 604 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 605: 605 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 606: 606 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 607: 607 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 608: 608 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 609: 609 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 610: 610 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 611: 611 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 612: 612 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 613: 613 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 614: 614 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,778 - INFO - Step 615: 615 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 616: 616 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 617: 617 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 618: 618 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 619: 619 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 620: 620 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 621: 621 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 622: 622 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 623: 623 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 624: 624 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 625: 625 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,779 - INFO - Step 626: 626 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 627: 627 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 628: 628 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 629: 629 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 630: 630 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 631: 631 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 632: 632 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 633: 633 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 634: 634 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 635: 635 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 636: 636 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,780 - INFO - Step 637: 637 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 638: 638 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 639: 639 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 640: 640 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 641: 641 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 642: 642 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 643: 643 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 644: 644 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 645: 645 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 646: 646 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,781 - INFO - Step 647: 647 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 648: 648 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 649: 649 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 650: 650 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 651: 651 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 652: 652 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 653: 653 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 654: 654 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 655: 655 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 656: 656 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 657: 657 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,782 - INFO - Step 658: 658 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 659: 659 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 660: 660 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 661: 661 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 662: 662 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 663: 663 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 664: 664 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 665: 665 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 666: 666 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 667: 667 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 668: 668 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,783 - INFO - Step 669: 669 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 670: 670 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 671: 671 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 672: 672 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 673: 673 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 674: 674 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 675: 675 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 676: 676 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 677: 677 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 678: 678 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 679: 679 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,784 - INFO - Step 680: 680 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 681: 681 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 682: 682 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 683: 683 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 684: 684 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 685: 685 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 686: 686 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 687: 687 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 688: 688 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 689: 689 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 690: 690 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,785 - INFO - Step 691: 691 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 692: 692 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 693: 693 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 694: 694 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 695: 695 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 696: 696 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 697: 697 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 698: 698 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 699: 699 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 700: 700 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,786 - INFO - Step 701: 701 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 702: 702 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 703: 703 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 704: 704 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 705: 705 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 706: 706 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 707: 707 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 708: 708 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 709: 709 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 710: 710 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 711: 711 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,787 - INFO - Step 712: 712 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 713: 713 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 714: 714 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 715: 715 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 716: 716 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 717: 717 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 718: 718 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 719: 719 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 720: 720 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 721: 721 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 722: 722 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,788 - INFO - Step 723: 723 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 724: 724 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 725: 725 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 726: 726 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 727: 727 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 728: 728 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 729: 729 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 730: 730 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 731: 731 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 732: 732 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 733: 733 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,789 - INFO - Step 734: 734 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 735: 735 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 736: 736 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 737: 737 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 738: 738 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 739: 739 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 740: 740 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 741: 741 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 742: 742 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 743: 743 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 744: 744 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,790 - INFO - Step 745: 745 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 746: 746 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 747: 747 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 748: 748 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 749: 749 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 750: 750 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 751: 751 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 752: 752 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 753: 753 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 754: 754 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 755: 755 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,791 - INFO - Step 756: 756 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 757: 757 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 758: 758 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 759: 759 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 760: 760 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 761: 761 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 762: 762 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 763: 763 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 764: 764 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 765: 765 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,792 - INFO - Step 766: 766 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 767: 767 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 768: 768 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 769: 769 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 770: 770 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 771: 771 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 772: 772 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 773: 773 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 774: 774 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 775: 775 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 776: 776 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,793 - INFO - Step 777: 777 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 778: 778 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 779: 779 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 780: 780 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 781: 781 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 782: 782 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 783: 783 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 784: 784 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 785: 785 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 786: 786 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 787: 787 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,794 - INFO - Step 788: 788 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 789: 789 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 790: 790 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 791: 791 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 792: 792 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 793: 793 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 794: 794 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 795: 795 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 796: 796 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 797: 797 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 798: 798 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,795 - INFO - Step 799: 799 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 800: 800 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 801: 801 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 802: 802 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 803: 803 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 804: 804 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 805: 805 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 806: 806 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 807: 807 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 808: 808 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,796 - INFO - Step 809: 809 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 810: 810 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 811: 811 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 812: 812 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 813: 813 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 814: 814 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 815: 815 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 816: 816 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 817: 817 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 818: 818 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 819: 819 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,797 - INFO - Step 820: 820 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 821: 821 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 822: 822 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 823: 823 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 824: 824 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 825: 825 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 826: 826 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 827: 827 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 828: 828 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 829: 829 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 830: 830 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,798 - INFO - Step 831: 831 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 832: 832 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 833: 833 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 834: 834 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 835: 835 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 836: 836 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 837: 837 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 838: 838 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 839: 839 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 840: 840 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 841: 841 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,799 - INFO - Step 842: 842 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 843: 843 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 844: 844 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 845: 845 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 846: 846 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 847: 847 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 848: 848 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 849: 849 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 850: 850 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 851: 851 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 852: 852 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,800 - INFO - Step 853: 853 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 854: 854 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 855: 855 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 856: 856 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 857: 857 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 858: 858 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 859: 859 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 860: 860 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 861: 861 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 862: 862 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 863: 863 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,801 - INFO - Step 864: 864 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 865: 865 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 866: 866 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 867: 867 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 868: 868 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 869: 869 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 870: 870 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 871: 871 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 872: 872 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 873: 873 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 874: 874 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,802 - INFO - Step 875: 875 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 876: 876 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 877: 877 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 878: 878 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 879: 879 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 880: 880 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 881: 881 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 882: 882 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 883: 883 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 884: 884 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,803 - INFO - Step 885: 885 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 886: 886 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 887: 887 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 888: 888 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 889: 889 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 890: 890 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 891: 891 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 892: 892 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 893: 893 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 894: 894 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 895: 895 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,804 - INFO - Step 896: 896 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 897: 897 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 898: 898 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 899: 899 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 900: 900 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 901: 901 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 902: 902 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 903: 903 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 904: 904 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 905: 905 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 906: 906 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,805 - INFO - Step 907: 907 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 908: 908 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 909: 909 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 910: 910 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 911: 911 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 912: 912 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 913: 913 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 914: 914 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 915: 915 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 916: 916 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,806 - INFO - Step 917: 917 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 918: 918 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 919: 919 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 920: 920 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 921: 921 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 922: 922 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 923: 923 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 924: 924 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 925: 925 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 926: 926 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 927: 927 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,807 - INFO - Step 928: 928 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 929: 929 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 930: 930 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 931: 931 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 932: 932 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 933: 933 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 934: 934 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 935: 935 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 936: 936 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 937: 937 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 938: 938 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,808 - INFO - Step 939: 939 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 940: 940 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 941: 941 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 942: 942 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 943: 943 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 944: 944 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 945: 945 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 946: 946 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 947: 947 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 948: 948 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 949: 949 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,809 - INFO - Step 950: 950 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 951: 951 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 952: 952 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 953: 953 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 954: 954 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 955: 955 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 956: 956 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 957: 957 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 958: 958 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 959: 959 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 960: 960 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,810 - INFO - Step 961: 961 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 962: 962 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 963: 963 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 964: 964 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 965: 965 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 966: 966 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 967: 967 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 968: 968 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 969: 969 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 970: 970 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,811 - INFO - Step 971: 971 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 972: 972 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 973: 973 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 974: 974 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 975: 975 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 976: 976 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 977: 977 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 978: 978 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 979: 979 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 980: 980 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 981: 981 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,812 - INFO - Step 982: 982 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 983: 983 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 984: 984 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 985: 985 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 986: 986 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 987: 987 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 988: 988 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 989: 989 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 990: 990 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 991: 991 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 992: 992 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,813 - INFO - Step 993: 993 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - Step 994: 994 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - Step 995: 995 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - Step 996: 996 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - Step 997: 997 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - Step 998: 998 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - Step 999: 999 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - Step 1000: 1000 neurons, perplexity: 45.6465, magnitude increase: 0.0000
2025-07-15 16:34:48,814 - INFO - === Multi-GPU Analysis Completed ===
2025-07-15 16:34:48,814 - INFO - Results saved to: ./result/llama_3b_mask_neuron.json
2025-07-15 16:34:48,814 - INFO - Log saved to: ./log/llama_3b.log
2025-07-15 16:37:28,646 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-07-15 16:37:28,646 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-07-15 16:37:28,647 - INFO - Neuron file: ./neurons/llama_3b.json
2025-07-15 16:37:28,647 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-07-15 16:37:28,647 - INFO - Step size: 1
2025-07-15 16:37:28,647 - INFO - Max magnitude increase: 4.0
2025-07-15 16:37:28,647 - INFO - Random seed: 42
2025-07-15 16:37:28,647 - INFO - Device: auto
2025-07-15 16:37:28,703 - INFO - Available GPUs: 1
2025-07-15 16:37:28,705 - INFO - Available GPUs: 1
2025-07-15 16:37:28,705 - INFO - Loading model with multi-GPU: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-07-15 16:37:28,705 - INFO - Transformers version: 4.52.4
2025-07-15 16:37:28,705 - INFO - PyTorch version: 2.6.0+cu124
2025-07-15 16:37:28,705 - INFO - CUDA available: True
2025-07-15 16:38:00,837 - INFO - Multi-GPU model loading completed
2025-07-15 16:38:00,838 - INFO - Model device allocation:
2025-07-15 16:38:00,838 - INFO -   : 0
2025-07-15 16:38:00,838 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-07-15 16:38:00,855 - INFO - Loaded 10000 neurons
2025-07-15 16:38:00,855 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-07-15 16:38:00,856 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-07-15 16:38:00,856 - INFO - Step size: 1
2025-07-15 16:38:00,856 - INFO - Max magnitude increase: 4.0
2025-07-15 16:38:00,856 - INFO - Using 1 GPUs
2025-07-15 16:39:07,894 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-07-15 16:39:07,894 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-07-15 16:39:07,894 - INFO - Neuron file: ./neurons/llama_3b.json
2025-07-15 16:39:07,894 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-07-15 16:39:07,894 - INFO - Step size: 1
2025-07-15 16:39:07,894 - INFO - Max magnitude increase: 4.0
2025-07-15 16:39:07,895 - INFO - Random seed: 42
2025-07-15 16:39:07,895 - INFO - Device: auto
2025-07-15 16:39:07,955 - INFO - Available GPUs: 1
2025-07-15 16:39:07,957 - INFO - Available GPUs: 1
2025-07-15 16:39:07,957 - INFO - Loading model with multi-GPU: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-07-15 16:39:07,957 - INFO - Transformers version: 4.52.4
2025-07-15 16:39:07,957 - INFO - PyTorch version: 2.6.0+cu124
2025-07-15 16:39:07,958 - INFO - CUDA available: True
2025-07-15 16:39:38,131 - INFO - Multi-GPU model loading completed
2025-07-15 16:39:38,131 - INFO - Model device allocation:
2025-07-15 16:39:38,131 - INFO -   : 0
2025-07-15 16:39:38,132 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-07-15 16:39:38,148 - INFO - Loaded 10000 neurons
2025-07-15 16:39:38,149 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-07-15 16:39:38,149 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-07-15 16:39:38,149 - INFO - Step size: 1
2025-07-15 16:39:38,149 - INFO - Max magnitude increase: 4.0
2025-07-15 16:39:38,149 - INFO - Using 1 GPUs
2025-07-15 16:39:38,149 - INFO - Computing baseline perplexity
2025-07-15 16:39:39,128 - INFO - Baseline perplexity: 45.6465
2025-07-15 16:39:39,129 - INFO - Step 1: masking 1 neurons (total: 1)
2025-07-15 16:39:39,130 - INFO - Set up 1 masking hooks for 1 layers
2025-07-15 16:39:39,130 - INFO - Applied masking to 1 neurons using 1 hooks
2025-07-15 16:39:39,170 - INFO - Masked perplexity: 44.3996
2025-07-15 16:39:39,171 - INFO - Magnitude increase: -0.0120
2025-07-15 16:39:39,173 - INFO - Step 2: masking 2 neurons (total: 2)
2025-07-15 16:39:39,173 - INFO - Set up 1 masking hooks for 1 layers
2025-07-15 16:39:39,173 - INFO - Applied masking to 2 neurons using 1 hooks
2025-07-15 16:39:39,216 - INFO - Masked perplexity: 43.6594
2025-07-15 16:39:39,217 - INFO - Magnitude increase: -0.0193
2025-07-15 16:39:39,219 - INFO - Step 3: masking 3 neurons (total: 3)
2025-07-15 16:39:39,220 - INFO - Set up 1 masking hooks for 1 layers
2025-07-15 16:39:39,220 - INFO - Applied masking to 3 neurons using 1 hooks
2025-07-15 16:39:39,265 - INFO - Masked perplexity: 54.4928
2025-07-15 16:39:39,265 - INFO - Magnitude increase: 0.0769
2025-07-15 16:39:39,267 - INFO - Step 4: masking 4 neurons (total: 4)
2025-07-15 16:39:39,267 - INFO - Set up 1 masking hooks for 1 layers
2025-07-15 16:39:39,267 - INFO - Applied masking to 4 neurons using 1 hooks
2025-07-15 16:39:39,311 - INFO - Masked perplexity: 869713.8750
2025-07-15 16:39:39,312 - INFO - Magnitude increase: 4.2800
2025-07-15 16:39:39,312 - INFO - Stopping: magnitude increase (4.2800) >= threshold (4.0)
2025-07-15 16:39:39,312 - INFO - Saving results to ./result/llama_3b_mask_neuron.json
2025-07-15 16:39:39,332 - INFO - Multi-GPU progressive masking analysis completed
2025-07-15 16:39:39,333 - INFO - Total steps: 4
2025-07-15 16:39:39,333 - INFO - Final masked neurons: 4
2025-07-15 16:39:39,333 - INFO - Used 1 GPUs for computation
2025-07-15 16:39:39,333 - INFO - 
=== Multi-GPU Masking Summary ===
2025-07-15 16:39:39,333 - INFO - Step 1: 1 neurons, perplexity: 44.3996, magnitude increase: -0.0120
2025-07-15 16:39:39,333 - INFO - Step 2: 2 neurons, perplexity: 43.6594, magnitude increase: -0.0193
2025-07-15 16:39:39,333 - INFO - Step 3: 3 neurons, perplexity: 54.4928, magnitude increase: 0.0769
2025-07-15 16:39:39,333 - INFO - Step 4: 4 neurons, perplexity: 869713.8750, magnitude increase: 4.2800
2025-07-15 16:39:39,333 - INFO - === Multi-GPU Analysis Completed ===
2025-07-15 16:39:39,333 - INFO - Results saved to: ./result/llama_3b_mask_neuron.json
2025-07-15 16:39:39,333 - INFO - Log saved to: ./log/llama_3b.log
2025-09-01 08:41:38,280 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Version) ===
2025-09-01 08:41:38,295 - INFO - ModelScope available: False
2025-09-01 08:41:38,296 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:41:38,296 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 08:41:38,296 - INFO - Dataset path: None
2025-09-01 08:41:38,296 - INFO - Split: test
2025-09-01 08:41:38,296 - INFO - Categories: None
2025-09-01 08:41:38,296 - INFO - Max length: 2048
2025-09-01 08:41:38,296 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 08:41:38,297 - INFO - Available GPUs: 2
2025-09-01 08:41:38,297 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:41:38,298 - INFO - Transformers version: 4.52.4
2025-09-01 08:41:38,298 - INFO - PyTorch version: 2.8.0+cu128
2025-09-01 08:43:15,309 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Version) ===
2025-09-01 08:43:15,310 - INFO - ModelScope available: False
2025-09-01 08:43:15,311 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:43:15,311 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 08:43:15,311 - INFO - Dataset path: None
2025-09-01 08:43:15,311 - INFO - Split: test
2025-09-01 08:43:15,311 - INFO - Categories: None
2025-09-01 08:43:15,311 - INFO - Max length: 2048
2025-09-01 08:43:15,311 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 08:43:15,313 - INFO - Available GPUs: 2
2025-09-01 08:43:15,313 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:43:15,313 - INFO - Transformers version: 4.52.4
2025-09-01 08:43:15,313 - INFO - PyTorch version: 2.8.0+cu128
2025-09-01 08:43:16,022 - WARNING - Failed to load model with device_map='auto': Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 08:43:16,022 - INFO - Trying alternative loading method...
2025-09-01 08:43:16,031 - WARNING - Failed to load model with torch.float16: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 08:43:16,032 - INFO - Trying with default dtype...
2025-09-01 08:43:59,408 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Version) ===
2025-09-01 08:43:59,410 - INFO - ModelScope available: False
2025-09-01 08:43:59,410 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:43:59,410 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 08:43:59,411 - INFO - Dataset path: None
2025-09-01 08:43:59,411 - INFO - Split: test
2025-09-01 08:43:59,411 - INFO - Categories: None
2025-09-01 08:43:59,411 - INFO - Max length: 2048
2025-09-01 08:43:59,411 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 08:43:59,412 - INFO - Available GPUs: 2
2025-09-01 08:43:59,412 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:43:59,413 - INFO - Transformers version: 4.52.4
2025-09-01 08:43:59,413 - INFO - PyTorch version: 2.8.0+cu128
2025-09-01 08:44:00,127 - WARNING - Failed to load model with device_map='auto': Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 08:44:00,127 - INFO - Trying alternative loading method...
2025-09-01 08:44:00,137 - WARNING - Failed to load model with torch.float16: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 08:44:00,138 - INFO - Trying with default dtype...
2025-09-01 08:44:53,142 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Version) ===
2025-09-01 08:44:53,144 - INFO - ModelScope available: False
2025-09-01 08:44:53,144 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:44:53,144 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 08:44:53,144 - INFO - Dataset path: None
2025-09-01 08:44:53,144 - INFO - Split: test
2025-09-01 08:44:53,145 - INFO - Categories: None
2025-09-01 08:44:53,145 - INFO - Max length: 2048
2025-09-01 08:44:53,145 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 08:44:53,146 - INFO - Available GPUs: 2
2025-09-01 08:44:53,146 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 08:44:53,146 - INFO - Transformers version: 4.56.0
2025-09-01 08:44:53,146 - INFO - PyTorch version: 2.8.0+cu128
2025-09-01 08:44:53,608 - WARNING - Failed to load model with device_map='auto': Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 08:44:53,609 - INFO - Trying alternative loading method...
2025-09-01 08:44:53,614 - WARNING - Failed to load model with torch.float16: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 08:44:53,614 - INFO - Trying with default dtype...
2025-09-01 13:02:40,082 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Only) ===
2025-09-01 13:02:40,101 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:02:40,102 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 13:02:40,102 - INFO - Split: test
2025-09-01 13:02:40,102 - INFO - Categories: None
2025-09-01 13:02:40,102 - INFO - Max length: 2048
2025-09-01 13:02:40,102 - INFO - Using ModelScope for dataset loading
2025-09-01 13:02:40,102 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 13:02:40,128 - INFO - Available GPUs: 2
2025-09-01 13:02:40,128 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:02:40,128 - INFO - Transformers version: 4.56.0
2025-09-01 13:02:40,128 - INFO - PyTorch version: 2.8.0+cu128
2025-09-01 13:02:40,710 - WARNING - LlamaForCausalLM not available in this transformers version
2025-09-01 13:02:40,711 - INFO - Loading with AutoConfig approach
2025-09-01 13:02:40,738 - WARNING - Failed to load with AutoConfig: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 13:02:40,738 - INFO - Loading with simplified parameters
2025-09-01 13:02:40,743 - WARNING - Failed to load with simplified parameters: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 13:02:40,743 - INFO - Loading with basic parameters (CPU first)
2025-09-01 13:02:40,748 - ERROR - All loading strategies failed: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 13:04:46,357 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Only) ===
2025-09-01 13:04:46,357 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:04:46,357 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 13:04:46,357 - INFO - Split: test
2025-09-01 13:04:46,357 - INFO - Categories: None
2025-09-01 13:04:46,357 - INFO - Max length: 2048
2025-09-01 13:04:46,358 - INFO - Using ModelScope for dataset loading
2025-09-01 13:04:46,358 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 13:04:46,381 - INFO - Available GPUs: 2
2025-09-01 13:04:46,382 - INFO - Loading model: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:04:46,382 - INFO - Transformers version: 4.56.0
2025-09-01 13:04:46,382 - INFO - PyTorch version: 2.8.0+cu128
2025-09-01 13:04:46,900 - WARNING - LlamaForCausalLM not available in this transformers version
2025-09-01 13:04:46,901 - INFO - Loading with AutoConfig approach
2025-09-01 13:04:46,907 - WARNING - Failed to load with AutoConfig: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 13:04:46,907 - INFO - Loading with simplified parameters
2025-09-01 13:04:46,912 - WARNING - Failed to load with simplified parameters: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 13:04:46,913 - INFO - Loading with basic parameters (CPU first)
2025-09-01 13:04:46,917 - ERROR - All loading strategies failed: Could not find LlamaForCausalLM neither in <module 'transformers.models.llama' from '/opt/conda/lib/python3.12/site-packages/transformers/models/llama/__init__.py'> nor in <module 'transformers' from '/opt/conda/lib/python3.12/site-packages/transformers/__init__.py'>!
2025-09-01 13:09:48,241 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Only) ===
2025-09-01 13:09:48,241 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:09:48,241 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 13:09:48,241 - INFO - Split: test
2025-09-01 13:09:48,242 - INFO - Categories: None
2025-09-01 13:09:48,242 - INFO - Max length: 2048
2025-09-01 13:09:48,242 - INFO - Using ModelScope for dataset loading
2025-09-01 13:09:48,242 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 13:09:48,266 - INFO - Available GPUs: 2
2025-09-01 13:09:48,266 - INFO - Loading model with multi-GPU: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:09:48,266 - INFO - Transformers version: 4.56.0
2025-09-01 13:09:48,266 - INFO - PyTorch version: 2.8.0+cu128
2025-09-01 13:16:52,972 - INFO - === MMLU-Pro Dataset Evaluator (ModelScope Only) ===
2025-09-01 13:16:52,972 - INFO - Model path: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:16:52,972 - INFO - Neuron file: ./neurons/llama_3b.json
2025-09-01 13:16:52,973 - INFO - Split: test
2025-09-01 13:16:52,973 - INFO - Categories: None
2025-09-01 13:16:52,973 - INFO - Max length: 2048
2025-09-01 13:16:52,973 - INFO - Using ModelScope for dataset loading
2025-09-01 13:16:52,973 - INFO - Testing on FULL dataset (no sample limit)
2025-09-01 13:16:52,996 - INFO - Available GPUs: 1
2025-09-01 13:16:52,996 - INFO - Loading model with multi-GPU: ../model/LLM-Research/Llama-3.2-3B-Instruct
2025-09-01 13:16:52,996 - INFO - Transformers version: 4.52.4
2025-09-01 13:16:52,996 - INFO - PyTorch version: 2.6.0+cu124
2025-09-01 13:17:22,991 - INFO - Multi-GPU model loading completed
2025-09-01 13:17:22,994 - INFO - Model device allocation:
2025-09-01 13:17:22,995 - INFO -   Device 0: 1 layers
2025-09-01 13:17:22,995 - INFO - Loading neuron importance data from: ./neurons/llama_3b.json
2025-09-01 13:17:23,038 - INFO - Loaded 10000 neurons for masking
2025-09-01 13:17:23,038 - INFO - Loading MMLU-Pro dataset from ModelScope, split: test
2025-09-01 13:19:59,777 - INFO - Dataset loaded successfully from ModelScope. Total items: 12032
2025-09-01 13:20:01,128 - INFO - Loaded 12032 questions from MMLU-Pro test
2025-09-01 13:20:01,129 - INFO - Sample question structure: ['question_id', 'question', 'options', 'answer', 'answer_index', 'cot_content', 'category', 'src']
2025-09-01 13:20:01,129 - INFO - Sample question: Typical advertising regulatory bodies suggest, for example that adverts must not: encourage ________...
2025-09-01 13:20:01,129 - INFO - Sample options: ['Safe practices, Fear, Jealousy, Trivial', 'Unsafe practices, Distress, Joy, Trivial', 'Safe practices, Wants, Jealousy, Trivial', 'Safe practices, Distress, Fear, Trivial', 'Unsafe practices, Wants, Jealousy, Serious', 'Safe practices, Distress, Jealousy, Serious', 'Safe practices, Wants, Fear, Serious', 'Unsafe practices, Wants, Fear, Trivial', 'Unsafe practices, Distress, Fear, Serious']
2025-09-01 13:20:01,129 - INFO - Sample answer: I
2025-09-01 13:20:01,129 - INFO - Sample category: business
2025-09-01 13:20:01,130 - INFO - Testing multiple neuron masking levels
2025-09-01 13:20:01,130 - INFO - Masking levels: [0, 4]
2025-09-01 13:20:01,133 - INFO - 
=== Testing with 0 neurons masked ===
2025-09-01 13:20:01,133 - INFO - Evaluating 12032 questions
2025-09-01 13:20:01,133 - INFO - Max length: 2048
2025-09-01 13:20:01,133 - INFO - No neuron masking applied
