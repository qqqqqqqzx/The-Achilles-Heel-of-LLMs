2025-09-20 15:37:23,052 - INFO - === Multi-GPU Neuron Activation Difference Analyzer ===
2025-09-20 15:37:23,052 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 15:37:23,052 - INFO - Input text: The Amazon Rainforest, located in South America, is the worldâ€™s largest tropical rainforest. It host...
2025-09-20 15:37:23,052 - INFO - Noise scale: 5.0
2025-09-20 15:37:23,052 - INFO - Number of samples: 100
2025-09-20 15:37:23,052 - INFO - Random seed: 42
2025-09-20 15:37:23,052 - INFO - Device: auto
2025-09-20 15:37:23,738 - INFO - Available GPUs: 8
2025-09-20 15:37:23,739 - INFO - Available GPUs: 8
2025-09-20 15:37:23,739 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 15:37:23,739 - INFO - Transformers version: 4.56.1
2025-09-20 15:37:23,739 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 15:37:23,739 - INFO - CUDA available: True
2025-09-20 15:37:54,428 - INFO - Multi-GPU model loading completed
2025-09-20 15:37:54,428 - INFO - Model device allocation:
2025-09-20 15:37:54,428 - INFO -   model.embed_tokens: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.0: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.1: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.2: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.3: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.4: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.5: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.6: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.7: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.8: 0
2025-09-20 15:37:54,429 - INFO -   model.layers.9: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.10: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.11: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.12: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.13: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.14: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.15: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.16: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.17: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.18: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.19: 1
2025-09-20 15:37:54,429 - INFO -   model.layers.20: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.21: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.22: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.23: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.24: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.25: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.26: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.27: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.28: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.29: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.30: 2
2025-09-20 15:37:54,429 - INFO -   model.layers.31: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.32: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.33: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.34: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.35: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.36: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.37: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.38: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.39: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.40: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.41: 3
2025-09-20 15:37:54,429 - INFO -   model.layers.42: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.43: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.44: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.45: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.46: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.47: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.48: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.49: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.50: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.51: 4
2025-09-20 15:37:54,429 - INFO -   model.layers.52: 4
2025-09-20 15:37:54,430 - INFO -   model.layers.53: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.54: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.55: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.56: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.57: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.58: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.59: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.60: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.61: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.62: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.63: 5
2025-09-20 15:37:54,430 - INFO -   model.layers.64: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.65: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.66: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.67: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.68: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.69: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.70: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.71: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.72: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.73: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.74: 6
2025-09-20 15:37:54,430 - INFO -   model.layers.75: 7
2025-09-20 15:37:54,430 - INFO -   model.layers.76: 7
2025-09-20 15:37:54,430 - INFO -   model.layers.77: 7
2025-09-20 15:37:54,430 - INFO -   model.layers.78: 7
2025-09-20 15:37:54,430 - INFO -   model.layers.79: 7
2025-09-20 15:37:54,430 - INFO -   model.norm: 7
2025-09-20 15:37:54,430 - INFO -   model.rotary_emb: 7
2025-09-20 15:37:54,430 - INFO -   lm_head: 7
2025-09-20 15:37:54,430 - INFO - Starting multi-GPU neuron activation difference analysis
2025-09-20 15:37:54,436 - INFO - Set up hooks for 720 key modules
2025-09-20 15:37:54,448 - INFO - Input text length: 34 tokens
2025-09-20 15:37:54,448 - INFO - Input device: cuda:0
2025-09-20 15:37:54,448 - INFO - Collecting baseline activations across GPUs
2025-09-20 15:37:55,090 - INFO - Collected baseline activations from 720 modules
2025-09-20 15:37:55,090 - INFO - Running noise experiment 1/100
2025-09-20 15:37:55,621 - INFO - Running noise experiment 2/100
2025-09-20 15:37:56,137 - INFO - Running noise experiment 3/100
2025-09-20 15:37:56,708 - INFO - Running noise experiment 4/100
2025-09-20 15:37:57,258 - INFO - Running noise experiment 5/100
2025-09-20 15:37:57,814 - INFO - Running noise experiment 6/100
2025-09-20 15:37:58,369 - INFO - Running noise experiment 7/100
2025-09-20 15:37:58,927 - INFO - Running noise experiment 8/100
2025-09-20 15:37:59,478 - INFO - Running noise experiment 9/100
2025-09-20 15:38:00,045 - INFO - Running noise experiment 10/100
2025-09-20 15:38:00,644 - INFO - Running noise experiment 11/100
2025-09-20 15:38:01,181 - INFO - Running noise experiment 12/100
2025-09-20 15:38:01,718 - INFO - Running noise experiment 13/100
2025-09-20 15:38:02,228 - INFO - Running noise experiment 14/100
2025-09-20 15:38:02,786 - INFO - Running noise experiment 15/100
2025-09-20 15:38:03,340 - INFO - Running noise experiment 16/100
2025-09-20 15:38:03,890 - INFO - Running noise experiment 17/100
2025-09-20 15:38:04,445 - INFO - Running noise experiment 18/100
2025-09-20 15:38:04,997 - INFO - Running noise experiment 19/100
2025-09-20 15:38:05,552 - INFO - Running noise experiment 20/100
2025-09-20 15:38:06,110 - INFO - Running noise experiment 21/100
2025-09-20 15:38:06,763 - INFO - Running noise experiment 22/100
2025-09-20 15:38:07,311 - INFO - Running noise experiment 23/100
2025-09-20 15:38:07,861 - INFO - Running noise experiment 24/100
2025-09-20 15:38:08,419 - INFO - Running noise experiment 25/100
2025-09-20 15:38:08,967 - INFO - Running noise experiment 26/100
2025-09-20 15:38:09,516 - INFO - Running noise experiment 27/100
2025-09-20 15:38:10,063 - INFO - Running noise experiment 28/100
2025-09-20 15:38:10,616 - INFO - Running noise experiment 29/100
2025-09-20 15:38:11,184 - INFO - Running noise experiment 30/100
2025-09-20 15:38:11,767 - INFO - Running noise experiment 31/100
2025-09-20 15:38:12,341 - INFO - Running noise experiment 32/100
2025-09-20 15:38:12,924 - INFO - Running noise experiment 33/100
2025-09-20 15:38:13,491 - INFO - Running noise experiment 34/100
2025-09-20 15:38:14,057 - INFO - Running noise experiment 35/100
2025-09-20 15:38:14,642 - INFO - Running noise experiment 36/100
2025-09-20 15:38:15,223 - INFO - Running noise experiment 37/100
2025-09-20 15:38:15,806 - INFO - Running noise experiment 38/100
2025-09-20 15:38:16,380 - INFO - Running noise experiment 39/100
2025-09-20 15:38:16,962 - INFO - Running noise experiment 40/100
2025-09-20 15:38:17,536 - INFO - Running noise experiment 41/100
2025-09-20 15:38:18,109 - INFO - Running noise experiment 42/100
2025-09-20 15:38:18,687 - INFO - Running noise experiment 43/100
2025-09-20 15:38:19,244 - INFO - Running noise experiment 44/100
2025-09-20 15:38:19,813 - INFO - Running noise experiment 45/100
2025-09-20 15:38:20,391 - INFO - Running noise experiment 46/100
2025-09-20 15:38:20,981 - INFO - Running noise experiment 47/100
2025-09-20 15:38:21,553 - INFO - Running noise experiment 48/100
2025-09-20 15:38:22,131 - INFO - Running noise experiment 49/100
2025-09-20 15:38:22,698 - INFO - Running noise experiment 50/100
2025-09-20 15:38:23,281 - INFO - Running noise experiment 51/100
2025-09-20 15:38:23,829 - INFO - Running noise experiment 52/100
2025-09-20 15:38:24,391 - INFO - Running noise experiment 53/100
2025-09-20 15:38:24,960 - INFO - Running noise experiment 54/100
2025-09-20 15:38:25,519 - INFO - Running noise experiment 55/100
2025-09-20 15:38:26,090 - INFO - Running noise experiment 56/100
2025-09-20 15:38:26,666 - INFO - Running noise experiment 57/100
2025-09-20 15:38:27,252 - INFO - Running noise experiment 58/100
2025-09-20 15:38:27,815 - INFO - Running noise experiment 59/100
2025-09-20 15:38:28,379 - INFO - Running noise experiment 60/100
2025-09-20 15:38:28,940 - INFO - Running noise experiment 61/100
2025-09-20 15:38:29,512 - INFO - Running noise experiment 62/100
2025-09-20 15:38:30,080 - INFO - Running noise experiment 63/100
2025-09-20 15:38:30,658 - INFO - Running noise experiment 64/100
2025-09-20 15:38:31,250 - INFO - Running noise experiment 65/100
2025-09-20 15:38:31,821 - INFO - Running noise experiment 66/100
2025-09-20 15:38:32,402 - INFO - Running noise experiment 67/100
2025-09-20 15:38:32,971 - INFO - Running noise experiment 68/100
2025-09-20 15:38:33,546 - INFO - Running noise experiment 69/100
2025-09-20 15:38:34,129 - INFO - Running noise experiment 70/100
2025-09-20 15:38:34,698 - INFO - Running noise experiment 71/100
2025-09-20 15:38:35,265 - INFO - Running noise experiment 72/100
2025-09-20 15:38:35,838 - INFO - Running noise experiment 73/100
2025-09-20 15:38:36,432 - INFO - Running noise experiment 74/100
2025-09-20 15:38:37,105 - INFO - Running noise experiment 75/100
2025-09-20 15:38:37,680 - INFO - Running noise experiment 76/100
2025-09-20 15:38:38,258 - INFO - Running noise experiment 77/100
2025-09-20 15:38:38,823 - INFO - Running noise experiment 78/100
2025-09-20 15:38:39,380 - INFO - Running noise experiment 79/100
2025-09-20 15:38:39,950 - INFO - Running noise experiment 80/100
2025-09-20 15:38:40,514 - INFO - Running noise experiment 81/100
2025-09-20 15:38:41,088 - INFO - Running noise experiment 82/100
2025-09-20 15:38:41,659 - INFO - Running noise experiment 83/100
2025-09-20 15:38:42,223 - INFO - Running noise experiment 84/100
2025-09-20 15:38:42,805 - INFO - Running noise experiment 85/100
2025-09-20 15:38:43,393 - INFO - Running noise experiment 86/100
2025-09-20 15:38:43,985 - INFO - Running noise experiment 87/100
2025-09-20 15:38:44,557 - INFO - Running noise experiment 88/100
2025-09-20 15:38:45,119 - INFO - Running noise experiment 89/100
2025-09-20 15:38:45,689 - INFO - Running noise experiment 90/100
2025-09-20 15:38:46,259 - INFO - Running noise experiment 91/100
2025-09-20 15:38:46,842 - INFO - Running noise experiment 92/100
2025-09-20 15:38:47,430 - INFO - Running noise experiment 93/100
2025-09-20 15:38:48,018 - INFO - Running noise experiment 94/100
2025-09-20 15:38:48,590 - INFO - Running noise experiment 95/100
2025-09-20 15:38:49,160 - INFO - Running noise experiment 96/100
2025-09-20 15:38:49,758 - INFO - Running noise experiment 97/100
2025-09-20 15:38:50,344 - INFO - Running noise experiment 98/100
2025-09-20 15:38:50,927 - INFO - Running noise experiment 99/100
2025-09-20 15:38:51,508 - INFO - Running noise experiment 100/100
2025-09-20 15:38:52,088 - INFO - Successfully collected activation differences from 720 modules
2025-09-20 15:38:52,088 - INFO - Computing neuron importance
2025-09-20 15:59:36,242 - INFO - Found 328663037 meaningful neurons
2025-09-20 15:59:36,242 - INFO - Sorting neurons by activation difference
2025-09-20 16:01:07,304 - INFO - Saving results to ./abl/s1.json
2025-09-20 16:01:07,367 - INFO - Multi-GPU analysis completed
2025-09-20 16:01:07,367 - INFO - Total discovered neurons: 328663037
2025-09-20 16:01:07,367 - INFO - Used 8 GPUs for computation
2025-09-20 16:01:07,367 - INFO - Top 10 neurons with highest activation difference:
2025-09-20 16:01:07,367 - INFO - Rank 1: Layer model.layers.3.mlp.down_proj, Activation diff: 471.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 16:01:07,367 - INFO - Rank 2: Layer model.layers.3.mlp.down_proj, Activation diff: 420.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 16:01:07,367 - INFO - Rank 3: Layer model.layers.3.mlp.down_proj, Activation diff: 392.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 16:01:07,367 - INFO - Rank 4: Layer model.layers.79.mlp.down_proj, Activation diff: 390.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 16:01:07,367 - INFO - Rank 5: Layer model.layers.79.mlp.down_proj, Activation diff: 342.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 16:01:07,367 - INFO - Rank 6: Layer model.layers.79.mlp.down_proj, Activation diff: 336.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 16:01:07,367 - INFO - Rank 7: Layer model.layers.0.mlp.down_proj, Activation diff: 62.718750, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 16:01:07,367 - INFO - Rank 8: Layer model.layers.79.mlp.down_proj, Activation diff: 51.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 775
2025-09-20 16:01:07,367 - INFO - Rank 9: Layer model.layers.79.mlp.down_proj, Activation diff: 43.125000, batch_idx: 0, seq_idx: 12, hidden_idx: 5114
2025-09-20 16:01:07,367 - INFO - Rank 10: Layer model.layers.79.mlp.down_proj, Activation diff: 41.625000, batch_idx: 0, seq_idx: 22, hidden_idx: 5114
2025-09-20 16:01:09,107 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 16:01:09,110 - INFO - Discovered 328663037 neurons
2025-09-20 16:01:09,115 - INFO - Results saved to: ./abl/s1.json
2025-09-20 16:01:09,121 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 16:04:57,056 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 16:04:57,056 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 16:04:57,057 - INFO - Neuron file: ./abl/s1.json
2025-09-20 16:04:57,057 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 16:04:57,057 - INFO - Step size: 1
2025-09-20 16:04:57,057 - INFO - Max magnitude increase: 5.0
2025-09-20 16:04:57,057 - INFO - Random seed: 42
2025-09-20 16:04:57,057 - INFO - Device: auto
2025-09-20 16:04:57,751 - INFO - Available GPUs: 8
2025-09-20 16:04:57,752 - INFO - Available GPUs: 8
2025-09-20 16:04:57,752 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 16:04:57,752 - INFO - Transformers version: 4.56.1
2025-09-20 16:04:57,752 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 16:04:57,752 - INFO - CUDA available: True
2025-09-20 16:05:37,085 - INFO - Multi-GPU model loading completed
2025-09-20 16:05:37,085 - INFO - Model device allocation:
2025-09-20 16:05:37,085 - INFO -   model.embed_tokens: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.0: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.1: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.2: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.3: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.4: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.5: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.6: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.7: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.8: 0
2025-09-20 16:05:37,085 - INFO -   model.layers.9: 1
2025-09-20 16:05:37,085 - INFO -   model.layers.10: 1
2025-09-20 16:05:37,085 - INFO -   model.layers.11: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.12: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.13: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.14: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.15: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.16: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.17: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.18: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.19: 1
2025-09-20 16:05:37,086 - INFO -   model.layers.20: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.21: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.22: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.23: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.24: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.25: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.26: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.27: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.28: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.29: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.30: 2
2025-09-20 16:05:37,086 - INFO -   model.layers.31: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.32: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.33: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.34: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.35: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.36: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.37: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.38: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.39: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.40: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.41: 3
2025-09-20 16:05:37,086 - INFO -   model.layers.42: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.43: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.44: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.45: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.46: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.47: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.48: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.49: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.50: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.51: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.52: 4
2025-09-20 16:05:37,086 - INFO -   model.layers.53: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.54: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.55: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.56: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.57: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.58: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.59: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.60: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.61: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.62: 5
2025-09-20 16:05:37,086 - INFO -   model.layers.63: 5
2025-09-20 16:05:37,087 - INFO -   model.layers.64: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.65: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.66: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.67: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.68: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.69: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.70: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.71: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.72: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.73: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.74: 6
2025-09-20 16:05:37,087 - INFO -   model.layers.75: 7
2025-09-20 16:05:37,087 - INFO -   model.layers.76: 7
2025-09-20 16:05:37,087 - INFO -   model.layers.77: 7
2025-09-20 16:05:37,087 - INFO -   model.layers.78: 7
2025-09-20 16:05:37,087 - INFO -   model.layers.79: 7
2025-09-20 16:05:37,087 - INFO -   model.norm: 7
2025-09-20 16:05:37,087 - INFO -   model.rotary_emb: 7
2025-09-20 16:05:37,087 - INFO -   lm_head: 7
2025-09-20 16:05:37,087 - INFO - Loading neuron importance data from: ./abl/s1.json
2025-09-20 16:05:37,095 - INFO - Loaded 10000 neurons
2025-09-20 16:05:37,095 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 16:05:37,095 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 16:05:37,096 - INFO - Step size: 1
2025-09-20 16:05:37,096 - INFO - Max magnitude increase: 5.0
2025-09-20 16:05:37,096 - INFO - Using 8 GPUs
2025-09-20 16:05:37,096 - INFO - Computing baseline perplexity
2025-09-20 16:05:37,697 - INFO - Baseline perplexity: 22.9140
2025-09-20 16:05:37,697 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 16:05:37,697 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 16:05:37,697 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 16:05:37,973 - INFO - Masked perplexity: 24.9976
2025-09-20 16:05:37,974 - INFO - Magnitude increase: 0.0378
2025-09-20 16:05:37,982 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 16:05:37,983 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 16:05:37,983 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 16:05:38,259 - INFO - Masked perplexity: 29.3805
2025-09-20 16:05:38,259 - INFO - Magnitude increase: 0.1080
2025-09-20 16:05:38,267 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 16:05:38,267 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 16:05:38,268 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 16:05:38,544 - INFO - Masked perplexity: 23759.0293
2025-09-20 16:05:38,544 - INFO - Magnitude increase: 3.0157
2025-09-20 16:05:38,553 - INFO - Step 4: masking 4 neurons (total: 4)
2025-09-20 16:05:38,554 - INFO - Set up 2 masking hooks for 2 layers
2025-09-20 16:05:38,554 - INFO - Applied masking to 4 neurons using 2 hooks
2025-09-20 16:05:38,831 - INFO - Masked perplexity: 24232.3027
2025-09-20 16:05:38,831 - INFO - Magnitude increase: 3.0243
2025-09-20 16:05:38,839 - INFO - Step 5: masking 5 neurons (total: 5)
2025-09-20 16:05:38,841 - INFO - Set up 2 masking hooks for 2 layers
2025-09-20 16:05:38,841 - INFO - Applied masking to 5 neurons using 2 hooks
2025-09-20 16:05:39,116 - INFO - Masked perplexity: 24585.1914
2025-09-20 16:05:39,116 - INFO - Magnitude increase: 3.0306
2025-09-20 16:05:39,125 - INFO - Step 6: masking 6 neurons (total: 6)
2025-09-20 16:05:39,126 - INFO - Set up 2 masking hooks for 2 layers
2025-09-20 16:05:39,126 - INFO - Applied masking to 6 neurons using 2 hooks
2025-09-20 16:05:39,402 - INFO - Masked perplexity: 24988.7891
2025-09-20 16:05:39,403 - INFO - Magnitude increase: 3.0376
2025-09-20 16:05:39,411 - INFO - Step 7: masking 7 neurons (total: 7)
2025-09-20 16:05:39,412 - INFO - Set up 3 masking hooks for 3 layers
2025-09-20 16:05:39,412 - INFO - Applied masking to 7 neurons using 3 hooks
2025-09-20 16:05:39,688 - INFO - Masked perplexity: 33231.2578
2025-09-20 16:05:39,689 - INFO - Magnitude increase: 3.1614
2025-09-20 16:05:39,697 - INFO - Step 8: masking 8 neurons (total: 8)
2025-09-20 16:05:39,698 - INFO - Set up 3 masking hooks for 3 layers
2025-09-20 16:05:39,698 - INFO - Applied masking to 8 neurons using 3 hooks
2025-09-20 16:05:39,974 - INFO - Masked perplexity: 34186.3906
2025-09-20 16:05:39,974 - INFO - Magnitude increase: 3.1738
2025-09-20 16:05:39,983 - INFO - Step 9: masking 9 neurons (total: 9)
2025-09-20 16:05:39,984 - INFO - Set up 3 masking hooks for 3 layers
2025-09-20 16:05:39,984 - INFO - Applied masking to 9 neurons using 3 hooks
2025-09-20 16:05:40,260 - INFO - Masked perplexity: 174066000.0000
2025-09-20 16:05:40,260 - INFO - Magnitude increase: 6.8806
2025-09-20 16:05:40,260 - INFO - Stopping: magnitude increase (6.8806) >= threshold (5.0)
2025-09-20 16:05:40,260 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 16:05:40,261 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 16:05:40,261 - INFO - Total steps: 9
2025-09-20 16:05:40,261 - INFO - Final masked neurons: 9
2025-09-20 16:05:40,261 - INFO - Used 8 GPUs for computation
2025-09-20 16:05:40,261 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 16:05:40,261 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 16:05:40,261 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 16:05:40,261 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 16:05:40,261 - INFO - Step 4: 4 neurons, perplexity: 24232.3027, magnitude increase: 3.0243
2025-09-20 16:05:40,261 - INFO - Step 5: 5 neurons, perplexity: 24585.1914, magnitude increase: 3.0306
2025-09-20 16:05:40,261 - INFO - Step 6: 6 neurons, perplexity: 24988.7891, magnitude increase: 3.0376
2025-09-20 16:05:40,261 - INFO - Step 7: 7 neurons, perplexity: 33231.2578, magnitude increase: 3.1614
2025-09-20 16:05:40,261 - INFO - Step 8: 8 neurons, perplexity: 34186.3906, magnitude increase: 3.1738
2025-09-20 16:05:40,261 - INFO - Step 9: 9 neurons, perplexity: 174066000.0000, magnitude increase: 6.8806
2025-09-20 16:05:40,261 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 16:05:40,261 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 16:05:40,261 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 18:03:07,493 - INFO - === Multi-GPU Neuron Activation Difference Analyzer ===
2025-09-20 18:03:07,493 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:03:07,493 - INFO - Input text: A rapidly spreading wildfire near Yosemite has forced evacuations in Mariposa County. Firefighters b...
2025-09-20 18:03:07,494 - INFO - Noise scale: 5.0
2025-09-20 18:03:07,494 - INFO - Number of samples: 100
2025-09-20 18:03:07,494 - INFO - Random seed: 42
2025-09-20 18:03:07,494 - INFO - Device: auto
2025-09-20 18:03:08,187 - INFO - Available GPUs: 8
2025-09-20 18:03:08,188 - INFO - Available GPUs: 8
2025-09-20 18:03:08,188 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:03:08,188 - INFO - Transformers version: 4.56.1
2025-09-20 18:03:08,188 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 18:03:08,188 - INFO - CUDA available: True
2025-09-20 18:03:40,846 - INFO - Multi-GPU model loading completed
2025-09-20 18:03:40,846 - INFO - Model device allocation:
2025-09-20 18:03:40,847 - INFO -   model.embed_tokens: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.0: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.1: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.2: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.3: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.4: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.5: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.6: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.7: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.8: 0
2025-09-20 18:03:40,847 - INFO -   model.layers.9: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.10: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.11: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.12: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.13: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.14: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.15: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.16: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.17: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.18: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.19: 1
2025-09-20 18:03:40,847 - INFO -   model.layers.20: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.21: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.22: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.23: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.24: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.25: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.26: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.27: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.28: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.29: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.30: 2
2025-09-20 18:03:40,847 - INFO -   model.layers.31: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.32: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.33: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.34: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.35: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.36: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.37: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.38: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.39: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.40: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.41: 3
2025-09-20 18:03:40,847 - INFO -   model.layers.42: 4
2025-09-20 18:03:40,847 - INFO -   model.layers.43: 4
2025-09-20 18:03:40,847 - INFO -   model.layers.44: 4
2025-09-20 18:03:40,847 - INFO -   model.layers.45: 4
2025-09-20 18:03:40,847 - INFO -   model.layers.46: 4
2025-09-20 18:03:40,847 - INFO -   model.layers.47: 4
2025-09-20 18:03:40,847 - INFO -   model.layers.48: 4
2025-09-20 18:03:40,847 - INFO -   model.layers.49: 4
2025-09-20 18:03:40,848 - INFO -   model.layers.50: 4
2025-09-20 18:03:40,848 - INFO -   model.layers.51: 4
2025-09-20 18:03:40,848 - INFO -   model.layers.52: 4
2025-09-20 18:03:40,848 - INFO -   model.layers.53: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.54: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.55: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.56: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.57: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.58: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.59: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.60: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.61: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.62: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.63: 5
2025-09-20 18:03:40,848 - INFO -   model.layers.64: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.65: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.66: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.67: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.68: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.69: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.70: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.71: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.72: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.73: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.74: 6
2025-09-20 18:03:40,848 - INFO -   model.layers.75: 7
2025-09-20 18:03:40,848 - INFO -   model.layers.76: 7
2025-09-20 18:03:40,848 - INFO -   model.layers.77: 7
2025-09-20 18:03:40,848 - INFO -   model.layers.78: 7
2025-09-20 18:03:40,848 - INFO -   model.layers.79: 7
2025-09-20 18:03:40,848 - INFO -   model.norm: 7
2025-09-20 18:03:40,848 - INFO -   model.rotary_emb: 7
2025-09-20 18:03:40,848 - INFO -   lm_head: 7
2025-09-20 18:03:40,848 - INFO - Starting multi-GPU neuron activation difference analysis
2025-09-20 18:03:40,854 - INFO - Set up hooks for 720 key modules
2025-09-20 18:03:40,867 - INFO - Input text length: 30 tokens
2025-09-20 18:03:40,867 - INFO - Input device: cuda:0
2025-09-20 18:03:40,867 - INFO - Collecting baseline activations across GPUs
2025-09-20 18:03:41,689 - INFO - Collected baseline activations from 720 modules
2025-09-20 18:03:41,689 - INFO - Running noise experiment 1/100
2025-09-20 18:03:42,141 - INFO - Running noise experiment 2/100
2025-09-20 18:03:42,569 - INFO - Running noise experiment 3/100
2025-09-20 18:03:42,980 - INFO - Running noise experiment 4/100
2025-09-20 18:03:43,459 - INFO - Running noise experiment 5/100
2025-09-20 18:03:43,984 - INFO - Running noise experiment 6/100
2025-09-20 18:03:44,540 - INFO - Running noise experiment 7/100
2025-09-20 18:03:45,052 - INFO - Running noise experiment 8/100
2025-09-20 18:03:45,579 - INFO - Running noise experiment 9/100
2025-09-20 18:03:46,120 - INFO - Running noise experiment 10/100
2025-09-20 18:03:46,665 - INFO - Running noise experiment 11/100
2025-09-20 18:03:47,222 - INFO - Running noise experiment 12/100
2025-09-20 18:03:47,754 - INFO - Running noise experiment 13/100
2025-09-20 18:03:48,268 - INFO - Running noise experiment 14/100
2025-09-20 18:03:48,810 - INFO - Running noise experiment 15/100
2025-09-20 18:03:49,346 - INFO - Running noise experiment 16/100
2025-09-20 18:03:49,878 - INFO - Running noise experiment 17/100
2025-09-20 18:03:50,417 - INFO - Running noise experiment 18/100
2025-09-20 18:03:50,950 - INFO - Running noise experiment 19/100
2025-09-20 18:03:51,484 - INFO - Running noise experiment 20/100
2025-09-20 18:03:52,023 - INFO - Running noise experiment 21/100
2025-09-20 18:03:52,659 - INFO - Running noise experiment 22/100
2025-09-20 18:03:53,197 - INFO - Running noise experiment 23/100
2025-09-20 18:03:53,738 - INFO - Running noise experiment 24/100
2025-09-20 18:03:54,279 - INFO - Running noise experiment 25/100
2025-09-20 18:03:54,820 - INFO - Running noise experiment 26/100
2025-09-20 18:03:55,363 - INFO - Running noise experiment 27/100
2025-09-20 18:03:55,900 - INFO - Running noise experiment 28/100
2025-09-20 18:03:56,436 - INFO - Running noise experiment 29/100
2025-09-20 18:03:56,969 - INFO - Running noise experiment 30/100
2025-09-20 18:03:57,508 - INFO - Running noise experiment 31/100
2025-09-20 18:03:58,046 - INFO - Running noise experiment 32/100
2025-09-20 18:03:58,587 - INFO - Running noise experiment 33/100
2025-09-20 18:03:59,121 - INFO - Running noise experiment 34/100
2025-09-20 18:03:59,664 - INFO - Running noise experiment 35/100
2025-09-20 18:04:00,204 - INFO - Running noise experiment 36/100
2025-09-20 18:04:00,738 - INFO - Running noise experiment 37/100
2025-09-20 18:04:01,274 - INFO - Running noise experiment 38/100
2025-09-20 18:04:01,808 - INFO - Running noise experiment 39/100
2025-09-20 18:04:02,341 - INFO - Running noise experiment 40/100
2025-09-20 18:04:02,874 - INFO - Running noise experiment 41/100
2025-09-20 18:04:03,409 - INFO - Running noise experiment 42/100
2025-09-20 18:04:03,946 - INFO - Running noise experiment 43/100
2025-09-20 18:04:04,487 - INFO - Running noise experiment 44/100
2025-09-20 18:04:05,024 - INFO - Running noise experiment 45/100
2025-09-20 18:04:05,565 - INFO - Running noise experiment 46/100
2025-09-20 18:04:06,103 - INFO - Running noise experiment 47/100
2025-09-20 18:04:06,643 - INFO - Running noise experiment 48/100
2025-09-20 18:04:07,184 - INFO - Running noise experiment 49/100
2025-09-20 18:04:07,720 - INFO - Running noise experiment 50/100
2025-09-20 18:04:08,256 - INFO - Running noise experiment 51/100
2025-09-20 18:04:08,797 - INFO - Running noise experiment 52/100
2025-09-20 18:04:09,336 - INFO - Running noise experiment 53/100
2025-09-20 18:04:09,871 - INFO - Running noise experiment 54/100
2025-09-20 18:04:10,409 - INFO - Running noise experiment 55/100
2025-09-20 18:04:10,947 - INFO - Running noise experiment 56/100
2025-09-20 18:04:11,483 - INFO - Running noise experiment 57/100
2025-09-20 18:04:12,022 - INFO - Running noise experiment 58/100
2025-09-20 18:04:12,563 - INFO - Running noise experiment 59/100
2025-09-20 18:04:13,102 - INFO - Running noise experiment 60/100
2025-09-20 18:04:13,636 - INFO - Running noise experiment 61/100
2025-09-20 18:04:14,173 - INFO - Running noise experiment 62/100
2025-09-20 18:04:14,709 - INFO - Running noise experiment 63/100
2025-09-20 18:04:15,258 - INFO - Running noise experiment 64/100
2025-09-20 18:04:15,804 - INFO - Running noise experiment 65/100
2025-09-20 18:04:16,335 - INFO - Running noise experiment 66/100
2025-09-20 18:04:16,885 - INFO - Running noise experiment 67/100
2025-09-20 18:04:17,432 - INFO - Running noise experiment 68/100
2025-09-20 18:04:17,990 - INFO - Running noise experiment 69/100
2025-09-20 18:04:18,547 - INFO - Running noise experiment 70/100
2025-09-20 18:04:19,093 - INFO - Running noise experiment 71/100
2025-09-20 18:04:19,645 - INFO - Running noise experiment 72/100
2025-09-20 18:04:20,186 - INFO - Running noise experiment 73/100
2025-09-20 18:04:20,742 - INFO - Running noise experiment 74/100
2025-09-20 18:04:21,389 - INFO - Running noise experiment 75/100
2025-09-20 18:04:21,926 - INFO - Running noise experiment 76/100
2025-09-20 18:04:22,464 - INFO - Running noise experiment 77/100
2025-09-20 18:04:23,014 - INFO - Running noise experiment 78/100
2025-09-20 18:04:23,545 - INFO - Running noise experiment 79/100
2025-09-20 18:04:24,086 - INFO - Running noise experiment 80/100
2025-09-20 18:04:24,619 - INFO - Running noise experiment 81/100
2025-09-20 18:04:25,169 - INFO - Running noise experiment 82/100
2025-09-20 18:04:25,705 - INFO - Running noise experiment 83/100
2025-09-20 18:04:26,239 - INFO - Running noise experiment 84/100
2025-09-20 18:04:26,789 - INFO - Running noise experiment 85/100
2025-09-20 18:04:27,343 - INFO - Running noise experiment 86/100
2025-09-20 18:04:27,892 - INFO - Running noise experiment 87/100
2025-09-20 18:04:28,426 - INFO - Running noise experiment 88/100
2025-09-20 18:04:28,962 - INFO - Running noise experiment 89/100
2025-09-20 18:04:29,494 - INFO - Running noise experiment 90/100
2025-09-20 18:04:30,018 - INFO - Running noise experiment 91/100
2025-09-20 18:04:30,553 - INFO - Running noise experiment 92/100
2025-09-20 18:04:31,091 - INFO - Running noise experiment 93/100
2025-09-20 18:04:31,634 - INFO - Running noise experiment 94/100
2025-09-20 18:04:32,179 - INFO - Running noise experiment 95/100
2025-09-20 18:04:32,732 - INFO - Running noise experiment 96/100
2025-09-20 18:04:33,270 - INFO - Running noise experiment 97/100
2025-09-20 18:04:33,817 - INFO - Running noise experiment 98/100
2025-09-20 18:04:34,344 - INFO - Running noise experiment 99/100
2025-09-20 18:04:34,879 - INFO - Running noise experiment 100/100
2025-09-20 18:04:35,417 - INFO - Successfully collected activation differences from 720 modules
2025-09-20 18:04:35,417 - INFO - Computing neuron importance
2025-09-20 18:23:14,572 - INFO - Found 289996797 meaningful neurons
2025-09-20 18:23:14,572 - INFO - Sorting neurons by activation difference
2025-09-20 18:24:34,864 - INFO - Saving results to ./abl/s4.json
2025-09-20 18:24:34,927 - INFO - Multi-GPU analysis completed
2025-09-20 18:24:34,928 - INFO - Total discovered neurons: 289996797
2025-09-20 18:24:34,928 - INFO - Used 8 GPUs for computation
2025-09-20 18:24:34,928 - INFO - Top 10 neurons with highest activation difference:
2025-09-20 18:24:34,928 - INFO - Rank 1: Layer model.layers.3.mlp.down_proj, Activation diff: 471.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 18:24:34,928 - INFO - Rank 2: Layer model.layers.3.mlp.down_proj, Activation diff: 420.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 18:24:34,928 - INFO - Rank 3: Layer model.layers.3.mlp.down_proj, Activation diff: 392.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 18:24:34,928 - INFO - Rank 4: Layer model.layers.79.mlp.down_proj, Activation diff: 390.500000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 18:24:34,928 - INFO - Rank 5: Layer model.layers.79.mlp.down_proj, Activation diff: 343.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 18:24:34,928 - INFO - Rank 6: Layer model.layers.79.mlp.down_proj, Activation diff: 336.500000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 18:24:34,928 - INFO - Rank 7: Layer model.layers.0.mlp.down_proj, Activation diff: 62.687500, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 18:24:34,928 - INFO - Rank 8: Layer model.layers.79.mlp.down_proj, Activation diff: 51.281250, batch_idx: 0, seq_idx: 0, hidden_idx: 775
2025-09-20 18:24:34,928 - INFO - Rank 9: Layer model.layers.79.mlp.down_proj, Activation diff: 38.031250, batch_idx: 0, seq_idx: 20, hidden_idx: 5114
2025-09-20 18:24:34,928 - INFO - Rank 10: Layer model.layers.79.mlp.down_proj, Activation diff: 36.562500, batch_idx: 0, seq_idx: 23, hidden_idx: 5114
2025-09-20 18:24:36,469 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 18:24:36,474 - INFO - Discovered 289996797 neurons
2025-09-20 18:24:36,480 - INFO - Results saved to: ./abl/s4.json
2025-09-20 18:24:36,488 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 18:27:37,929 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 18:27:37,929 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:27:37,929 - INFO - Neuron file: ./abl/s2.json
2025-09-20 18:27:37,929 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:27:37,929 - INFO - Step size: 1
2025-09-20 18:27:37,929 - INFO - Max magnitude increase: 3.0
2025-09-20 18:27:37,929 - INFO - Random seed: 42
2025-09-20 18:27:37,929 - INFO - Device: auto
2025-09-20 18:27:38,619 - INFO - Available GPUs: 8
2025-09-20 18:27:38,620 - INFO - Available GPUs: 8
2025-09-20 18:27:38,620 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:27:38,620 - INFO - Transformers version: 4.56.1
2025-09-20 18:27:38,620 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 18:27:38,620 - INFO - CUDA available: True
2025-09-20 18:28:11,535 - INFO - Multi-GPU model loading completed
2025-09-20 18:28:11,535 - INFO - Model device allocation:
2025-09-20 18:28:11,535 - INFO -   model.embed_tokens: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.0: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.1: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.2: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.3: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.4: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.5: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.6: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.7: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.8: 0
2025-09-20 18:28:11,535 - INFO -   model.layers.9: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.10: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.11: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.12: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.13: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.14: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.15: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.16: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.17: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.18: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.19: 1
2025-09-20 18:28:11,535 - INFO -   model.layers.20: 2
2025-09-20 18:28:11,535 - INFO -   model.layers.21: 2
2025-09-20 18:28:11,535 - INFO -   model.layers.22: 2
2025-09-20 18:28:11,535 - INFO -   model.layers.23: 2
2025-09-20 18:28:11,535 - INFO -   model.layers.24: 2
2025-09-20 18:28:11,535 - INFO -   model.layers.25: 2
2025-09-20 18:28:11,536 - INFO -   model.layers.26: 2
2025-09-20 18:28:11,536 - INFO -   model.layers.27: 2
2025-09-20 18:28:11,536 - INFO -   model.layers.28: 2
2025-09-20 18:28:11,536 - INFO -   model.layers.29: 2
2025-09-20 18:28:11,536 - INFO -   model.layers.30: 2
2025-09-20 18:28:11,536 - INFO -   model.layers.31: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.32: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.33: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.34: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.35: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.36: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.37: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.38: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.39: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.40: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.41: 3
2025-09-20 18:28:11,536 - INFO -   model.layers.42: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.43: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.44: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.45: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.46: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.47: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.48: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.49: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.50: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.51: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.52: 4
2025-09-20 18:28:11,536 - INFO -   model.layers.53: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.54: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.55: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.56: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.57: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.58: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.59: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.60: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.61: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.62: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.63: 5
2025-09-20 18:28:11,536 - INFO -   model.layers.64: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.65: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.66: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.67: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.68: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.69: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.70: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.71: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.72: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.73: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.74: 6
2025-09-20 18:28:11,536 - INFO -   model.layers.75: 7
2025-09-20 18:28:11,536 - INFO -   model.layers.76: 7
2025-09-20 18:28:11,536 - INFO -   model.layers.77: 7
2025-09-20 18:28:11,537 - INFO -   model.layers.78: 7
2025-09-20 18:28:11,537 - INFO -   model.layers.79: 7
2025-09-20 18:28:11,537 - INFO -   model.norm: 7
2025-09-20 18:28:11,537 - INFO -   model.rotary_emb: 7
2025-09-20 18:28:11,537 - INFO -   lm_head: 7
2025-09-20 18:28:11,537 - INFO - Loading neuron importance data from: ./abl/s2.json
2025-09-20 18:28:11,545 - INFO - Loaded 10000 neurons
2025-09-20 18:28:11,545 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 18:28:11,545 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:28:11,545 - INFO - Step size: 1
2025-09-20 18:28:11,545 - INFO - Max magnitude increase: 3.0
2025-09-20 18:28:11,545 - INFO - Using 8 GPUs
2025-09-20 18:28:11,545 - INFO - Computing baseline perplexity
2025-09-20 18:28:12,146 - INFO - Baseline perplexity: 22.9140
2025-09-20 18:28:12,147 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 18:28:12,147 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:28:12,147 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 18:28:12,423 - INFO - Masked perplexity: 24.9976
2025-09-20 18:28:12,423 - INFO - Magnitude increase: 0.0378
2025-09-20 18:28:12,431 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 18:28:12,431 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:28:12,432 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 18:28:12,708 - INFO - Masked perplexity: 29.3805
2025-09-20 18:28:12,708 - INFO - Magnitude increase: 0.1080
2025-09-20 18:28:12,716 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 18:28:12,717 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:28:12,717 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 18:28:12,993 - INFO - Masked perplexity: 23759.0293
2025-09-20 18:28:12,993 - INFO - Magnitude increase: 3.0157
2025-09-20 18:28:12,993 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 18:28:12,993 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 18:28:12,994 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 18:28:12,994 - INFO - Total steps: 3
2025-09-20 18:28:12,994 - INFO - Final masked neurons: 3
2025-09-20 18:28:12,994 - INFO - Used 8 GPUs for computation
2025-09-20 18:28:12,994 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 18:28:12,994 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 18:28:12,994 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 18:28:12,994 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 18:28:12,994 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 18:28:12,994 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 18:28:12,994 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 18:31:32,961 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 18:31:32,961 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:31:32,961 - INFO - Neuron file: ./abl/s3.json
2025-09-20 18:31:32,961 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:31:32,961 - INFO - Step size: 1
2025-09-20 18:31:32,961 - INFO - Max magnitude increase: 3.0
2025-09-20 18:31:32,962 - INFO - Random seed: 42
2025-09-20 18:31:32,962 - INFO - Device: auto
2025-09-20 18:31:33,656 - INFO - Available GPUs: 8
2025-09-20 18:31:33,657 - INFO - Available GPUs: 8
2025-09-20 18:31:33,657 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:31:33,657 - INFO - Transformers version: 4.56.1
2025-09-20 18:31:33,657 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 18:31:33,657 - INFO - CUDA available: True
2025-09-20 18:32:06,442 - INFO - Multi-GPU model loading completed
2025-09-20 18:32:06,442 - INFO - Model device allocation:
2025-09-20 18:32:06,443 - INFO -   model.embed_tokens: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.0: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.1: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.2: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.3: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.4: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.5: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.6: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.7: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.8: 0
2025-09-20 18:32:06,443 - INFO -   model.layers.9: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.10: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.11: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.12: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.13: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.14: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.15: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.16: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.17: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.18: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.19: 1
2025-09-20 18:32:06,443 - INFO -   model.layers.20: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.21: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.22: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.23: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.24: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.25: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.26: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.27: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.28: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.29: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.30: 2
2025-09-20 18:32:06,443 - INFO -   model.layers.31: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.32: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.33: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.34: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.35: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.36: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.37: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.38: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.39: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.40: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.41: 3
2025-09-20 18:32:06,443 - INFO -   model.layers.42: 4
2025-09-20 18:32:06,443 - INFO -   model.layers.43: 4
2025-09-20 18:32:06,443 - INFO -   model.layers.44: 4
2025-09-20 18:32:06,443 - INFO -   model.layers.45: 4
2025-09-20 18:32:06,443 - INFO -   model.layers.46: 4
2025-09-20 18:32:06,443 - INFO -   model.layers.47: 4
2025-09-20 18:32:06,443 - INFO -   model.layers.48: 4
2025-09-20 18:32:06,444 - INFO -   model.layers.49: 4
2025-09-20 18:32:06,444 - INFO -   model.layers.50: 4
2025-09-20 18:32:06,444 - INFO -   model.layers.51: 4
2025-09-20 18:32:06,444 - INFO -   model.layers.52: 4
2025-09-20 18:32:06,444 - INFO -   model.layers.53: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.54: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.55: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.56: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.57: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.58: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.59: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.60: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.61: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.62: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.63: 5
2025-09-20 18:32:06,444 - INFO -   model.layers.64: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.65: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.66: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.67: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.68: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.69: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.70: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.71: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.72: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.73: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.74: 6
2025-09-20 18:32:06,444 - INFO -   model.layers.75: 7
2025-09-20 18:32:06,444 - INFO -   model.layers.76: 7
2025-09-20 18:32:06,444 - INFO -   model.layers.77: 7
2025-09-20 18:32:06,444 - INFO -   model.layers.78: 7
2025-09-20 18:32:06,444 - INFO -   model.layers.79: 7
2025-09-20 18:32:06,444 - INFO -   model.norm: 7
2025-09-20 18:32:06,444 - INFO -   model.rotary_emb: 7
2025-09-20 18:32:06,444 - INFO -   lm_head: 7
2025-09-20 18:32:06,444 - INFO - Loading neuron importance data from: ./abl/s3.json
2025-09-20 18:32:06,453 - INFO - Loaded 10000 neurons
2025-09-20 18:32:06,453 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 18:32:06,453 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:32:06,453 - INFO - Step size: 1
2025-09-20 18:32:06,453 - INFO - Max magnitude increase: 3.0
2025-09-20 18:32:06,453 - INFO - Using 8 GPUs
2025-09-20 18:32:06,453 - INFO - Computing baseline perplexity
2025-09-20 18:32:07,051 - INFO - Baseline perplexity: 22.9140
2025-09-20 18:32:07,052 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 18:32:07,052 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:32:07,052 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 18:32:07,328 - INFO - Masked perplexity: 24.9976
2025-09-20 18:32:07,328 - INFO - Magnitude increase: 0.0378
2025-09-20 18:32:07,336 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 18:32:07,336 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:32:07,336 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 18:32:07,612 - INFO - Masked perplexity: 29.3805
2025-09-20 18:32:07,613 - INFO - Magnitude increase: 0.1080
2025-09-20 18:32:07,621 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 18:32:07,621 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:32:07,621 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 18:32:07,898 - INFO - Masked perplexity: 23759.0293
2025-09-20 18:32:07,898 - INFO - Magnitude increase: 3.0157
2025-09-20 18:32:07,898 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 18:32:07,898 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 18:32:07,898 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 18:32:07,898 - INFO - Total steps: 3
2025-09-20 18:32:07,898 - INFO - Final masked neurons: 3
2025-09-20 18:32:07,898 - INFO - Used 8 GPUs for computation
2025-09-20 18:32:07,898 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 18:32:07,898 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 18:32:07,898 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 18:32:07,898 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 18:32:07,898 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 18:32:07,898 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 18:32:07,898 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 18:48:17,132 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 18:48:17,132 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:48:17,132 - INFO - Neuron file: ./abl/s4.json
2025-09-20 18:48:17,132 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:48:17,133 - INFO - Step size: 1
2025-09-20 18:48:17,133 - INFO - Max magnitude increase: 3.0
2025-09-20 18:48:17,133 - INFO - Random seed: 42
2025-09-20 18:48:17,133 - INFO - Device: auto
2025-09-20 18:48:17,827 - INFO - Available GPUs: 8
2025-09-20 18:48:17,828 - INFO - Available GPUs: 8
2025-09-20 18:48:17,828 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:48:17,828 - INFO - Transformers version: 4.56.1
2025-09-20 18:48:17,828 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 18:48:17,828 - INFO - CUDA available: True
2025-09-20 18:48:50,258 - INFO - Multi-GPU model loading completed
2025-09-20 18:48:50,258 - INFO - Model device allocation:
2025-09-20 18:48:50,258 - INFO -   model.embed_tokens: 0
2025-09-20 18:48:50,258 - INFO -   model.layers.0: 0
2025-09-20 18:48:50,258 - INFO -   model.layers.1: 0
2025-09-20 18:48:50,258 - INFO -   model.layers.2: 0
2025-09-20 18:48:50,258 - INFO -   model.layers.3: 0
2025-09-20 18:48:50,258 - INFO -   model.layers.4: 0
2025-09-20 18:48:50,258 - INFO -   model.layers.5: 0
2025-09-20 18:48:50,259 - INFO -   model.layers.6: 0
2025-09-20 18:48:50,259 - INFO -   model.layers.7: 0
2025-09-20 18:48:50,259 - INFO -   model.layers.8: 0
2025-09-20 18:48:50,259 - INFO -   model.layers.9: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.10: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.11: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.12: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.13: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.14: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.15: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.16: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.17: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.18: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.19: 1
2025-09-20 18:48:50,259 - INFO -   model.layers.20: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.21: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.22: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.23: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.24: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.25: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.26: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.27: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.28: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.29: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.30: 2
2025-09-20 18:48:50,259 - INFO -   model.layers.31: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.32: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.33: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.34: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.35: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.36: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.37: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.38: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.39: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.40: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.41: 3
2025-09-20 18:48:50,259 - INFO -   model.layers.42: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.43: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.44: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.45: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.46: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.47: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.48: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.49: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.50: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.51: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.52: 4
2025-09-20 18:48:50,259 - INFO -   model.layers.53: 5
2025-09-20 18:48:50,259 - INFO -   model.layers.54: 5
2025-09-20 18:48:50,259 - INFO -   model.layers.55: 5
2025-09-20 18:48:50,259 - INFO -   model.layers.56: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.57: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.58: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.59: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.60: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.61: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.62: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.63: 5
2025-09-20 18:48:50,260 - INFO -   model.layers.64: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.65: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.66: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.67: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.68: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.69: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.70: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.71: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.72: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.73: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.74: 6
2025-09-20 18:48:50,260 - INFO -   model.layers.75: 7
2025-09-20 18:48:50,260 - INFO -   model.layers.76: 7
2025-09-20 18:48:50,260 - INFO -   model.layers.77: 7
2025-09-20 18:48:50,260 - INFO -   model.layers.78: 7
2025-09-20 18:48:50,260 - INFO -   model.layers.79: 7
2025-09-20 18:48:50,260 - INFO -   model.norm: 7
2025-09-20 18:48:50,260 - INFO -   model.rotary_emb: 7
2025-09-20 18:48:50,260 - INFO -   lm_head: 7
2025-09-20 18:48:50,260 - INFO - Loading neuron importance data from: ./abl/s4.json
2025-09-20 18:48:50,269 - INFO - Loaded 10000 neurons
2025-09-20 18:48:50,269 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 18:48:50,269 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:48:50,269 - INFO - Step size: 1
2025-09-20 18:48:50,269 - INFO - Max magnitude increase: 3.0
2025-09-20 18:48:50,269 - INFO - Using 8 GPUs
2025-09-20 18:48:50,269 - INFO - Computing baseline perplexity
2025-09-20 18:48:50,869 - INFO - Baseline perplexity: 22.9140
2025-09-20 18:48:50,870 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 18:48:50,870 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:48:50,870 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 18:48:51,145 - INFO - Masked perplexity: 24.9976
2025-09-20 18:48:51,145 - INFO - Magnitude increase: 0.0378
2025-09-20 18:48:51,154 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 18:48:51,155 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:48:51,155 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 18:48:51,431 - INFO - Masked perplexity: 29.3805
2025-09-20 18:48:51,431 - INFO - Magnitude increase: 0.1080
2025-09-20 18:48:51,439 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 18:48:51,439 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:48:51,439 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 18:48:51,716 - INFO - Masked perplexity: 23759.0293
2025-09-20 18:48:51,716 - INFO - Magnitude increase: 3.0157
2025-09-20 18:48:51,716 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 18:48:51,716 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 18:48:51,716 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 18:48:51,716 - INFO - Total steps: 3
2025-09-20 18:48:51,716 - INFO - Final masked neurons: 3
2025-09-20 18:48:51,716 - INFO - Used 8 GPUs for computation
2025-09-20 18:48:51,716 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 18:48:51,716 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 18:48:51,716 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 18:48:51,716 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 18:48:51,716 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 18:48:51,716 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 18:48:51,716 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 18:50:39,414 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 18:50:39,414 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:50:39,414 - INFO - Neuron file: ./abl/s5.json
2025-09-20 18:50:39,414 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:50:39,414 - INFO - Step size: 1
2025-09-20 18:50:39,414 - INFO - Max magnitude increase: 3.0
2025-09-20 18:50:39,414 - INFO - Random seed: 42
2025-09-20 18:50:39,414 - INFO - Device: auto
2025-09-20 18:50:40,122 - INFO - Available GPUs: 8
2025-09-20 18:50:40,123 - INFO - Available GPUs: 8
2025-09-20 18:50:40,123 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:50:40,123 - INFO - Transformers version: 4.56.1
2025-09-20 18:50:40,123 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 18:50:40,123 - INFO - CUDA available: True
2025-09-20 18:51:12,630 - INFO - Multi-GPU model loading completed
2025-09-20 18:51:12,630 - INFO - Model device allocation:
2025-09-20 18:51:12,630 - INFO -   model.embed_tokens: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.0: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.1: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.2: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.3: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.4: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.5: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.6: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.7: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.8: 0
2025-09-20 18:51:12,630 - INFO -   model.layers.9: 1
2025-09-20 18:51:12,630 - INFO -   model.layers.10: 1
2025-09-20 18:51:12,630 - INFO -   model.layers.11: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.12: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.13: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.14: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.15: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.16: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.17: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.18: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.19: 1
2025-09-20 18:51:12,631 - INFO -   model.layers.20: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.21: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.22: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.23: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.24: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.25: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.26: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.27: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.28: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.29: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.30: 2
2025-09-20 18:51:12,631 - INFO -   model.layers.31: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.32: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.33: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.34: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.35: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.36: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.37: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.38: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.39: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.40: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.41: 3
2025-09-20 18:51:12,631 - INFO -   model.layers.42: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.43: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.44: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.45: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.46: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.47: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.48: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.49: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.50: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.51: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.52: 4
2025-09-20 18:51:12,631 - INFO -   model.layers.53: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.54: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.55: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.56: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.57: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.58: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.59: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.60: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.61: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.62: 5
2025-09-20 18:51:12,631 - INFO -   model.layers.63: 5
2025-09-20 18:51:12,632 - INFO -   model.layers.64: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.65: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.66: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.67: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.68: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.69: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.70: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.71: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.72: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.73: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.74: 6
2025-09-20 18:51:12,632 - INFO -   model.layers.75: 7
2025-09-20 18:51:12,632 - INFO -   model.layers.76: 7
2025-09-20 18:51:12,632 - INFO -   model.layers.77: 7
2025-09-20 18:51:12,632 - INFO -   model.layers.78: 7
2025-09-20 18:51:12,632 - INFO -   model.layers.79: 7
2025-09-20 18:51:12,632 - INFO -   model.norm: 7
2025-09-20 18:51:12,632 - INFO -   model.rotary_emb: 7
2025-09-20 18:51:12,632 - INFO -   lm_head: 7
2025-09-20 18:51:12,632 - INFO - Loading neuron importance data from: ./abl/s5.json
2025-09-20 18:51:12,640 - INFO - Loaded 10000 neurons
2025-09-20 18:51:12,640 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 18:51:12,640 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:51:12,640 - INFO - Step size: 1
2025-09-20 18:51:12,640 - INFO - Max magnitude increase: 3.0
2025-09-20 18:51:12,640 - INFO - Using 8 GPUs
2025-09-20 18:51:12,640 - INFO - Computing baseline perplexity
2025-09-20 18:51:13,239 - INFO - Baseline perplexity: 22.9140
2025-09-20 18:51:13,240 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 18:51:13,240 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:51:13,240 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 18:51:13,515 - INFO - Masked perplexity: 24.9976
2025-09-20 18:51:13,515 - INFO - Magnitude increase: 0.0378
2025-09-20 18:51:13,523 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 18:51:13,524 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:51:13,524 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 18:51:13,799 - INFO - Masked perplexity: 29.3805
2025-09-20 18:51:13,800 - INFO - Magnitude increase: 0.1080
2025-09-20 18:51:13,808 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 18:51:13,808 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:51:13,808 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 18:51:14,084 - INFO - Masked perplexity: 23759.0293
2025-09-20 18:51:14,084 - INFO - Magnitude increase: 3.0157
2025-09-20 18:51:14,084 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 18:51:14,084 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 18:51:14,085 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 18:51:14,085 - INFO - Total steps: 3
2025-09-20 18:51:14,085 - INFO - Final masked neurons: 3
2025-09-20 18:51:14,085 - INFO - Used 8 GPUs for computation
2025-09-20 18:51:14,085 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 18:51:14,085 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 18:51:14,085 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 18:51:14,085 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 18:51:14,085 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 18:51:14,085 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 18:51:14,085 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 18:53:20,204 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 18:53:20,205 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:53:20,205 - INFO - Neuron file: ./abl/s6.json
2025-09-20 18:53:20,205 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:53:20,205 - INFO - Step size: 1
2025-09-20 18:53:20,205 - INFO - Max magnitude increase: 3.0
2025-09-20 18:53:20,205 - INFO - Random seed: 42
2025-09-20 18:53:20,205 - INFO - Device: auto
2025-09-20 18:53:20,899 - INFO - Available GPUs: 8
2025-09-20 18:53:20,900 - INFO - Available GPUs: 8
2025-09-20 18:53:20,900 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:53:20,900 - INFO - Transformers version: 4.56.1
2025-09-20 18:53:20,900 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 18:53:20,900 - INFO - CUDA available: True
2025-09-20 18:53:53,586 - INFO - Multi-GPU model loading completed
2025-09-20 18:53:53,587 - INFO - Model device allocation:
2025-09-20 18:53:53,587 - INFO -   model.embed_tokens: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.0: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.1: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.2: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.3: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.4: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.5: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.6: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.7: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.8: 0
2025-09-20 18:53:53,587 - INFO -   model.layers.9: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.10: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.11: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.12: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.13: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.14: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.15: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.16: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.17: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.18: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.19: 1
2025-09-20 18:53:53,587 - INFO -   model.layers.20: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.21: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.22: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.23: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.24: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.25: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.26: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.27: 2
2025-09-20 18:53:53,587 - INFO -   model.layers.28: 2
2025-09-20 18:53:53,588 - INFO -   model.layers.29: 2
2025-09-20 18:53:53,588 - INFO -   model.layers.30: 2
2025-09-20 18:53:53,588 - INFO -   model.layers.31: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.32: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.33: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.34: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.35: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.36: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.37: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.38: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.39: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.40: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.41: 3
2025-09-20 18:53:53,588 - INFO -   model.layers.42: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.43: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.44: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.45: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.46: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.47: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.48: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.49: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.50: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.51: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.52: 4
2025-09-20 18:53:53,588 - INFO -   model.layers.53: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.54: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.55: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.56: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.57: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.58: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.59: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.60: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.61: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.62: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.63: 5
2025-09-20 18:53:53,588 - INFO -   model.layers.64: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.65: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.66: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.67: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.68: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.69: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.70: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.71: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.72: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.73: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.74: 6
2025-09-20 18:53:53,588 - INFO -   model.layers.75: 7
2025-09-20 18:53:53,588 - INFO -   model.layers.76: 7
2025-09-20 18:53:53,588 - INFO -   model.layers.77: 7
2025-09-20 18:53:53,588 - INFO -   model.layers.78: 7
2025-09-20 18:53:53,588 - INFO -   model.layers.79: 7
2025-09-20 18:53:53,588 - INFO -   model.norm: 7
2025-09-20 18:53:53,588 - INFO -   model.rotary_emb: 7
2025-09-20 18:53:53,589 - INFO -   lm_head: 7
2025-09-20 18:53:53,589 - INFO - Loading neuron importance data from: ./abl/s6.json
2025-09-20 18:53:53,597 - INFO - Loaded 10000 neurons
2025-09-20 18:53:53,597 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 18:53:53,597 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 18:53:53,597 - INFO - Step size: 1
2025-09-20 18:53:53,597 - INFO - Max magnitude increase: 3.0
2025-09-20 18:53:53,597 - INFO - Using 8 GPUs
2025-09-20 18:53:53,597 - INFO - Computing baseline perplexity
2025-09-20 18:53:54,197 - INFO - Baseline perplexity: 22.9140
2025-09-20 18:53:54,197 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 18:53:54,198 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:53:54,198 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 18:53:54,473 - INFO - Masked perplexity: 24.9976
2025-09-20 18:53:54,473 - INFO - Magnitude increase: 0.0378
2025-09-20 18:53:54,482 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 18:53:54,482 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:53:54,482 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 18:53:54,758 - INFO - Masked perplexity: 29.3805
2025-09-20 18:53:54,758 - INFO - Magnitude increase: 0.1080
2025-09-20 18:53:54,767 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 18:53:54,767 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 18:53:54,767 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 18:53:55,043 - INFO - Masked perplexity: 23759.0293
2025-09-20 18:53:55,044 - INFO - Magnitude increase: 3.0157
2025-09-20 18:53:55,044 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 18:53:55,044 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 18:53:55,044 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 18:53:55,044 - INFO - Total steps: 3
2025-09-20 18:53:55,044 - INFO - Final masked neurons: 3
2025-09-20 18:53:55,044 - INFO - Used 8 GPUs for computation
2025-09-20 18:53:55,044 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 18:53:55,044 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 18:53:55,044 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 18:53:55,044 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 18:53:55,044 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 18:53:55,044 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 18:53:55,044 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 18:55:10,393 - INFO - === Multi-GPU Neuron Activation Difference Analyzer ===
2025-09-20 18:55:10,393 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:55:10,393 - INFO - Input text: Inception, directed by Christopher Nolan, is a sci-fi thriller about dream infiltration. Its innovat...
2025-09-20 18:55:10,393 - INFO - Noise scale: 5.0
2025-09-20 18:55:10,393 - INFO - Number of samples: 100
2025-09-20 18:55:10,393 - INFO - Random seed: 42
2025-09-20 18:55:10,393 - INFO - Device: auto
2025-09-20 18:55:11,083 - INFO - Available GPUs: 8
2025-09-20 18:55:11,084 - INFO - Available GPUs: 8
2025-09-20 18:55:11,084 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 18:55:11,084 - INFO - Transformers version: 4.56.1
2025-09-20 18:55:11,084 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 18:55:11,084 - INFO - CUDA available: True
2025-09-20 18:55:43,730 - INFO - Multi-GPU model loading completed
2025-09-20 18:55:43,730 - INFO - Model device allocation:
2025-09-20 18:55:43,730 - INFO -   model.embed_tokens: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.0: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.1: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.2: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.3: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.4: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.5: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.6: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.7: 0
2025-09-20 18:55:43,730 - INFO -   model.layers.8: 0
2025-09-20 18:55:43,731 - INFO -   model.layers.9: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.10: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.11: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.12: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.13: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.14: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.15: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.16: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.17: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.18: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.19: 1
2025-09-20 18:55:43,731 - INFO -   model.layers.20: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.21: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.22: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.23: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.24: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.25: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.26: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.27: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.28: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.29: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.30: 2
2025-09-20 18:55:43,731 - INFO -   model.layers.31: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.32: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.33: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.34: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.35: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.36: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.37: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.38: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.39: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.40: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.41: 3
2025-09-20 18:55:43,731 - INFO -   model.layers.42: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.43: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.44: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.45: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.46: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.47: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.48: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.49: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.50: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.51: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.52: 4
2025-09-20 18:55:43,731 - INFO -   model.layers.53: 5
2025-09-20 18:55:43,731 - INFO -   model.layers.54: 5
2025-09-20 18:55:43,731 - INFO -   model.layers.55: 5
2025-09-20 18:55:43,731 - INFO -   model.layers.56: 5
2025-09-20 18:55:43,731 - INFO -   model.layers.57: 5
2025-09-20 18:55:43,731 - INFO -   model.layers.58: 5
2025-09-20 18:55:43,731 - INFO -   model.layers.59: 5
2025-09-20 18:55:43,731 - INFO -   model.layers.60: 5
2025-09-20 18:55:43,732 - INFO -   model.layers.61: 5
2025-09-20 18:55:43,732 - INFO -   model.layers.62: 5
2025-09-20 18:55:43,732 - INFO -   model.layers.63: 5
2025-09-20 18:55:43,732 - INFO -   model.layers.64: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.65: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.66: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.67: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.68: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.69: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.70: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.71: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.72: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.73: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.74: 6
2025-09-20 18:55:43,732 - INFO -   model.layers.75: 7
2025-09-20 18:55:43,732 - INFO -   model.layers.76: 7
2025-09-20 18:55:43,732 - INFO -   model.layers.77: 7
2025-09-20 18:55:43,732 - INFO -   model.layers.78: 7
2025-09-20 18:55:43,732 - INFO -   model.layers.79: 7
2025-09-20 18:55:43,732 - INFO -   model.norm: 7
2025-09-20 18:55:43,732 - INFO -   model.rotary_emb: 7
2025-09-20 18:55:43,732 - INFO -   lm_head: 7
2025-09-20 18:55:43,732 - INFO - Starting multi-GPU neuron activation difference analysis
2025-09-20 18:55:43,738 - INFO - Set up hooks for 720 key modules
2025-09-20 18:55:43,750 - INFO - Input text length: 34 tokens
2025-09-20 18:55:43,750 - INFO - Input device: cuda:0
2025-09-20 18:55:43,750 - INFO - Collecting baseline activations across GPUs
2025-09-20 18:55:44,551 - INFO - Collected baseline activations from 720 modules
2025-09-20 18:55:44,551 - INFO - Running noise experiment 1/100
2025-09-20 18:55:44,974 - INFO - Running noise experiment 2/100
2025-09-20 18:55:45,432 - INFO - Running noise experiment 3/100
2025-09-20 18:55:45,964 - INFO - Running noise experiment 4/100
2025-09-20 18:55:46,528 - INFO - Running noise experiment 5/100
2025-09-20 18:55:47,105 - INFO - Running noise experiment 6/100
2025-09-20 18:55:47,669 - INFO - Running noise experiment 7/100
2025-09-20 18:55:48,236 - INFO - Running noise experiment 8/100
2025-09-20 18:55:48,807 - INFO - Running noise experiment 9/100
2025-09-20 18:55:49,388 - INFO - Running noise experiment 10/100
2025-09-20 18:55:49,991 - INFO - Running noise experiment 11/100
2025-09-20 18:55:50,545 - INFO - Running noise experiment 12/100
2025-09-20 18:55:51,076 - INFO - Running noise experiment 13/100
2025-09-20 18:55:51,647 - INFO - Running noise experiment 14/100
2025-09-20 18:55:52,215 - INFO - Running noise experiment 15/100
2025-09-20 18:55:52,781 - INFO - Running noise experiment 16/100
2025-09-20 18:55:53,355 - INFO - Running noise experiment 17/100
2025-09-20 18:55:53,923 - INFO - Running noise experiment 18/100
2025-09-20 18:55:54,493 - INFO - Running noise experiment 19/100
2025-09-20 18:55:55,061 - INFO - Running noise experiment 20/100
2025-09-20 18:55:55,632 - INFO - Running noise experiment 21/100
2025-09-20 18:55:56,297 - INFO - Running noise experiment 22/100
2025-09-20 18:55:56,871 - INFO - Running noise experiment 23/100
2025-09-20 18:55:57,443 - INFO - Running noise experiment 24/100
2025-09-20 18:55:58,017 - INFO - Running noise experiment 25/100
2025-09-20 18:55:58,587 - INFO - Running noise experiment 26/100
2025-09-20 18:55:59,161 - INFO - Running noise experiment 27/100
2025-09-20 18:55:59,728 - INFO - Running noise experiment 28/100
2025-09-20 18:56:00,304 - INFO - Running noise experiment 29/100
2025-09-20 18:56:00,872 - INFO - Running noise experiment 30/100
2025-09-20 18:56:01,447 - INFO - Running noise experiment 31/100
2025-09-20 18:56:02,012 - INFO - Running noise experiment 32/100
2025-09-20 18:56:02,585 - INFO - Running noise experiment 33/100
2025-09-20 18:56:03,152 - INFO - Running noise experiment 34/100
2025-09-20 18:56:03,719 - INFO - Running noise experiment 35/100
2025-09-20 18:56:04,290 - INFO - Running noise experiment 36/100
2025-09-20 18:56:04,863 - INFO - Running noise experiment 37/100
2025-09-20 18:56:05,433 - INFO - Running noise experiment 38/100
2025-09-20 18:56:06,005 - INFO - Running noise experiment 39/100
2025-09-20 18:56:06,571 - INFO - Running noise experiment 40/100
2025-09-20 18:56:07,140 - INFO - Running noise experiment 41/100
2025-09-20 18:56:07,709 - INFO - Running noise experiment 42/100
2025-09-20 18:56:08,293 - INFO - Running noise experiment 43/100
2025-09-20 18:56:08,870 - INFO - Running noise experiment 44/100
2025-09-20 18:56:09,451 - INFO - Running noise experiment 45/100
2025-09-20 18:56:10,024 - INFO - Running noise experiment 46/100
2025-09-20 18:56:10,605 - INFO - Running noise experiment 47/100
2025-09-20 18:56:11,184 - INFO - Running noise experiment 48/100
2025-09-20 18:56:11,755 - INFO - Running noise experiment 49/100
2025-09-20 18:56:12,317 - INFO - Running noise experiment 50/100
2025-09-20 18:56:12,881 - INFO - Running noise experiment 51/100
2025-09-20 18:56:13,447 - INFO - Running noise experiment 52/100
2025-09-20 18:56:14,016 - INFO - Running noise experiment 53/100
2025-09-20 18:56:14,583 - INFO - Running noise experiment 54/100
2025-09-20 18:56:15,159 - INFO - Running noise experiment 55/100
2025-09-20 18:56:15,721 - INFO - Running noise experiment 56/100
2025-09-20 18:56:16,289 - INFO - Running noise experiment 57/100
2025-09-20 18:56:16,862 - INFO - Running noise experiment 58/100
2025-09-20 18:56:17,429 - INFO - Running noise experiment 59/100
2025-09-20 18:56:18,002 - INFO - Running noise experiment 60/100
2025-09-20 18:56:18,565 - INFO - Running noise experiment 61/100
2025-09-20 18:56:19,131 - INFO - Running noise experiment 62/100
2025-09-20 18:56:19,697 - INFO - Running noise experiment 63/100
2025-09-20 18:56:20,273 - INFO - Running noise experiment 64/100
2025-09-20 18:56:20,839 - INFO - Running noise experiment 65/100
2025-09-20 18:56:21,405 - INFO - Running noise experiment 66/100
2025-09-20 18:56:21,967 - INFO - Running noise experiment 67/100
2025-09-20 18:56:22,528 - INFO - Running noise experiment 68/100
2025-09-20 18:56:23,089 - INFO - Running noise experiment 69/100
2025-09-20 18:56:23,655 - INFO - Running noise experiment 70/100
2025-09-20 18:56:24,222 - INFO - Running noise experiment 71/100
2025-09-20 18:56:24,796 - INFO - Running noise experiment 72/100
2025-09-20 18:56:25,367 - INFO - Running noise experiment 73/100
2025-09-20 18:56:25,935 - INFO - Running noise experiment 74/100
2025-09-20 18:56:26,603 - INFO - Running noise experiment 75/100
2025-09-20 18:56:27,171 - INFO - Running noise experiment 76/100
2025-09-20 18:56:27,733 - INFO - Running noise experiment 77/100
2025-09-20 18:56:28,298 - INFO - Running noise experiment 78/100
2025-09-20 18:56:28,863 - INFO - Running noise experiment 79/100
2025-09-20 18:56:29,425 - INFO - Running noise experiment 80/100
2025-09-20 18:56:29,981 - INFO - Running noise experiment 81/100
2025-09-20 18:56:30,541 - INFO - Running noise experiment 82/100
2025-09-20 18:56:31,093 - INFO - Running noise experiment 83/100
2025-09-20 18:56:31,650 - INFO - Running noise experiment 84/100
2025-09-20 18:56:32,207 - INFO - Running noise experiment 85/100
2025-09-20 18:56:32,769 - INFO - Running noise experiment 86/100
2025-09-20 18:56:33,325 - INFO - Running noise experiment 87/100
2025-09-20 18:56:33,885 - INFO - Running noise experiment 88/100
2025-09-20 18:56:34,442 - INFO - Running noise experiment 89/100
2025-09-20 18:56:34,997 - INFO - Running noise experiment 90/100
2025-09-20 18:56:35,555 - INFO - Running noise experiment 91/100
2025-09-20 18:56:36,118 - INFO - Running noise experiment 92/100
2025-09-20 18:56:36,677 - INFO - Running noise experiment 93/100
2025-09-20 18:56:37,240 - INFO - Running noise experiment 94/100
2025-09-20 18:56:37,798 - INFO - Running noise experiment 95/100
2025-09-20 18:56:38,356 - INFO - Running noise experiment 96/100
2025-09-20 18:56:38,911 - INFO - Running noise experiment 97/100
2025-09-20 18:56:39,468 - INFO - Running noise experiment 98/100
2025-09-20 18:56:40,023 - INFO - Running noise experiment 99/100
2025-09-20 18:56:40,581 - INFO - Running noise experiment 100/100
2025-09-20 18:56:41,135 - INFO - Successfully collected activation differences from 720 modules
2025-09-20 18:56:41,135 - INFO - Computing neuron importance
2025-09-20 19:17:25,086 - INFO - Found 328663038 meaningful neurons
2025-09-20 19:17:25,086 - INFO - Sorting neurons by activation difference
2025-09-20 19:18:55,875 - INFO - Saving results to ./abl/s9.json
2025-09-20 19:18:55,938 - INFO - Multi-GPU analysis completed
2025-09-20 19:18:55,939 - INFO - Total discovered neurons: 328663038
2025-09-20 19:18:55,939 - INFO - Used 8 GPUs for computation
2025-09-20 19:18:55,939 - INFO - Top 10 neurons with highest activation difference:
2025-09-20 19:18:55,939 - INFO - Rank 1: Layer model.layers.3.mlp.down_proj, Activation diff: 471.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 19:18:55,939 - INFO - Rank 2: Layer model.layers.3.mlp.down_proj, Activation diff: 420.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 19:18:55,939 - INFO - Rank 3: Layer model.layers.3.mlp.down_proj, Activation diff: 392.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 19:18:55,939 - INFO - Rank 4: Layer model.layers.79.mlp.down_proj, Activation diff: 390.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 19:18:55,939 - INFO - Rank 5: Layer model.layers.79.mlp.down_proj, Activation diff: 342.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 19:18:55,939 - INFO - Rank 6: Layer model.layers.79.mlp.down_proj, Activation diff: 336.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 19:18:55,939 - INFO - Rank 7: Layer model.layers.79.mlp.down_proj, Activation diff: 64.625000, batch_idx: 0, seq_idx: 24, hidden_idx: 5114
2025-09-20 19:18:55,939 - INFO - Rank 8: Layer model.layers.0.mlp.down_proj, Activation diff: 62.718750, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 19:18:55,939 - INFO - Rank 9: Layer model.layers.79.mlp.down_proj, Activation diff: 51.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 775
2025-09-20 19:18:55,939 - INFO - Rank 10: Layer model.layers.79.mlp.down_proj, Activation diff: 48.625000, batch_idx: 0, seq_idx: 32, hidden_idx: 5114
2025-09-20 19:18:57,642 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 19:18:57,646 - INFO - Discovered 328663038 neurons
2025-09-20 19:18:57,651 - INFO - Results saved to: ./abl/s9.json
2025-09-20 19:18:57,656 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 19:34:27,123 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 19:34:27,123 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:34:27,123 - INFO - Neuron file: ./abl/s9.json
2025-09-20 19:34:27,123 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 19:34:27,124 - INFO - Step size: 1
2025-09-20 19:34:27,124 - INFO - Max magnitude increase: 3.0
2025-09-20 19:34:27,124 - INFO - Random seed: 42
2025-09-20 19:34:27,124 - INFO - Device: auto
2025-09-20 19:34:27,814 - INFO - Available GPUs: 8
2025-09-20 19:34:27,815 - INFO - Available GPUs: 8
2025-09-20 19:34:27,815 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:34:27,815 - INFO - Transformers version: 4.56.1
2025-09-20 19:34:27,815 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 19:34:27,815 - INFO - CUDA available: True
2025-09-20 19:35:01,430 - INFO - Multi-GPU model loading completed
2025-09-20 19:35:01,430 - INFO - Model device allocation:
2025-09-20 19:35:01,430 - INFO -   model.embed_tokens: 0
2025-09-20 19:35:01,430 - INFO -   model.layers.0: 0
2025-09-20 19:35:01,430 - INFO -   model.layers.1: 0
2025-09-20 19:35:01,430 - INFO -   model.layers.2: 0
2025-09-20 19:35:01,430 - INFO -   model.layers.3: 0
2025-09-20 19:35:01,430 - INFO -   model.layers.4: 0
2025-09-20 19:35:01,431 - INFO -   model.layers.5: 0
2025-09-20 19:35:01,431 - INFO -   model.layers.6: 0
2025-09-20 19:35:01,431 - INFO -   model.layers.7: 0
2025-09-20 19:35:01,431 - INFO -   model.layers.8: 0
2025-09-20 19:35:01,431 - INFO -   model.layers.9: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.10: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.11: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.12: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.13: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.14: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.15: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.16: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.17: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.18: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.19: 1
2025-09-20 19:35:01,431 - INFO -   model.layers.20: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.21: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.22: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.23: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.24: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.25: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.26: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.27: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.28: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.29: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.30: 2
2025-09-20 19:35:01,431 - INFO -   model.layers.31: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.32: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.33: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.34: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.35: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.36: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.37: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.38: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.39: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.40: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.41: 3
2025-09-20 19:35:01,431 - INFO -   model.layers.42: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.43: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.44: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.45: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.46: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.47: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.48: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.49: 4
2025-09-20 19:35:01,431 - INFO -   model.layers.50: 4
2025-09-20 19:35:01,432 - INFO -   model.layers.51: 4
2025-09-20 19:35:01,432 - INFO -   model.layers.52: 4
2025-09-20 19:35:01,432 - INFO -   model.layers.53: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.54: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.55: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.56: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.57: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.58: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.59: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.60: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.61: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.62: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.63: 5
2025-09-20 19:35:01,432 - INFO -   model.layers.64: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.65: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.66: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.67: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.68: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.69: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.70: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.71: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.72: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.73: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.74: 6
2025-09-20 19:35:01,432 - INFO -   model.layers.75: 7
2025-09-20 19:35:01,432 - INFO -   model.layers.76: 7
2025-09-20 19:35:01,432 - INFO -   model.layers.77: 7
2025-09-20 19:35:01,432 - INFO -   model.layers.78: 7
2025-09-20 19:35:01,432 - INFO -   model.layers.79: 7
2025-09-20 19:35:01,432 - INFO -   model.norm: 7
2025-09-20 19:35:01,432 - INFO -   model.rotary_emb: 7
2025-09-20 19:35:01,432 - INFO -   lm_head: 7
2025-09-20 19:35:01,432 - INFO - Loading neuron importance data from: ./abl/s9.json
2025-09-20 19:35:01,441 - INFO - Loaded 10000 neurons
2025-09-20 19:35:01,441 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 19:35:01,441 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 19:35:01,441 - INFO - Step size: 1
2025-09-20 19:35:01,441 - INFO - Max magnitude increase: 3.0
2025-09-20 19:35:01,441 - INFO - Using 8 GPUs
2025-09-20 19:35:01,441 - INFO - Computing baseline perplexity
2025-09-20 19:35:02,136 - INFO - Baseline perplexity: 22.9140
2025-09-20 19:35:02,136 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 19:35:02,137 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:35:02,137 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 19:35:02,412 - INFO - Masked perplexity: 24.9976
2025-09-20 19:35:02,412 - INFO - Magnitude increase: 0.0378
2025-09-20 19:35:02,421 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 19:35:02,421 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:35:02,421 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 19:35:02,697 - INFO - Masked perplexity: 29.3805
2025-09-20 19:35:02,698 - INFO - Magnitude increase: 0.1080
2025-09-20 19:35:02,706 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 19:35:02,706 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:35:02,706 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 19:35:02,983 - INFO - Masked perplexity: 23759.0293
2025-09-20 19:35:02,983 - INFO - Magnitude increase: 3.0157
2025-09-20 19:35:02,983 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 19:35:02,983 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 19:35:02,983 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 19:35:02,983 - INFO - Total steps: 3
2025-09-20 19:35:02,983 - INFO - Final masked neurons: 3
2025-09-20 19:35:02,983 - INFO - Used 8 GPUs for computation
2025-09-20 19:35:02,983 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 19:35:02,983 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 19:35:02,983 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 19:35:02,984 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 19:35:02,984 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 19:35:02,984 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 19:35:02,984 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 19:35:46,467 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 19:35:46,468 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:35:46,468 - INFO - Neuron file: ./abl/s7.json
2025-09-20 19:35:46,468 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 19:35:46,468 - INFO - Step size: 1
2025-09-20 19:35:46,468 - INFO - Max magnitude increase: 3.0
2025-09-20 19:35:46,468 - INFO - Random seed: 42
2025-09-20 19:35:46,468 - INFO - Device: auto
2025-09-20 19:35:47,163 - INFO - Available GPUs: 8
2025-09-20 19:35:47,164 - INFO - Available GPUs: 8
2025-09-20 19:35:47,164 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:35:47,164 - INFO - Transformers version: 4.56.1
2025-09-20 19:35:47,164 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 19:35:47,164 - INFO - CUDA available: True
2025-09-20 19:36:20,370 - INFO - Multi-GPU model loading completed
2025-09-20 19:36:20,370 - INFO - Model device allocation:
2025-09-20 19:36:20,370 - INFO -   model.embed_tokens: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.0: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.1: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.2: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.3: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.4: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.5: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.6: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.7: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.8: 0
2025-09-20 19:36:20,370 - INFO -   model.layers.9: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.10: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.11: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.12: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.13: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.14: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.15: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.16: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.17: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.18: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.19: 1
2025-09-20 19:36:20,370 - INFO -   model.layers.20: 2
2025-09-20 19:36:20,370 - INFO -   model.layers.21: 2
2025-09-20 19:36:20,370 - INFO -   model.layers.22: 2
2025-09-20 19:36:20,370 - INFO -   model.layers.23: 2
2025-09-20 19:36:20,370 - INFO -   model.layers.24: 2
2025-09-20 19:36:20,370 - INFO -   model.layers.25: 2
2025-09-20 19:36:20,370 - INFO -   model.layers.26: 2
2025-09-20 19:36:20,371 - INFO -   model.layers.27: 2
2025-09-20 19:36:20,371 - INFO -   model.layers.28: 2
2025-09-20 19:36:20,371 - INFO -   model.layers.29: 2
2025-09-20 19:36:20,371 - INFO -   model.layers.30: 2
2025-09-20 19:36:20,371 - INFO -   model.layers.31: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.32: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.33: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.34: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.35: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.36: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.37: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.38: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.39: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.40: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.41: 3
2025-09-20 19:36:20,371 - INFO -   model.layers.42: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.43: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.44: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.45: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.46: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.47: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.48: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.49: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.50: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.51: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.52: 4
2025-09-20 19:36:20,371 - INFO -   model.layers.53: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.54: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.55: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.56: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.57: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.58: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.59: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.60: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.61: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.62: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.63: 5
2025-09-20 19:36:20,371 - INFO -   model.layers.64: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.65: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.66: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.67: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.68: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.69: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.70: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.71: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.72: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.73: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.74: 6
2025-09-20 19:36:20,371 - INFO -   model.layers.75: 7
2025-09-20 19:36:20,371 - INFO -   model.layers.76: 7
2025-09-20 19:36:20,371 - INFO -   model.layers.77: 7
2025-09-20 19:36:20,371 - INFO -   model.layers.78: 7
2025-09-20 19:36:20,371 - INFO -   model.layers.79: 7
2025-09-20 19:36:20,372 - INFO -   model.norm: 7
2025-09-20 19:36:20,372 - INFO -   model.rotary_emb: 7
2025-09-20 19:36:20,372 - INFO -   lm_head: 7
2025-09-20 19:36:20,372 - INFO - Loading neuron importance data from: ./abl/s7.json
2025-09-20 19:36:20,380 - INFO - Loaded 10000 neurons
2025-09-20 19:36:20,380 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 19:36:20,380 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 19:36:20,380 - INFO - Step size: 1
2025-09-20 19:36:20,380 - INFO - Max magnitude increase: 3.0
2025-09-20 19:36:20,380 - INFO - Using 8 GPUs
2025-09-20 19:36:20,380 - INFO - Computing baseline perplexity
2025-09-20 19:36:20,980 - INFO - Baseline perplexity: 22.9140
2025-09-20 19:36:20,981 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 19:36:20,981 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:36:20,981 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 19:36:21,256 - INFO - Masked perplexity: 24.9976
2025-09-20 19:36:21,256 - INFO - Magnitude increase: 0.0378
2025-09-20 19:36:21,265 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 19:36:21,265 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:36:21,265 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 19:36:21,541 - INFO - Masked perplexity: 29.3805
2025-09-20 19:36:21,541 - INFO - Magnitude increase: 0.1080
2025-09-20 19:36:21,550 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 19:36:21,550 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:36:21,550 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 19:36:21,826 - INFO - Masked perplexity: 23759.0293
2025-09-20 19:36:21,826 - INFO - Magnitude increase: 3.0157
2025-09-20 19:36:21,827 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 19:36:21,827 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 19:36:21,827 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 19:36:21,827 - INFO - Total steps: 3
2025-09-20 19:36:21,827 - INFO - Final masked neurons: 3
2025-09-20 19:36:21,827 - INFO - Used 8 GPUs for computation
2025-09-20 19:36:21,827 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 19:36:21,827 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 19:36:21,827 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 19:36:21,827 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 19:36:21,827 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 19:36:21,827 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 19:36:21,827 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 19:36:39,665 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 19:36:39,665 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:36:39,665 - INFO - Neuron file: ./abl/s8.json
2025-09-20 19:36:39,665 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 19:36:39,665 - INFO - Step size: 1
2025-09-20 19:36:39,665 - INFO - Max magnitude increase: 3.0
2025-09-20 19:36:39,665 - INFO - Random seed: 42
2025-09-20 19:36:39,665 - INFO - Device: auto
2025-09-20 19:36:40,422 - INFO - Available GPUs: 8
2025-09-20 19:36:40,423 - INFO - Available GPUs: 8
2025-09-20 19:36:40,423 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:36:40,423 - INFO - Transformers version: 4.56.1
2025-09-20 19:36:40,423 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 19:36:40,423 - INFO - CUDA available: True
2025-09-20 19:37:13,591 - INFO - Multi-GPU model loading completed
2025-09-20 19:37:13,591 - INFO - Model device allocation:
2025-09-20 19:37:13,591 - INFO -   model.embed_tokens: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.0: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.1: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.2: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.3: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.4: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.5: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.6: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.7: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.8: 0
2025-09-20 19:37:13,591 - INFO -   model.layers.9: 1
2025-09-20 19:37:13,591 - INFO -   model.layers.10: 1
2025-09-20 19:37:13,591 - INFO -   model.layers.11: 1
2025-09-20 19:37:13,591 - INFO -   model.layers.12: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.13: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.14: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.15: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.16: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.17: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.18: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.19: 1
2025-09-20 19:37:13,592 - INFO -   model.layers.20: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.21: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.22: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.23: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.24: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.25: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.26: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.27: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.28: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.29: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.30: 2
2025-09-20 19:37:13,592 - INFO -   model.layers.31: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.32: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.33: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.34: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.35: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.36: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.37: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.38: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.39: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.40: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.41: 3
2025-09-20 19:37:13,592 - INFO -   model.layers.42: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.43: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.44: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.45: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.46: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.47: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.48: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.49: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.50: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.51: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.52: 4
2025-09-20 19:37:13,592 - INFO -   model.layers.53: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.54: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.55: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.56: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.57: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.58: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.59: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.60: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.61: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.62: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.63: 5
2025-09-20 19:37:13,592 - INFO -   model.layers.64: 6
2025-09-20 19:37:13,592 - INFO -   model.layers.65: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.66: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.67: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.68: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.69: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.70: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.71: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.72: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.73: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.74: 6
2025-09-20 19:37:13,593 - INFO -   model.layers.75: 7
2025-09-20 19:37:13,593 - INFO -   model.layers.76: 7
2025-09-20 19:37:13,593 - INFO -   model.layers.77: 7
2025-09-20 19:37:13,593 - INFO -   model.layers.78: 7
2025-09-20 19:37:13,593 - INFO -   model.layers.79: 7
2025-09-20 19:37:13,593 - INFO -   model.norm: 7
2025-09-20 19:37:13,593 - INFO -   model.rotary_emb: 7
2025-09-20 19:37:13,593 - INFO -   lm_head: 7
2025-09-20 19:37:13,593 - INFO - Loading neuron importance data from: ./abl/s8.json
2025-09-20 19:37:13,601 - INFO - Loaded 10000 neurons
2025-09-20 19:37:13,601 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 19:37:13,601 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 19:37:13,601 - INFO - Step size: 1
2025-09-20 19:37:13,602 - INFO - Max magnitude increase: 3.0
2025-09-20 19:37:13,602 - INFO - Using 8 GPUs
2025-09-20 19:37:13,602 - INFO - Computing baseline perplexity
2025-09-20 19:37:14,200 - INFO - Baseline perplexity: 22.9140
2025-09-20 19:37:14,201 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 19:37:14,201 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:37:14,201 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 19:37:14,476 - INFO - Masked perplexity: 24.9976
2025-09-20 19:37:14,476 - INFO - Magnitude increase: 0.0378
2025-09-20 19:37:14,485 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 19:37:14,485 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:37:14,485 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 19:37:14,761 - INFO - Masked perplexity: 29.3805
2025-09-20 19:37:14,761 - INFO - Magnitude increase: 0.1080
2025-09-20 19:37:14,769 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 19:37:14,770 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 19:37:14,770 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 19:37:15,046 - INFO - Masked perplexity: 23759.0293
2025-09-20 19:37:15,046 - INFO - Magnitude increase: 3.0157
2025-09-20 19:37:15,046 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 19:37:15,046 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 19:37:15,046 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 19:37:15,046 - INFO - Total steps: 3
2025-09-20 19:37:15,046 - INFO - Final masked neurons: 3
2025-09-20 19:37:15,046 - INFO - Used 8 GPUs for computation
2025-09-20 19:37:15,046 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 19:37:15,047 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 19:37:15,047 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 19:37:15,047 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 19:37:15,047 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 19:37:15,047 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 19:37:15,047 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 19:38:56,680 - INFO - === Multi-GPU Neuron Activation Difference Analyzer ===
2025-09-20 19:38:56,680 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:38:56,680 - INFO - Input text: Stranger Things, a Netflix sci-fi horror series, follows kids battling supernatural forces in 1980s ...
2025-09-20 19:38:56,681 - INFO - Noise scale: 5.0
2025-09-20 19:38:56,681 - INFO - Number of samples: 100
2025-09-20 19:38:56,681 - INFO - Random seed: 42
2025-09-20 19:38:56,681 - INFO - Device: auto
2025-09-20 19:38:57,380 - INFO - Available GPUs: 8
2025-09-20 19:38:57,381 - INFO - Available GPUs: 8
2025-09-20 19:38:57,381 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 19:38:57,381 - INFO - Transformers version: 4.56.1
2025-09-20 19:38:57,381 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 19:38:57,381 - INFO - CUDA available: True
2025-09-20 19:39:30,645 - INFO - Multi-GPU model loading completed
2025-09-20 19:39:30,646 - INFO - Model device allocation:
2025-09-20 19:39:30,646 - INFO -   model.embed_tokens: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.0: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.1: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.2: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.3: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.4: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.5: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.6: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.7: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.8: 0
2025-09-20 19:39:30,646 - INFO -   model.layers.9: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.10: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.11: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.12: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.13: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.14: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.15: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.16: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.17: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.18: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.19: 1
2025-09-20 19:39:30,646 - INFO -   model.layers.20: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.21: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.22: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.23: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.24: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.25: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.26: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.27: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.28: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.29: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.30: 2
2025-09-20 19:39:30,646 - INFO -   model.layers.31: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.32: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.33: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.34: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.35: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.36: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.37: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.38: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.39: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.40: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.41: 3
2025-09-20 19:39:30,646 - INFO -   model.layers.42: 4
2025-09-20 19:39:30,646 - INFO -   model.layers.43: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.44: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.45: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.46: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.47: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.48: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.49: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.50: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.51: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.52: 4
2025-09-20 19:39:30,647 - INFO -   model.layers.53: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.54: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.55: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.56: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.57: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.58: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.59: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.60: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.61: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.62: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.63: 5
2025-09-20 19:39:30,647 - INFO -   model.layers.64: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.65: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.66: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.67: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.68: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.69: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.70: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.71: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.72: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.73: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.74: 6
2025-09-20 19:39:30,647 - INFO -   model.layers.75: 7
2025-09-20 19:39:30,647 - INFO -   model.layers.76: 7
2025-09-20 19:39:30,647 - INFO -   model.layers.77: 7
2025-09-20 19:39:30,647 - INFO -   model.layers.78: 7
2025-09-20 19:39:30,647 - INFO -   model.layers.79: 7
2025-09-20 19:39:30,647 - INFO -   model.norm: 7
2025-09-20 19:39:30,647 - INFO -   model.rotary_emb: 7
2025-09-20 19:39:30,647 - INFO -   lm_head: 7
2025-09-20 19:39:30,647 - INFO - Starting multi-GPU neuron activation difference analysis
2025-09-20 19:39:30,653 - INFO - Set up hooks for 720 key modules
2025-09-20 19:39:30,665 - INFO - Input text length: 33 tokens
2025-09-20 19:39:30,665 - INFO - Input device: cuda:0
2025-09-20 19:39:30,666 - INFO - Collecting baseline activations across GPUs
2025-09-20 19:39:31,308 - INFO - Collected baseline activations from 720 modules
2025-09-20 19:39:31,308 - INFO - Running noise experiment 1/100
2025-09-20 19:39:31,940 - INFO - Running noise experiment 2/100
2025-09-20 19:39:32,462 - INFO - Running noise experiment 3/100
2025-09-20 19:39:33,010 - INFO - Running noise experiment 4/100
2025-09-20 19:39:33,548 - INFO - Running noise experiment 5/100
2025-09-20 19:39:34,111 - INFO - Running noise experiment 6/100
2025-09-20 19:39:34,661 - INFO - Running noise experiment 7/100
2025-09-20 19:39:35,216 - INFO - Running noise experiment 8/100
2025-09-20 19:39:35,772 - INFO - Running noise experiment 9/100
2025-09-20 19:39:36,335 - INFO - Running noise experiment 10/100
2025-09-20 19:39:36,900 - INFO - Running noise experiment 11/100
2025-09-20 19:39:37,472 - INFO - Running noise experiment 12/100
2025-09-20 19:39:38,010 - INFO - Running noise experiment 13/100
2025-09-20 19:39:38,538 - INFO - Running noise experiment 14/100
2025-09-20 19:39:39,057 - INFO - Running noise experiment 15/100
2025-09-20 19:39:39,611 - INFO - Running noise experiment 16/100
2025-09-20 19:39:40,185 - INFO - Running noise experiment 17/100
2025-09-20 19:39:40,754 - INFO - Running noise experiment 18/100
2025-09-20 19:39:41,329 - INFO - Running noise experiment 19/100
2025-09-20 19:39:41,898 - INFO - Running noise experiment 20/100
2025-09-20 19:39:42,469 - INFO - Running noise experiment 21/100
2025-09-20 19:39:43,132 - INFO - Running noise experiment 22/100
2025-09-20 19:39:43,699 - INFO - Running noise experiment 23/100
2025-09-20 19:39:44,269 - INFO - Running noise experiment 24/100
2025-09-20 19:39:44,837 - INFO - Running noise experiment 25/100
2025-09-20 19:39:45,405 - INFO - Running noise experiment 26/100
2025-09-20 19:39:45,975 - INFO - Running noise experiment 27/100
2025-09-20 19:39:46,545 - INFO - Running noise experiment 28/100
2025-09-20 19:39:47,113 - INFO - Running noise experiment 29/100
2025-09-20 19:39:47,684 - INFO - Running noise experiment 30/100
2025-09-20 19:39:48,250 - INFO - Running noise experiment 31/100
2025-09-20 19:39:48,822 - INFO - Running noise experiment 32/100
2025-09-20 19:39:49,386 - INFO - Running noise experiment 33/100
2025-09-20 19:39:49,953 - INFO - Running noise experiment 34/100
2025-09-20 19:39:50,520 - INFO - Running noise experiment 35/100
2025-09-20 19:39:51,087 - INFO - Running noise experiment 36/100
2025-09-20 19:39:51,650 - INFO - Running noise experiment 37/100
2025-09-20 19:39:52,220 - INFO - Running noise experiment 38/100
2025-09-20 19:39:52,786 - INFO - Running noise experiment 39/100
2025-09-20 19:39:53,357 - INFO - Running noise experiment 40/100
2025-09-20 19:39:53,925 - INFO - Running noise experiment 41/100
2025-09-20 19:39:54,495 - INFO - Running noise experiment 42/100
2025-09-20 19:39:55,066 - INFO - Running noise experiment 43/100
2025-09-20 19:39:55,636 - INFO - Running noise experiment 44/100
2025-09-20 19:39:56,207 - INFO - Running noise experiment 45/100
2025-09-20 19:39:56,778 - INFO - Running noise experiment 46/100
2025-09-20 19:39:57,348 - INFO - Running noise experiment 47/100
2025-09-20 19:39:57,921 - INFO - Running noise experiment 48/100
2025-09-20 19:39:58,494 - INFO - Running noise experiment 49/100
2025-09-20 19:39:59,064 - INFO - Running noise experiment 50/100
2025-09-20 19:39:59,636 - INFO - Running noise experiment 51/100
2025-09-20 19:40:00,212 - INFO - Running noise experiment 52/100
2025-09-20 19:40:00,783 - INFO - Running noise experiment 53/100
2025-09-20 19:40:01,355 - INFO - Running noise experiment 54/100
2025-09-20 19:40:01,929 - INFO - Running noise experiment 55/100
2025-09-20 19:40:02,499 - INFO - Running noise experiment 56/100
2025-09-20 19:40:03,066 - INFO - Running noise experiment 57/100
2025-09-20 19:40:03,629 - INFO - Running noise experiment 58/100
2025-09-20 19:40:04,185 - INFO - Running noise experiment 59/100
2025-09-20 19:40:04,738 - INFO - Running noise experiment 60/100
2025-09-20 19:40:05,305 - INFO - Running noise experiment 61/100
2025-09-20 19:40:05,857 - INFO - Running noise experiment 62/100
2025-09-20 19:40:06,416 - INFO - Running noise experiment 63/100
2025-09-20 19:40:06,973 - INFO - Running noise experiment 64/100
2025-09-20 19:40:07,534 - INFO - Running noise experiment 65/100
2025-09-20 19:40:08,087 - INFO - Running noise experiment 66/100
2025-09-20 19:40:08,645 - INFO - Running noise experiment 67/100
2025-09-20 19:40:09,203 - INFO - Running noise experiment 68/100
2025-09-20 19:40:09,762 - INFO - Running noise experiment 69/100
2025-09-20 19:40:10,329 - INFO - Running noise experiment 70/100
2025-09-20 19:40:10,886 - INFO - Running noise experiment 71/100
2025-09-20 19:40:11,443 - INFO - Running noise experiment 72/100
2025-09-20 19:40:11,997 - INFO - Running noise experiment 73/100
2025-09-20 19:40:12,556 - INFO - Running noise experiment 74/100
2025-09-20 19:40:13,226 - INFO - Running noise experiment 75/100
2025-09-20 19:40:13,779 - INFO - Running noise experiment 76/100
2025-09-20 19:40:14,331 - INFO - Running noise experiment 77/100
2025-09-20 19:40:14,883 - INFO - Running noise experiment 78/100
2025-09-20 19:40:15,438 - INFO - Running noise experiment 79/100
2025-09-20 19:40:15,991 - INFO - Running noise experiment 80/100
2025-09-20 19:40:16,541 - INFO - Running noise experiment 81/100
2025-09-20 19:40:17,095 - INFO - Running noise experiment 82/100
2025-09-20 19:40:17,646 - INFO - Running noise experiment 83/100
2025-09-20 19:40:18,199 - INFO - Running noise experiment 84/100
2025-09-20 19:40:18,750 - INFO - Running noise experiment 85/100
2025-09-20 19:40:19,306 - INFO - Running noise experiment 86/100
2025-09-20 19:40:19,854 - INFO - Running noise experiment 87/100
2025-09-20 19:40:20,412 - INFO - Running noise experiment 88/100
2025-09-20 19:40:20,962 - INFO - Running noise experiment 89/100
2025-09-20 19:40:21,515 - INFO - Running noise experiment 90/100
2025-09-20 19:40:22,071 - INFO - Running noise experiment 91/100
2025-09-20 19:40:22,625 - INFO - Running noise experiment 92/100
2025-09-20 19:40:23,175 - INFO - Running noise experiment 93/100
2025-09-20 19:40:23,728 - INFO - Running noise experiment 94/100
2025-09-20 19:40:24,275 - INFO - Running noise experiment 95/100
2025-09-20 19:40:24,831 - INFO - Running noise experiment 96/100
2025-09-20 19:40:25,385 - INFO - Running noise experiment 97/100
2025-09-20 19:40:25,941 - INFO - Running noise experiment 98/100
2025-09-20 19:40:26,490 - INFO - Running noise experiment 99/100
2025-09-20 19:40:27,039 - INFO - Running noise experiment 100/100
2025-09-20 19:40:27,596 - INFO - Successfully collected activation differences from 720 modules
2025-09-20 19:40:27,596 - INFO - Computing neuron importance
2025-09-20 20:00:40,953 - INFO - Found 318996478 meaningful neurons
2025-09-20 20:00:40,953 - INFO - Sorting neurons by activation difference
2025-09-20 20:02:09,321 - INFO - Saving results to ./abl/s10.json
2025-09-20 20:02:09,385 - INFO - Multi-GPU analysis completed
2025-09-20 20:02:09,385 - INFO - Total discovered neurons: 318996478
2025-09-20 20:02:09,385 - INFO - Used 8 GPUs for computation
2025-09-20 20:02:09,385 - INFO - Top 10 neurons with highest activation difference:
2025-09-20 20:02:09,385 - INFO - Rank 1: Layer model.layers.3.mlp.down_proj, Activation diff: 471.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 20:02:09,385 - INFO - Rank 2: Layer model.layers.3.mlp.down_proj, Activation diff: 420.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 20:02:09,385 - INFO - Rank 3: Layer model.layers.3.mlp.down_proj, Activation diff: 392.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 20:02:09,385 - INFO - Rank 4: Layer model.layers.79.mlp.down_proj, Activation diff: 390.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 20:02:09,385 - INFO - Rank 5: Layer model.layers.79.mlp.down_proj, Activation diff: 342.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 20:02:09,385 - INFO - Rank 6: Layer model.layers.79.mlp.down_proj, Activation diff: 336.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 20:02:09,385 - INFO - Rank 7: Layer model.layers.0.mlp.down_proj, Activation diff: 62.718750, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 20:02:09,385 - INFO - Rank 8: Layer model.layers.79.mlp.down_proj, Activation diff: 54.375000, batch_idx: 0, seq_idx: 8, hidden_idx: 5114
2025-09-20 20:02:09,385 - INFO - Rank 9: Layer model.layers.79.mlp.down_proj, Activation diff: 51.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 775
2025-09-20 20:02:09,385 - INFO - Rank 10: Layer model.layers.79.mlp.down_proj, Activation diff: 48.906250, batch_idx: 0, seq_idx: 30, hidden_idx: 5114
2025-09-20 20:02:11,052 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 20:02:11,056 - INFO - Discovered 318996478 neurons
2025-09-20 20:02:11,061 - INFO - Results saved to: ./abl/s10.json
2025-09-20 20:02:11,065 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 20:41:07,430 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 20:41:07,430 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 20:41:07,430 - INFO - Neuron file: ./abl/s10.json
2025-09-20 20:41:07,430 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 20:41:07,430 - INFO - Step size: 1
2025-09-20 20:41:07,430 - INFO - Max magnitude increase: 3.0
2025-09-20 20:41:07,430 - INFO - Random seed: 42
2025-09-20 20:41:07,430 - INFO - Device: auto
2025-09-20 20:41:08,114 - INFO - Available GPUs: 8
2025-09-20 20:41:08,115 - INFO - Available GPUs: 8
2025-09-20 20:41:08,115 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 20:41:08,115 - INFO - Transformers version: 4.56.1
2025-09-20 20:41:08,115 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 20:41:08,115 - INFO - CUDA available: True
2025-09-20 20:41:40,557 - INFO - Multi-GPU model loading completed
2025-09-20 20:41:40,557 - INFO - Model device allocation:
2025-09-20 20:41:40,557 - INFO -   model.embed_tokens: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.0: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.1: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.2: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.3: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.4: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.5: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.6: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.7: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.8: 0
2025-09-20 20:41:40,557 - INFO -   model.layers.9: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.10: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.11: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.12: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.13: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.14: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.15: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.16: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.17: 1
2025-09-20 20:41:40,557 - INFO -   model.layers.18: 1
2025-09-20 20:41:40,558 - INFO -   model.layers.19: 1
2025-09-20 20:41:40,558 - INFO -   model.layers.20: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.21: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.22: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.23: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.24: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.25: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.26: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.27: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.28: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.29: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.30: 2
2025-09-20 20:41:40,558 - INFO -   model.layers.31: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.32: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.33: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.34: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.35: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.36: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.37: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.38: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.39: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.40: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.41: 3
2025-09-20 20:41:40,558 - INFO -   model.layers.42: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.43: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.44: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.45: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.46: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.47: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.48: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.49: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.50: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.51: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.52: 4
2025-09-20 20:41:40,558 - INFO -   model.layers.53: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.54: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.55: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.56: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.57: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.58: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.59: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.60: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.61: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.62: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.63: 5
2025-09-20 20:41:40,558 - INFO -   model.layers.64: 6
2025-09-20 20:41:40,558 - INFO -   model.layers.65: 6
2025-09-20 20:41:40,558 - INFO -   model.layers.66: 6
2025-09-20 20:41:40,558 - INFO -   model.layers.67: 6
2025-09-20 20:41:40,558 - INFO -   model.layers.68: 6
2025-09-20 20:41:40,558 - INFO -   model.layers.69: 6
2025-09-20 20:41:40,559 - INFO -   model.layers.70: 6
2025-09-20 20:41:40,559 - INFO -   model.layers.71: 6
2025-09-20 20:41:40,559 - INFO -   model.layers.72: 6
2025-09-20 20:41:40,559 - INFO -   model.layers.73: 6
2025-09-20 20:41:40,559 - INFO -   model.layers.74: 6
2025-09-20 20:41:40,559 - INFO -   model.layers.75: 7
2025-09-20 20:41:40,559 - INFO -   model.layers.76: 7
2025-09-20 20:41:40,559 - INFO -   model.layers.77: 7
2025-09-20 20:41:40,559 - INFO -   model.layers.78: 7
2025-09-20 20:41:40,559 - INFO -   model.layers.79: 7
2025-09-20 20:41:40,559 - INFO -   model.norm: 7
2025-09-20 20:41:40,559 - INFO -   model.rotary_emb: 7
2025-09-20 20:41:40,559 - INFO -   lm_head: 7
2025-09-20 20:41:40,559 - INFO - Loading neuron importance data from: ./abl/s10.json
2025-09-20 20:41:40,568 - INFO - Loaded 10000 neurons
2025-09-20 20:41:40,568 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 20:41:40,568 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 20:41:40,568 - INFO - Step size: 1
2025-09-20 20:41:40,568 - INFO - Max magnitude increase: 3.0
2025-09-20 20:41:40,568 - INFO - Using 8 GPUs
2025-09-20 20:41:40,568 - INFO - Computing baseline perplexity
2025-09-20 20:41:41,258 - INFO - Baseline perplexity: 22.9140
2025-09-20 20:41:41,259 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 20:41:41,259 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 20:41:41,259 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 20:41:41,534 - INFO - Masked perplexity: 24.9976
2025-09-20 20:41:41,535 - INFO - Magnitude increase: 0.0378
2025-09-20 20:41:41,543 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 20:41:41,543 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 20:41:41,543 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 20:41:41,819 - INFO - Masked perplexity: 29.3805
2025-09-20 20:41:41,819 - INFO - Magnitude increase: 0.1080
2025-09-20 20:41:41,828 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 20:41:41,828 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 20:41:41,828 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 20:41:42,104 - INFO - Masked perplexity: 23759.0293
2025-09-20 20:41:42,104 - INFO - Magnitude increase: 3.0157
2025-09-20 20:41:42,104 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 20:41:42,104 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 20:41:42,105 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 20:41:42,105 - INFO - Total steps: 3
2025-09-20 20:41:42,105 - INFO - Final masked neurons: 3
2025-09-20 20:41:42,105 - INFO - Used 8 GPUs for computation
2025-09-20 20:41:42,105 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 20:41:42,105 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 20:41:42,105 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 20:41:42,105 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 20:41:42,105 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 20:41:42,105 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 20:41:42,105 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 20:43:03,069 - INFO - === Multi-GPU Neuron Activation Difference Analyzer ===
2025-09-20 20:43:03,070 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 20:43:03,070 - INFO - Input text: Stranger Things, eine Netflix-Sci-Fi-Horrorserie, folgt Kindern, die in den 1980er Jahren in Indiana...
2025-09-20 20:43:03,070 - INFO - Noise scale: 5.0
2025-09-20 20:43:03,070 - INFO - Number of samples: 100
2025-09-20 20:43:03,070 - INFO - Random seed: 42
2025-09-20 20:43:03,070 - INFO - Device: auto
2025-09-20 20:43:03,754 - INFO - Available GPUs: 8
2025-09-20 20:43:03,755 - INFO - Available GPUs: 8
2025-09-20 20:43:03,755 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 20:43:03,755 - INFO - Transformers version: 4.56.1
2025-09-20 20:43:03,755 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 20:43:03,755 - INFO - CUDA available: True
2025-09-20 20:43:36,338 - INFO - Multi-GPU model loading completed
2025-09-20 20:43:36,338 - INFO - Model device allocation:
2025-09-20 20:43:36,338 - INFO -   model.embed_tokens: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.0: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.1: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.2: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.3: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.4: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.5: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.6: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.7: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.8: 0
2025-09-20 20:43:36,338 - INFO -   model.layers.9: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.10: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.11: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.12: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.13: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.14: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.15: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.16: 1
2025-09-20 20:43:36,338 - INFO -   model.layers.17: 1
2025-09-20 20:43:36,339 - INFO -   model.layers.18: 1
2025-09-20 20:43:36,339 - INFO -   model.layers.19: 1
2025-09-20 20:43:36,339 - INFO -   model.layers.20: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.21: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.22: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.23: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.24: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.25: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.26: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.27: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.28: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.29: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.30: 2
2025-09-20 20:43:36,339 - INFO -   model.layers.31: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.32: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.33: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.34: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.35: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.36: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.37: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.38: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.39: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.40: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.41: 3
2025-09-20 20:43:36,339 - INFO -   model.layers.42: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.43: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.44: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.45: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.46: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.47: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.48: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.49: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.50: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.51: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.52: 4
2025-09-20 20:43:36,339 - INFO -   model.layers.53: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.54: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.55: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.56: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.57: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.58: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.59: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.60: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.61: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.62: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.63: 5
2025-09-20 20:43:36,339 - INFO -   model.layers.64: 6
2025-09-20 20:43:36,339 - INFO -   model.layers.65: 6
2025-09-20 20:43:36,339 - INFO -   model.layers.66: 6
2025-09-20 20:43:36,339 - INFO -   model.layers.67: 6
2025-09-20 20:43:36,339 - INFO -   model.layers.68: 6
2025-09-20 20:43:36,339 - INFO -   model.layers.69: 6
2025-09-20 20:43:36,339 - INFO -   model.layers.70: 6
2025-09-20 20:43:36,340 - INFO -   model.layers.71: 6
2025-09-20 20:43:36,340 - INFO -   model.layers.72: 6
2025-09-20 20:43:36,340 - INFO -   model.layers.73: 6
2025-09-20 20:43:36,340 - INFO -   model.layers.74: 6
2025-09-20 20:43:36,340 - INFO -   model.layers.75: 7
2025-09-20 20:43:36,340 - INFO -   model.layers.76: 7
2025-09-20 20:43:36,340 - INFO -   model.layers.77: 7
2025-09-20 20:43:36,340 - INFO -   model.layers.78: 7
2025-09-20 20:43:36,340 - INFO -   model.layers.79: 7
2025-09-20 20:43:36,340 - INFO -   model.norm: 7
2025-09-20 20:43:36,340 - INFO -   model.rotary_emb: 7
2025-09-20 20:43:36,340 - INFO -   lm_head: 7
2025-09-20 20:43:36,340 - INFO - Starting multi-GPU neuron activation difference analysis
2025-09-20 20:43:36,345 - INFO - Set up hooks for 720 key modules
2025-09-20 20:43:36,358 - INFO - Input text length: 59 tokens
2025-09-20 20:43:36,358 - INFO - Input device: cuda:0
2025-09-20 20:43:36,358 - INFO - Collecting baseline activations across GPUs
2025-09-20 20:43:37,096 - INFO - Collected baseline activations from 720 modules
2025-09-20 20:43:37,096 - INFO - Running noise experiment 1/100
2025-09-20 20:43:37,942 - INFO - Running noise experiment 2/100
2025-09-20 20:43:38,616 - INFO - Running noise experiment 3/100
2025-09-20 20:43:39,277 - INFO - Running noise experiment 4/100
2025-09-20 20:43:39,964 - INFO - Running noise experiment 5/100
2025-09-20 20:43:40,689 - INFO - Running noise experiment 6/100
2025-09-20 20:43:41,373 - INFO - Running noise experiment 7/100
2025-09-20 20:43:42,118 - INFO - Running noise experiment 8/100
2025-09-20 20:43:42,797 - INFO - Running noise experiment 9/100
2025-09-20 20:43:43,464 - INFO - Running noise experiment 10/100
2025-09-20 20:43:44,131 - INFO - Running noise experiment 11/100
2025-09-20 20:43:44,868 - INFO - Running noise experiment 12/100
2025-09-20 20:43:45,620 - INFO - Running noise experiment 13/100
2025-09-20 20:43:46,380 - INFO - Running noise experiment 14/100
2025-09-20 20:43:47,131 - INFO - Running noise experiment 15/100
2025-09-20 20:43:47,885 - INFO - Running noise experiment 16/100
2025-09-20 20:43:48,640 - INFO - Running noise experiment 17/100
2025-09-20 20:43:49,395 - INFO - Running noise experiment 18/100
2025-09-20 20:43:50,176 - INFO - Running noise experiment 19/100
2025-09-20 20:43:50,936 - INFO - Running noise experiment 20/100
2025-09-20 20:43:51,685 - INFO - Running noise experiment 21/100
2025-09-20 20:43:52,524 - INFO - Running noise experiment 22/100
2025-09-20 20:43:53,268 - INFO - Running noise experiment 23/100
2025-09-20 20:43:53,997 - INFO - Running noise experiment 24/100
2025-09-20 20:43:54,740 - INFO - Running noise experiment 25/100
2025-09-20 20:43:55,486 - INFO - Running noise experiment 26/100
2025-09-20 20:43:56,228 - INFO - Running noise experiment 27/100
2025-09-20 20:43:56,979 - INFO - Running noise experiment 28/100
2025-09-20 20:43:57,721 - INFO - Running noise experiment 29/100
2025-09-20 20:43:58,460 - INFO - Running noise experiment 30/100
2025-09-20 20:43:59,194 - INFO - Running noise experiment 31/100
2025-09-20 20:43:59,939 - INFO - Running noise experiment 32/100
2025-09-20 20:44:00,676 - INFO - Running noise experiment 33/100
2025-09-20 20:44:01,421 - INFO - Running noise experiment 34/100
2025-09-20 20:44:02,155 - INFO - Running noise experiment 35/100
2025-09-20 20:44:02,899 - INFO - Running noise experiment 36/100
2025-09-20 20:44:03,644 - INFO - Running noise experiment 37/100
2025-09-20 20:44:04,377 - INFO - Running noise experiment 38/100
2025-09-20 20:44:05,128 - INFO - Running noise experiment 39/100
2025-09-20 20:44:05,864 - INFO - Running noise experiment 40/100
2025-09-20 20:44:06,614 - INFO - Running noise experiment 41/100
2025-09-20 20:44:07,350 - INFO - Running noise experiment 42/100
2025-09-20 20:44:08,085 - INFO - Running noise experiment 43/100
2025-09-20 20:44:08,829 - INFO - Running noise experiment 44/100
2025-09-20 20:44:09,576 - INFO - Running noise experiment 45/100
2025-09-20 20:44:10,328 - INFO - Running noise experiment 46/100
2025-09-20 20:44:11,052 - INFO - Running noise experiment 47/100
2025-09-20 20:44:11,790 - INFO - Running noise experiment 48/100
2025-09-20 20:44:12,523 - INFO - Running noise experiment 49/100
2025-09-20 20:44:13,252 - INFO - Running noise experiment 50/100
2025-09-20 20:44:13,987 - INFO - Running noise experiment 51/100
2025-09-20 20:44:14,723 - INFO - Running noise experiment 52/100
2025-09-20 20:44:15,466 - INFO - Running noise experiment 53/100
2025-09-20 20:44:16,201 - INFO - Running noise experiment 54/100
2025-09-20 20:44:16,936 - INFO - Running noise experiment 55/100
2025-09-20 20:44:17,668 - INFO - Running noise experiment 56/100
2025-09-20 20:44:18,399 - INFO - Running noise experiment 57/100
2025-09-20 20:44:19,126 - INFO - Running noise experiment 58/100
2025-09-20 20:44:19,864 - INFO - Running noise experiment 59/100
2025-09-20 20:44:20,606 - INFO - Running noise experiment 60/100
2025-09-20 20:44:21,333 - INFO - Running noise experiment 61/100
2025-09-20 20:44:22,073 - INFO - Running noise experiment 62/100
2025-09-20 20:44:22,803 - INFO - Running noise experiment 63/100
2025-09-20 20:44:23,535 - INFO - Running noise experiment 64/100
2025-09-20 20:44:24,266 - INFO - Running noise experiment 65/100
2025-09-20 20:44:25,002 - INFO - Running noise experiment 66/100
2025-09-20 20:44:25,727 - INFO - Running noise experiment 67/100
2025-09-20 20:44:26,455 - INFO - Running noise experiment 68/100
2025-09-20 20:44:27,182 - INFO - Running noise experiment 69/100
2025-09-20 20:44:27,919 - INFO - Running noise experiment 70/100
2025-09-20 20:44:28,651 - INFO - Running noise experiment 71/100
2025-09-20 20:44:29,387 - INFO - Running noise experiment 72/100
2025-09-20 20:44:30,121 - INFO - Running noise experiment 73/100
2025-09-20 20:44:30,857 - INFO - Running noise experiment 74/100
2025-09-20 20:44:31,693 - INFO - Running noise experiment 75/100
2025-09-20 20:44:32,431 - INFO - Running noise experiment 76/100
2025-09-20 20:44:33,161 - INFO - Running noise experiment 77/100
2025-09-20 20:44:33,889 - INFO - Running noise experiment 78/100
2025-09-20 20:44:34,626 - INFO - Running noise experiment 79/100
2025-09-20 20:44:35,370 - INFO - Running noise experiment 80/100
2025-09-20 20:44:36,106 - INFO - Running noise experiment 81/100
2025-09-20 20:44:36,842 - INFO - Running noise experiment 82/100
2025-09-20 20:44:37,579 - INFO - Running noise experiment 83/100
2025-09-20 20:44:38,320 - INFO - Running noise experiment 84/100
2025-09-20 20:44:39,045 - INFO - Running noise experiment 85/100
2025-09-20 20:44:39,786 - INFO - Running noise experiment 86/100
2025-09-20 20:44:40,521 - INFO - Running noise experiment 87/100
2025-09-20 20:44:41,252 - INFO - Running noise experiment 88/100
2025-09-20 20:44:41,987 - INFO - Running noise experiment 89/100
2025-09-20 20:44:42,722 - INFO - Running noise experiment 90/100
2025-09-20 20:44:43,453 - INFO - Running noise experiment 91/100
2025-09-20 20:44:44,192 - INFO - Running noise experiment 92/100
2025-09-20 20:44:44,920 - INFO - Running noise experiment 93/100
2025-09-20 20:44:45,656 - INFO - Running noise experiment 94/100
2025-09-20 20:44:46,381 - INFO - Running noise experiment 95/100
2025-09-20 20:44:47,112 - INFO - Running noise experiment 96/100
2025-09-20 20:44:47,839 - INFO - Running noise experiment 97/100
2025-09-20 20:44:48,560 - INFO - Running noise experiment 98/100
2025-09-20 20:44:49,287 - INFO - Running noise experiment 99/100
2025-09-20 20:44:50,023 - INFO - Running noise experiment 100/100
2025-09-20 20:44:50,761 - INFO - Successfully collected activation differences from 720 modules
2025-09-20 20:44:50,761 - INFO - Computing neuron importance
2025-09-20 21:20:34,060 - INFO - Found 570327033 meaningful neurons
2025-09-20 21:20:34,060 - INFO - Sorting neurons by activation difference
2025-09-20 21:23:14,375 - INFO - Saving results to ./abl/s13.json
2025-09-20 21:23:14,439 - INFO - Multi-GPU analysis completed
2025-09-20 21:23:14,439 - INFO - Total discovered neurons: 570327033
2025-09-20 21:23:14,439 - INFO - Used 8 GPUs for computation
2025-09-20 21:23:14,439 - INFO - Top 10 neurons with highest activation difference:
2025-09-20 21:23:14,439 - INFO - Rank 1: Layer model.layers.3.mlp.down_proj, Activation diff: 471.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 21:23:14,439 - INFO - Rank 2: Layer model.layers.3.mlp.down_proj, Activation diff: 420.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 21:23:14,439 - INFO - Rank 3: Layer model.layers.3.mlp.down_proj, Activation diff: 392.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 21:23:14,439 - INFO - Rank 4: Layer model.layers.79.mlp.down_proj, Activation diff: 390.500000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 21:23:14,439 - INFO - Rank 5: Layer model.layers.79.mlp.down_proj, Activation diff: 343.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 21:23:14,439 - INFO - Rank 6: Layer model.layers.79.mlp.down_proj, Activation diff: 336.500000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 21:23:14,439 - INFO - Rank 7: Layer model.layers.0.mlp.down_proj, Activation diff: 62.687500, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 21:23:14,439 - INFO - Rank 8: Layer model.layers.79.mlp.down_proj, Activation diff: 51.281250, batch_idx: 0, seq_idx: 0, hidden_idx: 775
2025-09-20 21:23:14,439 - INFO - Rank 9: Layer model.layers.78.mlp.down_proj, Activation diff: 34.531250, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 21:23:14,439 - INFO - Rank 10: Layer model.layers.78.mlp.down_proj, Activation diff: 34.406250, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 21:23:17,379 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 21:23:17,382 - INFO - Discovered 570327033 neurons
2025-09-20 21:23:17,389 - INFO - Results saved to: ./abl/s13.json
2025-09-20 21:23:17,402 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 21:32:32,264 - INFO - === Multi-GPU Neuron Activation Difference Analyzer ===
2025-09-20 21:32:32,264 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 21:32:32,264 - INFO - Input text: ä¸€å®¶é¢†å…ˆç§‘æŠ€å…¬å¸ä»Šæ—¥å®£å¸ƒæŽ¨å‡ºæ–°åž‹AIæ¨¡åž‹ï¼Œæ‰¿è¯ºæ›´å¿«çš„å¤„ç†é€Ÿåº¦å’Œæ›´é«˜çš„å‡†ç¡®æ€§ã€‚ä¸“å®¶é¢„æµ‹å°†å¯¹å…¨çƒäº§ä¸šäº§ç”Ÿé‡å¤§å½±å“ã€‚...
2025-09-20 21:32:32,264 - INFO - Noise scale: 5.0
2025-09-20 21:32:32,264 - INFO - Number of samples: 100
2025-09-20 21:32:32,264 - INFO - Random seed: 42
2025-09-20 21:32:32,264 - INFO - Device: auto
2025-09-20 21:32:32,955 - INFO - Available GPUs: 8
2025-09-20 21:32:32,956 - INFO - Available GPUs: 8
2025-09-20 21:32:32,956 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 21:32:32,956 - INFO - Transformers version: 4.56.1
2025-09-20 21:32:32,956 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 21:32:32,956 - INFO - CUDA available: True
2025-09-20 21:33:07,616 - INFO - Multi-GPU model loading completed
2025-09-20 21:33:07,616 - INFO - Model device allocation:
2025-09-20 21:33:07,616 - INFO -   model.embed_tokens: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.0: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.1: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.2: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.3: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.4: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.5: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.6: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.7: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.8: 0
2025-09-20 21:33:07,616 - INFO -   model.layers.9: 1
2025-09-20 21:33:07,616 - INFO -   model.layers.10: 1
2025-09-20 21:33:07,616 - INFO -   model.layers.11: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.12: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.13: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.14: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.15: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.16: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.17: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.18: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.19: 1
2025-09-20 21:33:07,617 - INFO -   model.layers.20: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.21: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.22: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.23: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.24: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.25: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.26: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.27: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.28: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.29: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.30: 2
2025-09-20 21:33:07,617 - INFO -   model.layers.31: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.32: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.33: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.34: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.35: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.36: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.37: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.38: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.39: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.40: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.41: 3
2025-09-20 21:33:07,617 - INFO -   model.layers.42: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.43: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.44: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.45: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.46: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.47: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.48: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.49: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.50: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.51: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.52: 4
2025-09-20 21:33:07,617 - INFO -   model.layers.53: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.54: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.55: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.56: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.57: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.58: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.59: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.60: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.61: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.62: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.63: 5
2025-09-20 21:33:07,617 - INFO -   model.layers.64: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.65: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.66: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.67: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.68: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.69: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.70: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.71: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.72: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.73: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.74: 6
2025-09-20 21:33:07,618 - INFO -   model.layers.75: 7
2025-09-20 21:33:07,618 - INFO -   model.layers.76: 7
2025-09-20 21:33:07,618 - INFO -   model.layers.77: 7
2025-09-20 21:33:07,618 - INFO -   model.layers.78: 7
2025-09-20 21:33:07,618 - INFO -   model.layers.79: 7
2025-09-20 21:33:07,618 - INFO -   model.norm: 7
2025-09-20 21:33:07,618 - INFO -   model.rotary_emb: 7
2025-09-20 21:33:07,618 - INFO -   lm_head: 7
2025-09-20 21:33:07,618 - INFO - Starting multi-GPU neuron activation difference analysis
2025-09-20 21:33:07,624 - INFO - Set up hooks for 720 key modules
2025-09-20 21:33:07,636 - INFO - Input text length: 44 tokens
2025-09-20 21:33:07,637 - INFO - Input device: cuda:0
2025-09-20 21:33:07,637 - INFO - Collecting baseline activations across GPUs
2025-09-20 21:33:08,427 - INFO - Collected baseline activations from 720 modules
2025-09-20 21:33:08,427 - INFO - Running noise experiment 1/100
2025-09-20 21:33:08,898 - INFO - Running noise experiment 2/100
2025-09-20 21:33:09,497 - INFO - Running noise experiment 3/100
2025-09-20 21:33:10,161 - INFO - Running noise experiment 4/100
2025-09-20 21:33:10,811 - INFO - Running noise experiment 5/100
2025-09-20 21:33:11,462 - INFO - Running noise experiment 6/100
2025-09-20 21:33:12,119 - INFO - Running noise experiment 7/100
2025-09-20 21:33:12,747 - INFO - Running noise experiment 8/100
2025-09-20 21:33:13,416 - INFO - Running noise experiment 9/100
2025-09-20 21:33:14,043 - INFO - Running noise experiment 10/100
2025-09-20 21:33:14,657 - INFO - Running noise experiment 11/100
2025-09-20 21:33:15,258 - INFO - Running noise experiment 12/100
2025-09-20 21:33:15,884 - INFO - Running noise experiment 13/100
2025-09-20 21:33:16,528 - INFO - Running noise experiment 14/100
2025-09-20 21:33:17,181 - INFO - Running noise experiment 15/100
2025-09-20 21:33:17,835 - INFO - Running noise experiment 16/100
2025-09-20 21:33:18,488 - INFO - Running noise experiment 17/100
2025-09-20 21:33:19,145 - INFO - Running noise experiment 18/100
2025-09-20 21:33:19,800 - INFO - Running noise experiment 19/100
2025-09-20 21:33:20,462 - INFO - Running noise experiment 20/100
2025-09-20 21:33:21,124 - INFO - Running noise experiment 21/100
2025-09-20 21:33:21,882 - INFO - Running noise experiment 22/100
2025-09-20 21:33:22,539 - INFO - Running noise experiment 23/100
2025-09-20 21:33:23,191 - INFO - Running noise experiment 24/100
2025-09-20 21:33:23,848 - INFO - Running noise experiment 25/100
2025-09-20 21:33:24,504 - INFO - Running noise experiment 26/100
2025-09-20 21:33:25,204 - INFO - Running noise experiment 27/100
2025-09-20 21:33:25,856 - INFO - Running noise experiment 28/100
2025-09-20 21:33:26,517 - INFO - Running noise experiment 29/100
2025-09-20 21:33:27,174 - INFO - Running noise experiment 30/100
2025-09-20 21:33:27,826 - INFO - Running noise experiment 31/100
2025-09-20 21:33:28,480 - INFO - Running noise experiment 32/100
2025-09-20 21:33:29,131 - INFO - Running noise experiment 33/100
2025-09-20 21:33:29,781 - INFO - Running noise experiment 34/100
2025-09-20 21:33:30,440 - INFO - Running noise experiment 35/100
2025-09-20 21:33:31,100 - INFO - Running noise experiment 36/100
2025-09-20 21:33:31,759 - INFO - Running noise experiment 37/100
2025-09-20 21:33:32,411 - INFO - Running noise experiment 38/100
2025-09-20 21:33:33,065 - INFO - Running noise experiment 39/100
2025-09-20 21:33:33,724 - INFO - Running noise experiment 40/100
2025-09-20 21:33:34,380 - INFO - Running noise experiment 41/100
2025-09-20 21:33:35,040 - INFO - Running noise experiment 42/100
2025-09-20 21:33:35,687 - INFO - Running noise experiment 43/100
2025-09-20 21:33:36,327 - INFO - Running noise experiment 44/100
2025-09-20 21:33:36,965 - INFO - Running noise experiment 45/100
2025-09-20 21:33:37,590 - INFO - Running noise experiment 46/100
2025-09-20 21:33:38,218 - INFO - Running noise experiment 47/100
2025-09-20 21:33:38,856 - INFO - Running noise experiment 48/100
2025-09-20 21:33:39,482 - INFO - Running noise experiment 49/100
2025-09-20 21:33:40,118 - INFO - Running noise experiment 50/100
2025-09-20 21:33:40,754 - INFO - Running noise experiment 51/100
2025-09-20 21:33:41,383 - INFO - Running noise experiment 52/100
2025-09-20 21:33:42,010 - INFO - Running noise experiment 53/100
2025-09-20 21:33:42,641 - INFO - Running noise experiment 54/100
2025-09-20 21:33:43,272 - INFO - Running noise experiment 55/100
2025-09-20 21:33:43,903 - INFO - Running noise experiment 56/100
2025-09-20 21:33:44,521 - INFO - Running noise experiment 57/100
2025-09-20 21:33:45,167 - INFO - Running noise experiment 58/100
2025-09-20 21:33:45,795 - INFO - Running noise experiment 59/100
2025-09-20 21:33:46,427 - INFO - Running noise experiment 60/100
2025-09-20 21:33:47,048 - INFO - Running noise experiment 61/100
2025-09-20 21:33:47,678 - INFO - Running noise experiment 62/100
2025-09-20 21:33:48,301 - INFO - Running noise experiment 63/100
2025-09-20 21:33:48,930 - INFO - Running noise experiment 64/100
2025-09-20 21:33:49,558 - INFO - Running noise experiment 65/100
2025-09-20 21:33:50,194 - INFO - Running noise experiment 66/100
2025-09-20 21:33:50,815 - INFO - Running noise experiment 67/100
2025-09-20 21:33:51,442 - INFO - Running noise experiment 68/100
2025-09-20 21:33:52,071 - INFO - Running noise experiment 69/100
2025-09-20 21:33:52,699 - INFO - Running noise experiment 70/100
2025-09-20 21:33:53,331 - INFO - Running noise experiment 71/100
2025-09-20 21:33:53,962 - INFO - Running noise experiment 72/100
2025-09-20 21:33:54,595 - INFO - Running noise experiment 73/100
2025-09-20 21:33:55,226 - INFO - Running noise experiment 74/100
2025-09-20 21:33:55,969 - INFO - Running noise experiment 75/100
2025-09-20 21:33:56,591 - INFO - Running noise experiment 76/100
2025-09-20 21:33:57,224 - INFO - Running noise experiment 77/100
2025-09-20 21:33:57,851 - INFO - Running noise experiment 78/100
2025-09-20 21:33:58,482 - INFO - Running noise experiment 79/100
2025-09-20 21:33:59,110 - INFO - Running noise experiment 80/100
2025-09-20 21:33:59,739 - INFO - Running noise experiment 81/100
2025-09-20 21:34:00,386 - INFO - Running noise experiment 82/100
2025-09-20 21:34:01,010 - INFO - Running noise experiment 83/100
2025-09-20 21:34:01,639 - INFO - Running noise experiment 84/100
2025-09-20 21:34:02,267 - INFO - Running noise experiment 85/100
2025-09-20 21:34:02,902 - INFO - Running noise experiment 86/100
2025-09-20 21:34:03,540 - INFO - Running noise experiment 87/100
2025-09-20 21:34:04,173 - INFO - Running noise experiment 88/100
2025-09-20 21:34:04,809 - INFO - Running noise experiment 89/100
2025-09-20 21:34:05,452 - INFO - Running noise experiment 90/100
2025-09-20 21:34:06,082 - INFO - Running noise experiment 91/100
2025-09-20 21:34:06,713 - INFO - Running noise experiment 92/100
2025-09-20 21:34:07,345 - INFO - Running noise experiment 93/100
2025-09-20 21:34:07,977 - INFO - Running noise experiment 94/100
2025-09-20 21:34:08,610 - INFO - Running noise experiment 95/100
2025-09-20 21:34:09,233 - INFO - Running noise experiment 96/100
2025-09-20 21:34:09,864 - INFO - Running noise experiment 97/100
2025-09-20 21:34:10,497 - INFO - Running noise experiment 98/100
2025-09-20 21:34:11,127 - INFO - Running noise experiment 99/100
2025-09-20 21:34:11,755 - INFO - Running noise experiment 100/100
2025-09-20 21:34:12,386 - INFO - Successfully collected activation differences from 720 modules
2025-09-20 21:34:12,386 - INFO - Computing neuron importance
2025-09-20 22:01:19,190 - INFO - Found 425328635 meaningful neurons
2025-09-20 22:01:19,191 - INFO - Sorting neurons by activation difference
2025-09-20 22:03:20,257 - INFO - Saving results to ./abl/s16.json
2025-09-20 22:03:20,321 - INFO - Multi-GPU analysis completed
2025-09-20 22:03:20,321 - INFO - Total discovered neurons: 425328635
2025-09-20 22:03:20,321 - INFO - Used 8 GPUs for computation
2025-09-20 22:03:20,321 - INFO - Top 10 neurons with highest activation difference:
2025-09-20 22:03:20,321 - INFO - Rank 1: Layer model.layers.3.mlp.down_proj, Activation diff: 471.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 22:03:20,321 - INFO - Rank 2: Layer model.layers.3.mlp.down_proj, Activation diff: 420.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 22:03:20,322 - INFO - Rank 3: Layer model.layers.3.mlp.down_proj, Activation diff: 392.000000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 22:03:20,322 - INFO - Rank 4: Layer model.layers.79.mlp.down_proj, Activation diff: 390.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 1532
2025-09-20 22:03:20,322 - INFO - Rank 5: Layer model.layers.79.mlp.down_proj, Activation diff: 342.750000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 22:03:20,322 - INFO - Rank 6: Layer model.layers.79.mlp.down_proj, Activation diff: 336.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 22:03:20,322 - INFO - Rank 7: Layer model.layers.0.mlp.down_proj, Activation diff: 62.718750, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 22:03:20,322 - INFO - Rank 8: Layer model.layers.79.mlp.down_proj, Activation diff: 51.250000, batch_idx: 0, seq_idx: 0, hidden_idx: 775
2025-09-20 22:03:20,322 - INFO - Rank 9: Layer model.layers.78.mlp.down_proj, Activation diff: 34.500000, batch_idx: 0, seq_idx: 0, hidden_idx: 7306
2025-09-20 22:03:20,322 - INFO - Rank 10: Layer model.layers.78.mlp.down_proj, Activation diff: 34.406250, batch_idx: 0, seq_idx: 0, hidden_idx: 6857
2025-09-20 22:03:22,559 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 22:03:22,563 - INFO - Discovered 425328635 neurons
2025-09-20 22:03:22,568 - INFO - Results saved to: ./abl/s16.json
2025-09-20 22:03:22,573 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 23:55:09,186 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 23:55:09,186 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:55:09,186 - INFO - Neuron file: ./abl/s12.json
2025-09-20 23:55:09,187 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:55:09,187 - INFO - Step size: 1
2025-09-20 23:55:09,187 - INFO - Max magnitude increase: 3.0
2025-09-20 23:55:09,187 - INFO - Random seed: 42
2025-09-20 23:55:09,187 - INFO - Device: auto
2025-09-20 23:55:09,879 - INFO - Available GPUs: 8
2025-09-20 23:55:09,881 - INFO - Available GPUs: 8
2025-09-20 23:55:09,881 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:55:09,881 - INFO - Transformers version: 4.56.1
2025-09-20 23:55:09,881 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 23:55:09,881 - INFO - CUDA available: True
2025-09-20 23:55:45,488 - INFO - Multi-GPU model loading completed
2025-09-20 23:55:45,488 - INFO - Model device allocation:
2025-09-20 23:55:45,488 - INFO -   model.embed_tokens: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.0: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.1: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.2: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.3: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.4: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.5: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.6: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.7: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.8: 0
2025-09-20 23:55:45,488 - INFO -   model.layers.9: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.10: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.11: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.12: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.13: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.14: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.15: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.16: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.17: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.18: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.19: 1
2025-09-20 23:55:45,488 - INFO -   model.layers.20: 2
2025-09-20 23:55:45,488 - INFO -   model.layers.21: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.22: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.23: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.24: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.25: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.26: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.27: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.28: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.29: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.30: 2
2025-09-20 23:55:45,489 - INFO -   model.layers.31: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.32: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.33: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.34: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.35: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.36: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.37: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.38: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.39: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.40: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.41: 3
2025-09-20 23:55:45,489 - INFO -   model.layers.42: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.43: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.44: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.45: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.46: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.47: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.48: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.49: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.50: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.51: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.52: 4
2025-09-20 23:55:45,489 - INFO -   model.layers.53: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.54: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.55: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.56: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.57: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.58: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.59: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.60: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.61: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.62: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.63: 5
2025-09-20 23:55:45,489 - INFO -   model.layers.64: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.65: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.66: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.67: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.68: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.69: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.70: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.71: 6
2025-09-20 23:55:45,489 - INFO -   model.layers.72: 6
2025-09-20 23:55:45,490 - INFO -   model.layers.73: 6
2025-09-20 23:55:45,490 - INFO -   model.layers.74: 6
2025-09-20 23:55:45,490 - INFO -   model.layers.75: 7
2025-09-20 23:55:45,490 - INFO -   model.layers.76: 7
2025-09-20 23:55:45,490 - INFO -   model.layers.77: 7
2025-09-20 23:55:45,490 - INFO -   model.layers.78: 7
2025-09-20 23:55:45,490 - INFO -   model.layers.79: 7
2025-09-20 23:55:45,490 - INFO -   model.norm: 7
2025-09-20 23:55:45,490 - INFO -   model.rotary_emb: 7
2025-09-20 23:55:45,490 - INFO -   lm_head: 7
2025-09-20 23:55:45,490 - INFO - Loading neuron importance data from: ./abl/s12.json
2025-09-20 23:55:45,500 - INFO - Loaded 10000 neurons
2025-09-20 23:55:45,500 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 23:55:45,500 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:55:45,500 - INFO - Step size: 1
2025-09-20 23:55:45,500 - INFO - Max magnitude increase: 3.0
2025-09-20 23:55:45,500 - INFO - Using 8 GPUs
2025-09-20 23:55:45,500 - INFO - Computing baseline perplexity
2025-09-20 23:55:46,208 - INFO - Baseline perplexity: 22.9140
2025-09-20 23:55:46,208 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 23:55:46,209 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:55:46,209 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 23:55:46,484 - INFO - Masked perplexity: 24.9976
2025-09-20 23:55:46,484 - INFO - Magnitude increase: 0.0378
2025-09-20 23:55:46,492 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 23:55:46,493 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:55:46,493 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 23:55:46,769 - INFO - Masked perplexity: 29.3805
2025-09-20 23:55:46,769 - INFO - Magnitude increase: 0.1080
2025-09-20 23:55:46,777 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 23:55:46,777 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:55:46,777 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 23:55:47,053 - INFO - Masked perplexity: 23759.0293
2025-09-20 23:55:47,054 - INFO - Magnitude increase: 3.0157
2025-09-20 23:55:47,054 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 23:55:47,054 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 23:55:47,054 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 23:55:47,054 - INFO - Total steps: 3
2025-09-20 23:55:47,054 - INFO - Final masked neurons: 3
2025-09-20 23:55:47,054 - INFO - Used 8 GPUs for computation
2025-09-20 23:55:47,054 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 23:55:47,054 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 23:55:47,054 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 23:55:47,054 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 23:55:47,054 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 23:55:47,054 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 23:55:47,054 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 23:56:21,849 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 23:56:21,849 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:56:21,849 - INFO - Neuron file: ./abl/s13.json
2025-09-20 23:56:21,849 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:56:21,849 - INFO - Step size: 1
2025-09-20 23:56:21,849 - INFO - Max magnitude increase: 3.0
2025-09-20 23:56:21,849 - INFO - Random seed: 42
2025-09-20 23:56:21,849 - INFO - Device: auto
2025-09-20 23:56:22,539 - INFO - Available GPUs: 8
2025-09-20 23:56:22,540 - INFO - Available GPUs: 8
2025-09-20 23:56:22,540 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:56:22,540 - INFO - Transformers version: 4.56.1
2025-09-20 23:56:22,540 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 23:56:22,540 - INFO - CUDA available: True
2025-09-20 23:56:57,080 - INFO - Multi-GPU model loading completed
2025-09-20 23:56:57,080 - INFO - Model device allocation:
2025-09-20 23:56:57,080 - INFO -   model.embed_tokens: 0
2025-09-20 23:56:57,080 - INFO -   model.layers.0: 0
2025-09-20 23:56:57,080 - INFO -   model.layers.1: 0
2025-09-20 23:56:57,080 - INFO -   model.layers.2: 0
2025-09-20 23:56:57,080 - INFO -   model.layers.3: 0
2025-09-20 23:56:57,080 - INFO -   model.layers.4: 0
2025-09-20 23:56:57,080 - INFO -   model.layers.5: 0
2025-09-20 23:56:57,081 - INFO -   model.layers.6: 0
2025-09-20 23:56:57,081 - INFO -   model.layers.7: 0
2025-09-20 23:56:57,081 - INFO -   model.layers.8: 0
2025-09-20 23:56:57,081 - INFO -   model.layers.9: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.10: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.11: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.12: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.13: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.14: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.15: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.16: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.17: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.18: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.19: 1
2025-09-20 23:56:57,081 - INFO -   model.layers.20: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.21: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.22: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.23: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.24: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.25: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.26: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.27: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.28: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.29: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.30: 2
2025-09-20 23:56:57,081 - INFO -   model.layers.31: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.32: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.33: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.34: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.35: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.36: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.37: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.38: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.39: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.40: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.41: 3
2025-09-20 23:56:57,081 - INFO -   model.layers.42: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.43: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.44: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.45: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.46: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.47: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.48: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.49: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.50: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.51: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.52: 4
2025-09-20 23:56:57,081 - INFO -   model.layers.53: 5
2025-09-20 23:56:57,081 - INFO -   model.layers.54: 5
2025-09-20 23:56:57,081 - INFO -   model.layers.55: 5
2025-09-20 23:56:57,081 - INFO -   model.layers.56: 5
2025-09-20 23:56:57,081 - INFO -   model.layers.57: 5
2025-09-20 23:56:57,082 - INFO -   model.layers.58: 5
2025-09-20 23:56:57,082 - INFO -   model.layers.59: 5
2025-09-20 23:56:57,082 - INFO -   model.layers.60: 5
2025-09-20 23:56:57,082 - INFO -   model.layers.61: 5
2025-09-20 23:56:57,082 - INFO -   model.layers.62: 5
2025-09-20 23:56:57,082 - INFO -   model.layers.63: 5
2025-09-20 23:56:57,082 - INFO -   model.layers.64: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.65: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.66: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.67: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.68: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.69: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.70: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.71: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.72: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.73: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.74: 6
2025-09-20 23:56:57,082 - INFO -   model.layers.75: 7
2025-09-20 23:56:57,082 - INFO -   model.layers.76: 7
2025-09-20 23:56:57,082 - INFO -   model.layers.77: 7
2025-09-20 23:56:57,082 - INFO -   model.layers.78: 7
2025-09-20 23:56:57,082 - INFO -   model.layers.79: 7
2025-09-20 23:56:57,082 - INFO -   model.norm: 7
2025-09-20 23:56:57,082 - INFO -   model.rotary_emb: 7
2025-09-20 23:56:57,082 - INFO -   lm_head: 7
2025-09-20 23:56:57,082 - INFO - Loading neuron importance data from: ./abl/s13.json
2025-09-20 23:56:57,092 - INFO - Loaded 10000 neurons
2025-09-20 23:56:57,092 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 23:56:57,092 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:56:57,092 - INFO - Step size: 1
2025-09-20 23:56:57,092 - INFO - Max magnitude increase: 3.0
2025-09-20 23:56:57,092 - INFO - Using 8 GPUs
2025-09-20 23:56:57,092 - INFO - Computing baseline perplexity
2025-09-20 23:56:57,794 - INFO - Baseline perplexity: 22.9140
2025-09-20 23:56:57,795 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 23:56:57,795 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:56:57,795 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 23:56:58,071 - INFO - Masked perplexity: 24.9976
2025-09-20 23:56:58,071 - INFO - Magnitude increase: 0.0378
2025-09-20 23:56:58,080 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 23:56:58,080 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:56:58,080 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 23:56:58,356 - INFO - Masked perplexity: 29.3805
2025-09-20 23:56:58,356 - INFO - Magnitude increase: 0.1080
2025-09-20 23:56:58,365 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 23:56:58,365 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:56:58,365 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 23:56:58,641 - INFO - Masked perplexity: 23759.0293
2025-09-20 23:56:58,641 - INFO - Magnitude increase: 3.0157
2025-09-20 23:56:58,642 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 23:56:58,642 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 23:56:58,642 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 23:56:58,642 - INFO - Total steps: 3
2025-09-20 23:56:58,642 - INFO - Final masked neurons: 3
2025-09-20 23:56:58,642 - INFO - Used 8 GPUs for computation
2025-09-20 23:56:58,642 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 23:56:58,642 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 23:56:58,642 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 23:56:58,642 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 23:56:58,642 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 23:56:58,642 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 23:56:58,642 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 23:57:17,964 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 23:57:17,964 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:57:17,964 - INFO - Neuron file: ./abl/s14.json
2025-09-20 23:57:17,964 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:57:17,964 - INFO - Step size: 1
2025-09-20 23:57:17,964 - INFO - Max magnitude increase: 3.0
2025-09-20 23:57:17,964 - INFO - Random seed: 42
2025-09-20 23:57:17,964 - INFO - Device: auto
2025-09-20 23:57:18,659 - INFO - Available GPUs: 8
2025-09-20 23:57:18,660 - INFO - Available GPUs: 8
2025-09-20 23:57:18,660 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:57:18,660 - INFO - Transformers version: 4.56.1
2025-09-20 23:57:18,660 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 23:57:18,660 - INFO - CUDA available: True
2025-09-20 23:57:53,036 - INFO - Multi-GPU model loading completed
2025-09-20 23:57:53,037 - INFO - Model device allocation:
2025-09-20 23:57:53,037 - INFO -   model.embed_tokens: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.0: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.1: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.2: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.3: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.4: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.5: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.6: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.7: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.8: 0
2025-09-20 23:57:53,037 - INFO -   model.layers.9: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.10: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.11: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.12: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.13: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.14: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.15: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.16: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.17: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.18: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.19: 1
2025-09-20 23:57:53,037 - INFO -   model.layers.20: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.21: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.22: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.23: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.24: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.25: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.26: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.27: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.28: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.29: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.30: 2
2025-09-20 23:57:53,037 - INFO -   model.layers.31: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.32: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.33: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.34: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.35: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.36: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.37: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.38: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.39: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.40: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.41: 3
2025-09-20 23:57:53,037 - INFO -   model.layers.42: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.43: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.44: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.45: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.46: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.47: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.48: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.49: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.50: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.51: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.52: 4
2025-09-20 23:57:53,038 - INFO -   model.layers.53: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.54: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.55: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.56: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.57: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.58: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.59: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.60: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.61: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.62: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.63: 5
2025-09-20 23:57:53,038 - INFO -   model.layers.64: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.65: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.66: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.67: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.68: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.69: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.70: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.71: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.72: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.73: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.74: 6
2025-09-20 23:57:53,038 - INFO -   model.layers.75: 7
2025-09-20 23:57:53,038 - INFO -   model.layers.76: 7
2025-09-20 23:57:53,038 - INFO -   model.layers.77: 7
2025-09-20 23:57:53,038 - INFO -   model.layers.78: 7
2025-09-20 23:57:53,038 - INFO -   model.layers.79: 7
2025-09-20 23:57:53,038 - INFO -   model.norm: 7
2025-09-20 23:57:53,038 - INFO -   model.rotary_emb: 7
2025-09-20 23:57:53,038 - INFO -   lm_head: 7
2025-09-20 23:57:53,039 - INFO - Loading neuron importance data from: ./abl/s14.json
2025-09-20 23:57:53,048 - INFO - Loaded 10000 neurons
2025-09-20 23:57:53,048 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 23:57:53,048 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:57:53,048 - INFO - Step size: 1
2025-09-20 23:57:53,048 - INFO - Max magnitude increase: 3.0
2025-09-20 23:57:53,048 - INFO - Using 8 GPUs
2025-09-20 23:57:53,048 - INFO - Computing baseline perplexity
2025-09-20 23:57:53,759 - INFO - Baseline perplexity: 22.9140
2025-09-20 23:57:53,759 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 23:57:53,760 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:57:53,760 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 23:57:54,035 - INFO - Masked perplexity: 24.9976
2025-09-20 23:57:54,035 - INFO - Magnitude increase: 0.0378
2025-09-20 23:57:54,044 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 23:57:54,044 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:57:54,044 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 23:57:54,320 - INFO - Masked perplexity: 29.3805
2025-09-20 23:57:54,320 - INFO - Magnitude increase: 0.1080
2025-09-20 23:57:54,329 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 23:57:54,329 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:57:54,329 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 23:57:54,605 - INFO - Masked perplexity: 23759.0293
2025-09-20 23:57:54,606 - INFO - Magnitude increase: 3.0157
2025-09-20 23:57:54,606 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 23:57:54,606 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 23:57:54,606 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 23:57:54,606 - INFO - Total steps: 3
2025-09-20 23:57:54,606 - INFO - Final masked neurons: 3
2025-09-20 23:57:54,606 - INFO - Used 8 GPUs for computation
2025-09-20 23:57:54,606 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 23:57:54,606 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 23:57:54,606 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 23:57:54,606 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 23:57:54,606 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 23:57:54,606 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 23:57:54,606 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-20 23:58:24,164 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-20 23:58:24,164 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:58:24,164 - INFO - Neuron file: ./abl/s15.json
2025-09-20 23:58:24,164 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:58:24,164 - INFO - Step size: 1
2025-09-20 23:58:24,164 - INFO - Max magnitude increase: 3.0
2025-09-20 23:58:24,164 - INFO - Random seed: 42
2025-09-20 23:58:24,164 - INFO - Device: auto
2025-09-20 23:58:24,855 - INFO - Available GPUs: 8
2025-09-20 23:58:24,856 - INFO - Available GPUs: 8
2025-09-20 23:58:24,856 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-20 23:58:24,856 - INFO - Transformers version: 4.56.1
2025-09-20 23:58:24,856 - INFO - PyTorch version: 2.8.0+cu128
2025-09-20 23:58:24,856 - INFO - CUDA available: True
2025-09-20 23:58:59,313 - INFO - Multi-GPU model loading completed
2025-09-20 23:58:59,313 - INFO - Model device allocation:
2025-09-20 23:58:59,313 - INFO -   model.embed_tokens: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.0: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.1: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.2: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.3: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.4: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.5: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.6: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.7: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.8: 0
2025-09-20 23:58:59,313 - INFO -   model.layers.9: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.10: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.11: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.12: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.13: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.14: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.15: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.16: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.17: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.18: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.19: 1
2025-09-20 23:58:59,313 - INFO -   model.layers.20: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.21: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.22: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.23: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.24: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.25: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.26: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.27: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.28: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.29: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.30: 2
2025-09-20 23:58:59,314 - INFO -   model.layers.31: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.32: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.33: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.34: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.35: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.36: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.37: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.38: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.39: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.40: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.41: 3
2025-09-20 23:58:59,314 - INFO -   model.layers.42: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.43: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.44: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.45: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.46: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.47: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.48: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.49: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.50: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.51: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.52: 4
2025-09-20 23:58:59,314 - INFO -   model.layers.53: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.54: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.55: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.56: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.57: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.58: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.59: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.60: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.61: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.62: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.63: 5
2025-09-20 23:58:59,314 - INFO -   model.layers.64: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.65: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.66: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.67: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.68: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.69: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.70: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.71: 6
2025-09-20 23:58:59,314 - INFO -   model.layers.72: 6
2025-09-20 23:58:59,315 - INFO -   model.layers.73: 6
2025-09-20 23:58:59,315 - INFO -   model.layers.74: 6
2025-09-20 23:58:59,315 - INFO -   model.layers.75: 7
2025-09-20 23:58:59,315 - INFO -   model.layers.76: 7
2025-09-20 23:58:59,315 - INFO -   model.layers.77: 7
2025-09-20 23:58:59,315 - INFO -   model.layers.78: 7
2025-09-20 23:58:59,315 - INFO -   model.layers.79: 7
2025-09-20 23:58:59,315 - INFO -   model.norm: 7
2025-09-20 23:58:59,315 - INFO -   model.rotary_emb: 7
2025-09-20 23:58:59,315 - INFO -   lm_head: 7
2025-09-20 23:58:59,315 - INFO - Loading neuron importance data from: ./abl/s15.json
2025-09-20 23:58:59,323 - INFO - Loaded 10000 neurons
2025-09-20 23:58:59,323 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-20 23:58:59,323 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-20 23:58:59,323 - INFO - Step size: 1
2025-09-20 23:58:59,323 - INFO - Max magnitude increase: 3.0
2025-09-20 23:58:59,323 - INFO - Using 8 GPUs
2025-09-20 23:58:59,323 - INFO - Computing baseline perplexity
2025-09-20 23:58:59,923 - INFO - Baseline perplexity: 22.9140
2025-09-20 23:58:59,924 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-20 23:58:59,924 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:58:59,924 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-20 23:59:00,199 - INFO - Masked perplexity: 24.9976
2025-09-20 23:59:00,200 - INFO - Magnitude increase: 0.0378
2025-09-20 23:59:00,208 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-20 23:59:00,208 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:59:00,208 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-20 23:59:00,484 - INFO - Masked perplexity: 29.3805
2025-09-20 23:59:00,485 - INFO - Magnitude increase: 0.1080
2025-09-20 23:59:00,493 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-20 23:59:00,493 - INFO - Set up 1 masking hooks for 1 layers
2025-09-20 23:59:00,493 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-20 23:59:00,770 - INFO - Masked perplexity: 23759.0293
2025-09-20 23:59:00,770 - INFO - Magnitude increase: 3.0157
2025-09-20 23:59:00,770 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-20 23:59:00,770 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-20 23:59:00,770 - INFO - Multi-GPU progressive masking analysis completed
2025-09-20 23:59:00,770 - INFO - Total steps: 3
2025-09-20 23:59:00,770 - INFO - Final masked neurons: 3
2025-09-20 23:59:00,770 - INFO - Used 8 GPUs for computation
2025-09-20 23:59:00,770 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-20 23:59:00,770 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-20 23:59:00,770 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-20 23:59:00,770 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-20 23:59:00,770 - INFO - === Multi-GPU Analysis Completed ===
2025-09-20 23:59:00,770 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-20 23:59:00,770 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-21 00:00:59,736 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-21 00:00:59,736 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-21 00:00:59,736 - INFO - Neuron file: ./abl/s16.json
2025-09-21 00:00:59,736 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-21 00:00:59,736 - INFO - Step size: 1
2025-09-21 00:00:59,736 - INFO - Max magnitude increase: 3.0
2025-09-21 00:00:59,736 - INFO - Random seed: 42
2025-09-21 00:00:59,736 - INFO - Device: auto
2025-09-21 00:01:00,499 - INFO - Available GPUs: 8
2025-09-21 00:01:00,500 - INFO - Available GPUs: 8
2025-09-21 00:01:00,500 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-21 00:01:00,500 - INFO - Transformers version: 4.56.1
2025-09-21 00:01:00,500 - INFO - PyTorch version: 2.8.0+cu128
2025-09-21 00:01:00,500 - INFO - CUDA available: True
2025-09-21 00:01:34,904 - INFO - Multi-GPU model loading completed
2025-09-21 00:01:34,904 - INFO - Model device allocation:
2025-09-21 00:01:34,904 - INFO -   model.embed_tokens: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.0: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.1: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.2: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.3: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.4: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.5: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.6: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.7: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.8: 0
2025-09-21 00:01:34,904 - INFO -   model.layers.9: 1
2025-09-21 00:01:34,904 - INFO -   model.layers.10: 1
2025-09-21 00:01:34,904 - INFO -   model.layers.11: 1
2025-09-21 00:01:34,904 - INFO -   model.layers.12: 1
2025-09-21 00:01:34,904 - INFO -   model.layers.13: 1
2025-09-21 00:01:34,904 - INFO -   model.layers.14: 1
2025-09-21 00:01:34,904 - INFO -   model.layers.15: 1
2025-09-21 00:01:34,905 - INFO -   model.layers.16: 1
2025-09-21 00:01:34,905 - INFO -   model.layers.17: 1
2025-09-21 00:01:34,905 - INFO -   model.layers.18: 1
2025-09-21 00:01:34,905 - INFO -   model.layers.19: 1
2025-09-21 00:01:34,905 - INFO -   model.layers.20: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.21: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.22: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.23: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.24: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.25: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.26: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.27: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.28: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.29: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.30: 2
2025-09-21 00:01:34,905 - INFO -   model.layers.31: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.32: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.33: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.34: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.35: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.36: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.37: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.38: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.39: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.40: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.41: 3
2025-09-21 00:01:34,905 - INFO -   model.layers.42: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.43: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.44: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.45: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.46: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.47: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.48: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.49: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.50: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.51: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.52: 4
2025-09-21 00:01:34,905 - INFO -   model.layers.53: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.54: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.55: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.56: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.57: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.58: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.59: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.60: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.61: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.62: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.63: 5
2025-09-21 00:01:34,905 - INFO -   model.layers.64: 6
2025-09-21 00:01:34,905 - INFO -   model.layers.65: 6
2025-09-21 00:01:34,905 - INFO -   model.layers.66: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.67: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.68: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.69: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.70: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.71: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.72: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.73: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.74: 6
2025-09-21 00:01:34,906 - INFO -   model.layers.75: 7
2025-09-21 00:01:34,906 - INFO -   model.layers.76: 7
2025-09-21 00:01:34,906 - INFO -   model.layers.77: 7
2025-09-21 00:01:34,906 - INFO -   model.layers.78: 7
2025-09-21 00:01:34,906 - INFO -   model.layers.79: 7
2025-09-21 00:01:34,906 - INFO -   model.norm: 7
2025-09-21 00:01:34,906 - INFO -   model.rotary_emb: 7
2025-09-21 00:01:34,906 - INFO -   lm_head: 7
2025-09-21 00:01:34,906 - INFO - Loading neuron importance data from: ./abl/s16.json
2025-09-21 00:01:34,914 - INFO - Loaded 10000 neurons
2025-09-21 00:01:34,914 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-21 00:01:34,914 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-21 00:01:34,914 - INFO - Step size: 1
2025-09-21 00:01:34,914 - INFO - Max magnitude increase: 3.0
2025-09-21 00:01:34,915 - INFO - Using 8 GPUs
2025-09-21 00:01:34,915 - INFO - Computing baseline perplexity
2025-09-21 00:01:35,554 - INFO - Baseline perplexity: 22.9140
2025-09-21 00:01:35,555 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-21 00:01:35,555 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:01:35,555 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-21 00:01:35,830 - INFO - Masked perplexity: 24.9976
2025-09-21 00:01:35,830 - INFO - Magnitude increase: 0.0378
2025-09-21 00:01:35,839 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-21 00:01:35,839 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:01:35,839 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-21 00:01:36,115 - INFO - Masked perplexity: 29.3805
2025-09-21 00:01:36,115 - INFO - Magnitude increase: 0.1080
2025-09-21 00:01:36,123 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-21 00:01:36,124 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:01:36,124 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-21 00:01:36,400 - INFO - Masked perplexity: 23759.0293
2025-09-21 00:01:36,400 - INFO - Magnitude increase: 3.0157
2025-09-21 00:01:36,400 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-21 00:01:36,400 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-21 00:01:36,400 - INFO - Multi-GPU progressive masking analysis completed
2025-09-21 00:01:36,400 - INFO - Total steps: 3
2025-09-21 00:01:36,400 - INFO - Final masked neurons: 3
2025-09-21 00:01:36,400 - INFO - Used 8 GPUs for computation
2025-09-21 00:01:36,400 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-21 00:01:36,401 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-21 00:01:36,401 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-21 00:01:36,401 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-21 00:01:36,401 - INFO - === Multi-GPU Analysis Completed ===
2025-09-21 00:01:36,401 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-21 00:01:36,401 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-21 00:02:00,276 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-21 00:02:00,276 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-21 00:02:00,276 - INFO - Neuron file: ./abl/s17.json
2025-09-21 00:02:00,276 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-21 00:02:00,276 - INFO - Step size: 1
2025-09-21 00:02:00,276 - INFO - Max magnitude increase: 3.0
2025-09-21 00:02:00,276 - INFO - Random seed: 42
2025-09-21 00:02:00,276 - INFO - Device: auto
2025-09-21 00:02:00,967 - INFO - Available GPUs: 8
2025-09-21 00:02:00,968 - INFO - Available GPUs: 8
2025-09-21 00:02:00,968 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-21 00:02:00,968 - INFO - Transformers version: 4.56.1
2025-09-21 00:02:00,968 - INFO - PyTorch version: 2.8.0+cu128
2025-09-21 00:02:00,968 - INFO - CUDA available: True
2025-09-21 00:02:35,536 - INFO - Multi-GPU model loading completed
2025-09-21 00:02:35,536 - INFO - Model device allocation:
2025-09-21 00:02:35,536 - INFO -   model.embed_tokens: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.0: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.1: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.2: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.3: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.4: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.5: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.6: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.7: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.8: 0
2025-09-21 00:02:35,536 - INFO -   model.layers.9: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.10: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.11: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.12: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.13: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.14: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.15: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.16: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.17: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.18: 1
2025-09-21 00:02:35,536 - INFO -   model.layers.19: 1
2025-09-21 00:02:35,537 - INFO -   model.layers.20: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.21: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.22: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.23: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.24: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.25: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.26: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.27: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.28: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.29: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.30: 2
2025-09-21 00:02:35,537 - INFO -   model.layers.31: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.32: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.33: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.34: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.35: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.36: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.37: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.38: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.39: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.40: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.41: 3
2025-09-21 00:02:35,537 - INFO -   model.layers.42: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.43: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.44: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.45: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.46: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.47: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.48: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.49: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.50: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.51: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.52: 4
2025-09-21 00:02:35,537 - INFO -   model.layers.53: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.54: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.55: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.56: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.57: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.58: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.59: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.60: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.61: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.62: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.63: 5
2025-09-21 00:02:35,537 - INFO -   model.layers.64: 6
2025-09-21 00:02:35,537 - INFO -   model.layers.65: 6
2025-09-21 00:02:35,537 - INFO -   model.layers.66: 6
2025-09-21 00:02:35,537 - INFO -   model.layers.67: 6
2025-09-21 00:02:35,537 - INFO -   model.layers.68: 6
2025-09-21 00:02:35,537 - INFO -   model.layers.69: 6
2025-09-21 00:02:35,537 - INFO -   model.layers.70: 6
2025-09-21 00:02:35,538 - INFO -   model.layers.71: 6
2025-09-21 00:02:35,538 - INFO -   model.layers.72: 6
2025-09-21 00:02:35,538 - INFO -   model.layers.73: 6
2025-09-21 00:02:35,538 - INFO -   model.layers.74: 6
2025-09-21 00:02:35,538 - INFO -   model.layers.75: 7
2025-09-21 00:02:35,538 - INFO -   model.layers.76: 7
2025-09-21 00:02:35,538 - INFO -   model.layers.77: 7
2025-09-21 00:02:35,538 - INFO -   model.layers.78: 7
2025-09-21 00:02:35,538 - INFO -   model.layers.79: 7
2025-09-21 00:02:35,538 - INFO -   model.norm: 7
2025-09-21 00:02:35,538 - INFO -   model.rotary_emb: 7
2025-09-21 00:02:35,538 - INFO -   lm_head: 7
2025-09-21 00:02:35,538 - INFO - Loading neuron importance data from: ./abl/s17.json
2025-09-21 00:02:35,546 - INFO - Loaded 10000 neurons
2025-09-21 00:02:35,546 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-21 00:02:35,546 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-21 00:02:35,546 - INFO - Step size: 1
2025-09-21 00:02:35,546 - INFO - Max magnitude increase: 3.0
2025-09-21 00:02:35,546 - INFO - Using 8 GPUs
2025-09-21 00:02:35,546 - INFO - Computing baseline perplexity
2025-09-21 00:02:36,144 - INFO - Baseline perplexity: 22.9140
2025-09-21 00:02:36,145 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-21 00:02:36,145 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:02:36,145 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-21 00:02:36,420 - INFO - Masked perplexity: 24.9976
2025-09-21 00:02:36,421 - INFO - Magnitude increase: 0.0378
2025-09-21 00:02:36,429 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-21 00:02:36,429 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:02:36,429 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-21 00:02:36,706 - INFO - Masked perplexity: 29.3805
2025-09-21 00:02:36,706 - INFO - Magnitude increase: 0.1080
2025-09-21 00:02:36,714 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-21 00:02:36,714 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:02:36,715 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-21 00:02:36,991 - INFO - Masked perplexity: 23759.0293
2025-09-21 00:02:36,991 - INFO - Magnitude increase: 3.0157
2025-09-21 00:02:36,991 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-21 00:02:36,991 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-21 00:02:36,991 - INFO - Multi-GPU progressive masking analysis completed
2025-09-21 00:02:36,991 - INFO - Total steps: 3
2025-09-21 00:02:36,991 - INFO - Final masked neurons: 3
2025-09-21 00:02:36,991 - INFO - Used 8 GPUs for computation
2025-09-21 00:02:36,991 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-21 00:02:36,991 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-21 00:02:36,991 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-21 00:02:36,991 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-21 00:02:36,991 - INFO - === Multi-GPU Analysis Completed ===
2025-09-21 00:02:36,991 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-21 00:02:36,991 - INFO - Log saved to: ./log/deepseek_70b.log
2025-09-21 00:02:55,963 - INFO - === Multi-GPU Progressive Neuron Masking Analyzer ===
2025-09-21 00:02:55,963 - INFO - Model path: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-21 00:02:55,963 - INFO - Neuron file: ./abl/s17.json
2025-09-21 00:02:55,963 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-21 00:02:55,963 - INFO - Step size: 1
2025-09-21 00:02:55,963 - INFO - Max magnitude increase: 3.0
2025-09-21 00:02:55,963 - INFO - Random seed: 42
2025-09-21 00:02:55,963 - INFO - Device: auto
2025-09-21 00:02:56,655 - INFO - Available GPUs: 8
2025-09-21 00:02:56,656 - INFO - Available GPUs: 8
2025-09-21 00:02:56,656 - INFO - Loading model with multi-GPU: ../model/deepseek-ai/DeepSeek-R1-Distill-Llama-70B
2025-09-21 00:02:56,656 - INFO - Transformers version: 4.56.1
2025-09-21 00:02:56,656 - INFO - PyTorch version: 2.8.0+cu128
2025-09-21 00:02:56,656 - INFO - CUDA available: True
2025-09-21 00:03:31,184 - INFO - Multi-GPU model loading completed
2025-09-21 00:03:31,184 - INFO - Model device allocation:
2025-09-21 00:03:31,184 - INFO -   model.embed_tokens: 0
2025-09-21 00:03:31,184 - INFO -   model.layers.0: 0
2025-09-21 00:03:31,184 - INFO -   model.layers.1: 0
2025-09-21 00:03:31,184 - INFO -   model.layers.2: 0
2025-09-21 00:03:31,185 - INFO -   model.layers.3: 0
2025-09-21 00:03:31,185 - INFO -   model.layers.4: 0
2025-09-21 00:03:31,185 - INFO -   model.layers.5: 0
2025-09-21 00:03:31,185 - INFO -   model.layers.6: 0
2025-09-21 00:03:31,185 - INFO -   model.layers.7: 0
2025-09-21 00:03:31,185 - INFO -   model.layers.8: 0
2025-09-21 00:03:31,185 - INFO -   model.layers.9: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.10: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.11: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.12: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.13: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.14: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.15: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.16: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.17: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.18: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.19: 1
2025-09-21 00:03:31,185 - INFO -   model.layers.20: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.21: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.22: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.23: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.24: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.25: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.26: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.27: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.28: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.29: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.30: 2
2025-09-21 00:03:31,185 - INFO -   model.layers.31: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.32: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.33: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.34: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.35: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.36: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.37: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.38: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.39: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.40: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.41: 3
2025-09-21 00:03:31,185 - INFO -   model.layers.42: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.43: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.44: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.45: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.46: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.47: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.48: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.49: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.50: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.51: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.52: 4
2025-09-21 00:03:31,185 - INFO -   model.layers.53: 5
2025-09-21 00:03:31,185 - INFO -   model.layers.54: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.55: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.56: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.57: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.58: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.59: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.60: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.61: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.62: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.63: 5
2025-09-21 00:03:31,186 - INFO -   model.layers.64: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.65: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.66: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.67: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.68: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.69: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.70: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.71: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.72: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.73: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.74: 6
2025-09-21 00:03:31,186 - INFO -   model.layers.75: 7
2025-09-21 00:03:31,186 - INFO -   model.layers.76: 7
2025-09-21 00:03:31,186 - INFO -   model.layers.77: 7
2025-09-21 00:03:31,186 - INFO -   model.layers.78: 7
2025-09-21 00:03:31,186 - INFO -   model.layers.79: 7
2025-09-21 00:03:31,186 - INFO -   model.norm: 7
2025-09-21 00:03:31,186 - INFO -   model.rotary_emb: 7
2025-09-21 00:03:31,186 - INFO -   lm_head: 7
2025-09-21 00:03:31,186 - INFO - Loading neuron importance data from: ./abl/s17.json
2025-09-21 00:03:31,195 - INFO - Loaded 10000 neurons
2025-09-21 00:03:31,195 - INFO - Starting multi-GPU progressive neuron masking analysis
2025-09-21 00:03:31,195 - INFO - Test text: Later reviews were more positive .  In just over 29 minutes , Bookends is stunning in its vision of ...
2025-09-21 00:03:31,195 - INFO - Step size: 1
2025-09-21 00:03:31,195 - INFO - Max magnitude increase: 3.0
2025-09-21 00:03:31,195 - INFO - Using 8 GPUs
2025-09-21 00:03:31,195 - INFO - Computing baseline perplexity
2025-09-21 00:03:31,792 - INFO - Baseline perplexity: 22.9140
2025-09-21 00:03:31,793 - INFO - Step 1: masking 1 neurons (total: 1)
2025-09-21 00:03:31,793 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:03:31,793 - INFO - Applied masking to 1 neurons using 1 hooks
2025-09-21 00:03:32,068 - INFO - Masked perplexity: 24.9976
2025-09-21 00:03:32,068 - INFO - Magnitude increase: 0.0378
2025-09-21 00:03:32,077 - INFO - Step 2: masking 2 neurons (total: 2)
2025-09-21 00:03:32,077 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:03:32,077 - INFO - Applied masking to 2 neurons using 1 hooks
2025-09-21 00:03:32,353 - INFO - Masked perplexity: 29.3805
2025-09-21 00:03:32,353 - INFO - Magnitude increase: 0.1080
2025-09-21 00:03:32,362 - INFO - Step 3: masking 3 neurons (total: 3)
2025-09-21 00:03:32,362 - INFO - Set up 1 masking hooks for 1 layers
2025-09-21 00:03:32,362 - INFO - Applied masking to 3 neurons using 1 hooks
2025-09-21 00:03:32,638 - INFO - Masked perplexity: 23759.0293
2025-09-21 00:03:32,638 - INFO - Magnitude increase: 3.0157
2025-09-21 00:03:32,639 - INFO - Stopping: magnitude increase (3.0157) >= threshold (3.0)
2025-09-21 00:03:32,639 - INFO - Saving results to ./result/llama_70b_mask_neuron.json
2025-09-21 00:03:32,639 - INFO - Multi-GPU progressive masking analysis completed
2025-09-21 00:03:32,639 - INFO - Total steps: 3
2025-09-21 00:03:32,639 - INFO - Final masked neurons: 3
2025-09-21 00:03:32,639 - INFO - Used 8 GPUs for computation
2025-09-21 00:03:32,639 - INFO - 
=== Multi-GPU Masking Summary ===
2025-09-21 00:03:32,639 - INFO - Step 1: 1 neurons, perplexity: 24.9976, magnitude increase: 0.0378
2025-09-21 00:03:32,639 - INFO - Step 2: 2 neurons, perplexity: 29.3805, magnitude increase: 0.1080
2025-09-21 00:03:32,639 - INFO - Step 3: 3 neurons, perplexity: 23759.0293, magnitude increase: 3.0157
2025-09-21 00:03:32,639 - INFO - === Multi-GPU Analysis Completed ===
2025-09-21 00:03:32,639 - INFO - Results saved to: ./result/llama_70b_mask_neuron.json
2025-09-21 00:03:32,639 - INFO - Log saved to: ./log/deepseek_70b.log
